{"categories":[{"title":"alg","uri":"https://liwm29.github.io/categories/alg/"},{"title":"arch","uri":"https://liwm29.github.io/categories/arch/"},{"title":"atomic","uri":"https://liwm29.github.io/categories/atomic/"},{"title":"ByteDance","uri":"https://liwm29.github.io/categories/bytedance/"},{"title":"c","uri":"https://liwm29.github.io/categories/c/"},{"title":"cache","uri":"https://liwm29.github.io/categories/cache/"},{"title":"cli","uri":"https://liwm29.github.io/categories/cli/"},{"title":"concurrency","uri":"https://liwm29.github.io/categories/concurrency/"},{"title":"dataMining","uri":"https://liwm29.github.io/categories/datamining/"},{"title":"dataStructure","uri":"https://liwm29.github.io/categories/datastructure/"},{"title":"DB","uri":"https://liwm29.github.io/categories/db/"},{"title":"deploy","uri":"https://liwm29.github.io/categories/deploy/"},{"title":"Go","uri":"https://liwm29.github.io/categories/go/"},{"title":"HTTP","uri":"https://liwm29.github.io/categories/http/"},{"title":"innoDB","uri":"https://liwm29.github.io/categories/innodb/"},{"title":"interview","uri":"https://liwm29.github.io/categories/interview/"},{"title":"kafka","uri":"https://liwm29.github.io/categories/kafka/"},{"title":"linux","uri":"https://liwm29.github.io/categories/linux/"},{"title":"mem","uri":"https://liwm29.github.io/categories/mem/"},{"title":"mq","uri":"https://liwm29.github.io/categories/mq/"},{"title":"other","uri":"https://liwm29.github.io/categories/other/"},{"title":"protocol","uri":"https://liwm29.github.io/categories/protocol/"},{"title":"rpc","uri":"https://liwm29.github.io/categories/rpc/"},{"title":"sys","uri":"https://liwm29.github.io/categories/sys/"},{"title":"Todo","uri":"https://liwm29.github.io/categories/todo/"},{"title":"underTheHood","uri":"https://liwm29.github.io/categories/underthehood/"},{"title":"vue","uri":"https://liwm29.github.io/categories/vue/"},{"title":"zookeeper","uri":"https://liwm29.github.io/categories/zookeeper/"}],"posts":[{"content":"TodoList   sysmon线程\n  eBPF和ipvs : ref\n  数据挖掘: LHS\n  数学物理方程: 波动方程,热传导方程\n  ","id":0,"section":"posts","summary":"TodoList sysmon线程 eBPF和ipvs : ref 数据挖掘: LHS 数学物理方程: 波动方程,热传导方程","tags":["Todo"],"title":"TodoList","uri":"https://liwm29.github.io/2021/04/aatodo-todo-list/","year":"2021"},{"content":"关于RMW与Atomic LD/ST [TOC]\n事情的起因是我在记录自己学习设计模式的过程时,看了sync.Once的源码,其实以前也看了很多遍,但今天一看,突然发现自己不是很懂atomic.LoadUint32()的意义,于是促成了这篇文章\natomic.LoadUint32() 关于atomic.LoadUint32意义在哪里?和普通的读有什么区别?\n 原子性: 要么发生,要么不发生\n  荐读:\nhttp://www.1024cores.net/home/lock-free-algorithms/so-what-is-a-memory-model-and-how-to-cook-it\nhttps://preshing.com/20130618/atomic-vs-non-atomic-operations/\n 原子指令分类 有两类原子指令:\n RMW: read-modify-write  compare and swap(CAS)  或相似的load-linked/store-conditional, LL/SC(解决了CAS的ABA问题)   fetch and add(FAA)  atomic.AddUint32(\u0026amp;sum, 1) 为什么有个fetch?因为要更改值,必须先加载到寄存器或ALU,再更改,所以先fetch     loads and stores  即关于load和store的原子性  atomic.LoadUint32() atomic.StoreUint32()      对于RMW类指令,很好理解,可以解决经典的对线程对sum++的竞态问题(比如使用FAA),那么load\u0026amp;store这两个指令呢?\n在一些stackoverflow的回答中,我了解到,对于内存对齐的32位数,是自然提供原子读写的,通过这个,我们大概了解到原子读写是指的能否一次性通过总线把数据从内存中读写出来,但是,如果不提供原子性,危害在哪里?\n原子性缺失证明 双MOV 证实: 对如下代码使用386的32位指令集架构,在amd64下交叉编译,可以看到,一个return语句确实分成了两个汇编指令\n 对go语言,交叉编译异常简单,只要设置GOOS和GOARCH即可\n func b() uint64 {\rvar a uint64 = 0\ra = 0x900000008\rreturn a\r}\r0x0012 00018 (a.go:6) MOVL $8, \u0026quot;\u0026quot;.~r0+4(SP)\r0x001a 00026 (a.go:6) MOVL $9, \u0026quot;\u0026quot;.~r0+8(SP)\r 非原子单条汇编指令 在一些cpu架构上(即一些指令集上),即使只有单条指令,也无法保证原子性\n比如 ARMv7 指令\n// 将r0,r1两个32位数存在r2指向的内存上的64数\rstrd r0, r1, [r2]\r  On some ARMv7 processors, this instruction is not atomic. When the processor sees this instruction, it actually performs two separate 32-bit stores under the hood\n 原子性保证 原子写:\n When an atomic store is performed on a shared variable, no other thread can observe the modification half-complete,保证数据一次写完,防止其他线程读到半更新数据 常见于32位机器写64位数,只能分成2个MOV指令,破坏了原子性  原子读:\n 保证一次读完数据,防止在两次读的间隙数据又被更改  缺失危害 这种data race的后果:\n 未提供原子写  同时写: the upper 32 bits from one thread, the lower 32 bits from another. 一读一写: any thread executing on a different core could read sharedValue at a moment when only half the change is visible,读到其他线程写了一半的数据   未提供原子读  一读多写: 读到的数据类似于同时写,上4字节来自一个线程,下4字节来自另一个线程 过程是: w1-\u0026gt;r_hi32-\u0026gt;w2-\u0026gt;r_lo32    解决方法 对共享变量这种会产生多线程读写data race的情况(不同于普通的竞态,data race是如上所说,更底层的竞态)\n因此,对于存在data race的共享变量,需要在__语言层面__提供__原子读写__,即对共享变量使用atomic rd/wr而不是plain rd/wr\n对于现代体系架构,原子读写是默认支持的,除非你在32位机器上存储64位数,或是对共享atomic.Value的读写,这时,需要显式使用相关package的函数支持\n atomic.Value可能承载一个很大的结构体,比如sync.map里面,内置的built-in map是用atomic.Value实现的\n  在底层原子读写指令的实现,要么是锁cache line ,要么是锁总线(优先锁住cache行)\n CAS cas的缺点: 可能会造成活锁和ABA问题\n 活锁: 虽然大家都在不断尝试,外界看起来也都在运行,但是没有一个人成功 ABA问题: 这不是__CAS本身的问题__,而是在使用CAS时常见的错误用法  因为使用CAS,你需要先加载旧值,oldVar = *addr,再CAS(addr,oldVar,newVar) 再加载旧值和CAS之间,如果addr被人改了又改回去,你是无法识别的,这会导致newVar也许已经失效(如果是典型的链表场景)     如果要解决这个问题,可能需要加上版本号之类的\n C++的addr.compare_exchange_weak(oldVar,newVar)当cmp失败时,会将oldVar置为新值,这可以很方便的让人写出CAS LOOP\ndo{\r// do something about oldValue and get newValue\r}\rwhile (!shared.compare_exchange_weak(oldValue, newValue));\r 但是遗憾的是Go语言的func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)\t虽然提供了非侵入式的接口,但old值是不会改变的\nLL/SC 对于load-link/store-conditional指令,可以有效解决ABA问题\noldVar = LL(addr)\r// dosomthing\rok = SC(addr , newVar)\r 一旦在本线程LL后SC前,只要有其他线程访问了这个addr,就导致SC的false\n锁 Futex fast userspace mutx\n A futex consists of a kernelspace wait queue that is attached to an atomic integer in userspace.\n 查了很久,也没弄懂到底是个啥,如果按照上面这个wiki的定义,我倾向于说go的built-in mutex就是一种futex\ntype Mutex struct {\rstate int32\rsema uint32\r}\r   state是位于用户态空间的,用于无竞态时的快速上锁\n  sema则用于竞态时的阻塞\n   这样的锁也称为lightweight mutex ref\n 总结 竞态  宏观竞态race condition  读写过程作为整体不原子,用RMW解决   微观竞态data race  读写本身不原子,用原子读写解决    默认原子读写 it’s common knowledge that on all modern x86, x64, Itanium, SPARC, ARM and PowerPC processors, plain 32-bit integer assignment is atomic as long as the target variable is naturally aligned\n处理器架构 处理器位数\n  386,i386(intel386),80386 都指intel的32位处理器\n  amd64,intel64,x86-64,x64 都指intel的64位处理器\n  处理器架构\n  x86\n x86,x86-32,IA32: x86是对Intel 8086、80186、80286、80386以及80486的架构的泛称,如今又称为x86-32,或IA-32 amd64,intel64,x86-64,x64: 由AMD公司所开发,基于IA32/x86-32架构    IA64\n IA-64: IA-64是一种崭新的系统，和x86架构完全没有相似性；不应该把它与x86-64/x64弄混    单独说x86,就是指x86-32/IA32/386/I386,单指32位intel处理器\n如果是说x86-64,会说x64或amd64/intel64\n","id":1,"section":"posts","summary":"关于RMW与Atomic LD/ST [TOC] 事情的起因是我在记录自己学习设计模式的过程时,看了sync.Once的源码,其实以前也看了很多遍,但今天一看,突","tags":["atomic"],"title":"[atomic] atomic","uri":"https://liwm29.github.io/2021/03/atomic-atomic/","year":"2021"},{"content":"推荐系统 utility matrix效用矩阵,横轴是用户,纵轴是商品,矩阵元素是打分\n推荐系统的三个核心步骤:\n 收集效用矩阵中的打分 从已知的打分中预测未知的打分 评估预测性能  Gathering Ratings 我们可以显式让用户打分或付钱让它们打分,也可以从它们的行为推测分数,比如它们经常观看,或购买\n但是utility matrix是稀疏的,大多数人对大多数item都是没有打分的,并且新用户和新item都是没有值的\n我们主要介绍三种方法:\n 基于内容的 协同的 基于潜在因子的  基于内容的推荐 主要思想: 仅考虑用户自己,我们向用户推荐这样的商品,这些商品和用户之前的高打分商品类似\n比如电影,我们已知用户的一些高打分电影,于是向用户推荐同一个导演,演员等等的电影\nItem profile 因此,我们需要为每个item建立一个profile,profile是一些特征的集合,比如电影就是导演,演员,剧本作者等等,网页就是一些关键字集合\n对于文本网页来说,如何选择重要的关键字特征呢?\n我们使用 TF-IDF score,当一个关键字在该网页出现的越多,在其他网页出现的越少,我们就认为该关键字的TF-IDF指标高,更能代表该doc\nTF-IDF score: $$ w_{ij} = TF_{ij} * IDF_i $$ 其中: $$ TF_{ij} = \\frac{f_{ij}}{max_kf_{kj}} , IDF_i = log\\frac{N}{n_i} $$ f_ij 表示term/feature i 在 doc/item j中的频率,n_i表示有多少个doc提到了term i,N是总的doc数\nUser profile 它已打分的一些item的加权平均数据\n推荐 给定user profile x和item profile i,我们通过余弦相似度来判断是否相似\npros \u0026amp; cons 优点:\n 不需要其他user的信息 能够按用户的口味推荐 能够推荐新的或不流行的item 可解释性  缺点:\n 寻找合适的feature去构建item profile是较难的 对于新用户,没有user profile,无法推荐 过于专一化,绝不推荐user的content profile之外的item,用户也许想有不同的兴趣  协同过滤 我们首先找到N个其他user,这些user对item的打分与user x的打分是类似的,我们基于这N个用户的打分来预测x的打分,所以叫协同\n寻找相似的user jaccard 相似度 如果我们不考虑具体的打分多少,而只考虑有没有打分,然后可以对集合计算jaccard相似度\ncos 相似度 我们将未打分的item视作0,于是一个user对应的item就是一个向量,计算余弦即可\npearson 互相关系数 皮尔森互相关系数,具体公式见ppt,这是统计里面相关性检验常用的方法\n协同过滤 假设utility矩阵是user x item的\nuser-user 协同过滤 即只考虑一列,通过一列上的其他相似user的值来预测自己,N代表与那些对i打过分的user中的与x最相似的k个user,s_xy代表x与y的相似度 $$ r_{xi} = \\frac{\\sum_{y∈N}s_{xy}*r_{yi}}{\\sum_{y∈N}s_{xy}} $$\nitem-item 协同过滤 即只考虑一行,通过一行上的其他相似item的值来预测自己 $$ r_{xi} = \\frac{\\sum_{j∈N}s_{ij}*r_{xi}}{\\sum_{j∈N}s_{ij}} $$\npros \u0026amp; cons 优点:\n 不需要选择feature,对所有类型的item都适用  缺点\n 冷启动 first rater,对于未被打分过的新item,不能推荐 popularity bias,一般会倾向于推荐热门的item,而不是对味的item  ","id":2,"section":"posts","summary":"推荐系统 utility matrix效用矩阵,横轴是用户,纵轴是商品,矩阵元素是打分 推荐系统的三个核心步骤: 收集效用矩阵中的打分 从已知的打分中预测未知的打","tags":null,"title":"recommend system","uri":"https://liwm29.github.io/2021/04/datamining-recsys/","year":"2021"},{"content":"locality sensitive hashing 位置敏感哈希,这是一种hash算法,当两个对象被hash到同一个桶中时,我们认为这两个对象是可能相似的,然后去检查这两个对象的相似性,最后得出答案,这避免了对所有对象两两之间进行O(N^2)的比较\n寻找相似的文章 graph LR;\ra(docs)--\u0026gt;|shingling|b(k-shingles)--\u0026gt;|min-hashing|c(signature matrix)--\u0026gt;|lsh|d(buckets)\r shingling shingling是一个取样过程,最终得到k-shingle的集合,即每个shingle含有k个token,token可以是char,word等,一般可以用word\nshingle的方法是,维护一个k大小的窗口,从文档开头开始,取样,然后向后移动一个token,继续取样,重复上述过程\n假设doc是\u0026quot;abcab\u0026quot;,以k=2,token=char来shingle,则得到{ab,bc,ca,ab} -\u0026gt; {ab,bc,ca}(忽略重复的)\n假设doc是\u0026quot;a rose is a rose is a rose\u0026quot;,以k=4,token=word来shingle,则得到{ (a,rose,is,a), (rose,is,a,rose), (is,a,rose,is),(a,rose,is,a),(rose ,is ,a ,rose) } -\u0026gt; { (a,rose,is,a), (rose,is,a,rose), (is,a,rose,is) }\n现在我们有了两个doc的k-shingle集合,一种朴素的想法是直接计算这两个集合的jaccard相似度即可,这需要O(N^2)的复杂度\nmin-hashing 在保留相似性的情况下,将大的shingle的集合hash成小的signature\n  if sim(C1,C2) is high, then with high prob. h(C1) = h(C2)\n  if sim(C1,C2) is low, then with high prob. h(C1) ≠ h(C2)\n   Pr[ hmin(A) = hmin(B) ] = J(A,B)\n 不是所有的相似性度量都能找到何时的hash函数,但是当使用jaccard时,min-hashing就是一个合适的hash函数\n首先我们在shingling可以得到一个shingles矩阵(行是shingle,列是doc),我们定义一次min-Hashing是这样的,首先生成一个随机的全排列,然后将每一列按这个全排列进行重新排列,然后寻找第一个为1的行号,这个行号就是minHashing的结果(至于这个行号是选择映射后的还是映射前的,其实无所谓)\n进行多次minHashing,我们得到了一个signature matrix,每一行就是相应的列的一次minHashing的结果\n比如一列是(1100011),排列向量是(2376154),那么结果是(0111100),排列向量代表着映射后的位置\n 一般可能hash100次,即最终的signature矩阵有100行\n LSH 我们认为两个doc之间如果jaccard的相似度大于0.8,就是相似的\nLSH哈希函数的目的是将一些doc映射到一个桶中,我们认为一个桶内的doc就是可能相似的备选对(candidate pair),然后去check这些备选对即可\n在lsh中,一列被分为b个band,一个band包含r行,我们每次对一个band进行hash(一列hash到一个桶,并且只有当band完全相同时,才会hash到一个桶),对于hash到一个桶内的不同列,我们认为其是备选对,check它们真正的相似性\n继续hash下一个band,重复操作\n 因此,对于hash到一个桶内的不同列,它们至少是有一个band是完全相同的,假设sim(c1,c2)=0.8,也就是c1,c2两列的相似度为0.8,也就是每个signature相似的概率为0.8,那么一个band完全相同的概率为(0.8)^r\n  这个hash函数的选取,只需要保证,必须是完全相同才能映射到一个桶中\n ","id":3,"section":"posts","summary":"locality sensitive hashing 位置敏感哈希,这是一种hash算法,当两个对象被hash到同一个桶中时,我们认为这两个对象是可能相似的,然后去检查这两个对象的相似性,","tags":["dataMining","LSH"],"title":"[dataMining] LSH","uri":"https://liwm29.github.io/2021/04/datamining-lsh/","year":"2021"},{"content":"深入kafka 在此前的系列中,其实对于kafka集群和zk集群的区分很模糊,数据似乎有时是存在某个broker中的,又有时是存在zk中的\nkafka成员 kafka使用zk来维护集群成员的信息.\n","id":4,"section":"posts","summary":"深入kafka 在此前的系列中,其实对于kafka集群和zk集群的区分很模糊,数据似乎有时是存在某个broker中的,又有时是存在zk中的 ka","tags":["mq","kafka"],"title":"[mq] kafka4 工作原理","uri":"https://liwm29.github.io/2021/04/mq-kafka4-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","year":"2021"},{"content":"Intro  官方文档： https://zookeeper.apache.org/doc/r3.4.14/\n zookeeper是一种分布式协调服务(也就是说常称的注册中心),分布式应用正在运行的一组系统称为集群，而在集群中运行的每台机器被称为节点\n服务器在整个集群中，有三种角色，分别是\n Leader  处理写请求，事务调度和处理   Follower  处理读请求，转发写请求给leader，参与leader选举   Observer  同follower，但不参与leader选举    主从和主备\n 主从： 主节点分配调度任务，从节点执行任务 主备： 主节点作为日常工作节点，当主节点宕机后，备份节点成为主节点  实际上，我们使用的是主从和主备的结合，从节点不仅会执行任务，也会选举成为主节点\n 注意,采用主备模式的集群（比如kafka的某个主分区和备份分区），会有数据同步这个概念，即备份节点从主节点同步数据。\n但是zk中，写是下发到从节点的，但它们的写提交是类似的，都要等大部分节点完成写/同步后，才算写的完成\n这两者的区别，更像是主动和被动的区别，同步是从节点主动，而消息议案是主节点主动\n Guarantees  Sequential Consistency - Updates from a client will be applied in the order that they were sent. Atomicity - Updates either succeed or fail. No partial results. Single System Image - A client will see the same view of the service regardless of the server that it connects to. Reliability - Once an update has been applied, it will persist from that time forward until a client overwrites the update. Timeliness - The clients view of the system is guaranteed to be up-to-date within a certain time bound.  APIS zk 只支持7种操作，这里的node指的是znode\n create : creates a node at a location in the tree delete : deletes a node exists : tests if a node exists at a location get data : reads the data from a node set data : writes data to a node get children : retrieves a list of children of a node sync : waits for data to be propagated  connection Clients connect to a single ZooKeeper server. The client maintains a TCP connection through which it\n sends requests, gets responses, gets watch events, sends heart beats.  If the TCP connection to the server breaks, the client will connect to a different server.\nznode  znode： zookeeper data node\n zk以类似目录的形式来组织数据，client要想找到想要的数据，需要先提供数据的路由地址（比如/app/1/p）, 和目录不同之处在于目录本身也能存数据，而不只是文件才能存数据\n好像比较，其他的注册中心可能采用键值的形式，而不是路由的形式\n 小知识： gin的路由是基于radix数的\n znode结构 Znodes maintain a stat structure that includes version numbers for data changes, ACL changes, and timestamps, to allow cache validations and coordinated updates.\nEach time a znode\u0026rsquo;s data changes, the version number increases. For instance, whenever a client retrieves data it also receives the version of the data.\n ACL: Each node has an Access Control List (ACL) that restricts who can do what.\n 数据读 Read requests are serviced from the local replica of each server database.\nRequests that change the state of the service, write requests, are processed by an agreement protocol.\n数据写 As part of the agreement protocol all write requests from clients are forwarded to a single server, called the leader.\nThe rest of the ZooKeeper servers, called followers, receive message proposals from the leader and agree upon message delivery.\n follower收到写请求-\u0026gt;follower转发给leader-\u0026gt;leader发送消息提案给follower-\u0026gt;follower返回ack，表示接收消息写\n 数据更新 Updates are logged to disk for recoverability, and writes are serialized to disk before they are applied to the in-memory database.\n WAL : write ahead log,在写数据之前先写log，这里和数据库的区别是，数据是驻留在内存的，而log是在磁盘的\n 顺序 zab要求满足如下的顺序（都要满足）\n 全序（total order）  If message a is delivered before message b by one server, then every server that delivers a and b delivers a before b. 这里的deliver message，可以理解为消息被client看见，即开始分发这个消息给client   因果序（causal order）  If message a causally precedes message b and both messages are delivered, then a must be ordered before b.    因果序有两种：\n If two messages,a and b, are sent by the same server and a is proposed before b,we say that a causally precedes b;  由同一个server发送导致的消息顺序   If a leader changes, any previously proposed messages causally precede messages proposed by the new leader.  由leader变更导致的消息顺序    原子广播Zab  ref： https://www.datadoghq.com/pdf/zab.totally-ordered-broadcast-protocol.2008.pdf\n Zab协议下的服务有两种状态\n 广播 恢复  当一个新的服务开启，或leader宕机后，服务进入恢复状态，直到新的leader出现并且存在法定人数的follower与leader的状态同步，此后服务进入广播状态\n对于服务器，也同样具有这两种状态，当一个新的服务器进入集群时，首先进入恢复状态，直到与leader同步，然后进入广播状态（当新server加入时，虽然它自己是恢复状态，但整个服务仍是广播状态）\n写提交（write commit） 这是一种__两阶段提交__协议\n a leader proposes a request, collects votes, and finally commits\n leader收到写请求后，将其作为消息议案（message proposal）广播给follower，follower在自己的in-memory database写这个消息后，返回ack给leader，当leader收到法定人数的ack后立马提交，而无需等待所有的follower的ack. 提交操作会广播commit消息给所有的follower，follower收到commit后，client就能从它那里读该消息了（当然，提交后client可以立即从leader那里读消息）\n 但是commit是没有ack的，如果leader自己commit后立马宕机了，follower都不知道这个消息commit了怎么办？\n 消息顺序性 Zab使用TCP协议，该协议本身就提供了一个FIFO通道（使用序号来排序），所以对端将会按发端发送的顺序接收消息\nzxid 每个被propose的消息都会被赋予一个单调递增的唯一id，称为zxid. 为了保证因果序，消息也会按照zxid进行排序\n恢复  a recovery procedure is necessary to elect a new leader and bring all servers to a correct state\n 两个原则：\n 当一个消息在一个服务器上可见（被commit），那么它就应该在所有服务器上可见 一个被跳过的消息应该维持其被跳过的状态  否则就会违背消息顺序性    当leader收到来自法定人数的follower的commit后，该消息就在leader身上commit了，然后准备向follower广播这个commit，这时，leader宕机了，只有部分follower收到了这个commit\n后续的leader被选举出来，follower首先会和leader同步状态，如果这个leader收到了那个消息的commit，那么其他follower应该提交这个消息，如果它没有收到，其他follower就应该取消对该消息的提交\n在实现上，这是借助zxid实现的，zxid的低32位是递增的uid，高32位是与epoch相关的uid，没选举一次leader就会一轮\n当上一次宕机的leader重新上线，它将作为follower，此时的leader将会检查follower的最进提交的消息的epoch，和自己的epoch里的最近提交的消息比对，并告诉follower删除那条提交\n","id":5,"section":"posts","summary":"Intro 官方文档： https://zookeeper.apache.org/doc/r3.4.14/ zookeeper是一种分布式协调服务(也就是说常称的注册中心),分布式应用正在运行的一组系统称为集群，而在集群中运行的每台机","tags":["zookeeper"],"title":"[zk] zk1 intro","uri":"https://liwm29.github.io/2021/04/zk-zk1-intro/","year":"2021"},{"content":"kafka3 consumer [TOC]\n消费组 往群组里增加消费者是横向伸缩消费能力的主要方式\n消费组内的消费者可以订阅不同的topic,这意味着不是所有的消费者都能接收到某个topic的消息,而必须要订阅\n因此逻辑上消费者的查找关系是: 消费组\u0026ndash;\u0026gt;订阅了该消息的消费者们\u0026ndash;\u0026gt;消费者\n分区再均衡 由于我们可能动态的增加和缩减消费组内的消费者(因为一个消费者是一个进程,增加一个进程是理所当然的),所以,分区与消费者的对应关系需要变化\n在再均衡期间,消费者无法读取消息,会有短时间内的消息队列不可用\n由于分区消费offset是由消费者维护的,当由新的消费者接替时,将会丢失offset,这时需要去zk/broker同步offset,也会增加一些开销\n群组协调器 某个broker将会被指定为某个消费组的协调器,不同的消费组可以有不同的协调器.\n消费者将会往协调器发送心跳heartbeat,来维持消费者和消费组的从属关系以及和分区的对应(所有权)关系.\n消费组会在消费消息或提交偏移量时发送心跳,如果消费者较长时间未发送心跳,协调器就认为该消费者宕机,便触发一次再平衡\n分区分配过程 无论是再分配还是初始分配过程,都是一样的,针对给定的分区和消费者,均匀分配所有权关系\n该分配过程由消费组的群主承担,第一个加入消费组的消费者自动成为群主.群主从协调器那里获得群组成员列表和分区数,并给每个分区分配一个消费者.分配完毕后,群主将结果发送给协调器,协调器再将每个消费者的分配情况发送给消费者,消费者只能看见自己被分配的分区\n创建kafka消费者 创建消费者需要指定:\n bootstrap.servers,比如:\u0026ldquo;broker1:9092,broker2:9092\u0026rdquo;  bootstrap.servers也就是broker-list,但不需要包含所有的broker,客户端会做一个搜索,搜出所有的broker,一般指定两个,防止其中一个宕机   group-id,即所属的消费组 反序列化器  订阅主题 consumer可以通过列表或正则的方式订阅主题\n 注意: 同一个Group中的不同Consumer实例可以订阅不同的Topic\n即:订阅是消费者的行为,而不是消费组的行为\n 轮询 kafka是pull类型的消息队列,需要消费者自身定期轮询broker\n轮询不只是包含消息拉取,还包含查找群组协调器并加入该组,接收分配的分区,以及后续的再平衡过程,以及心跳的发送\n消息提交和偏移量 kafka不会像其他__JMS__队列一样,需要消费者在消费成功后返回ack,这是因为偏移量offset是由消费者自己维护的.\n jms指java message service,是一种消息队列api规范\n 为了保证分区再平衡或消费者宕机后的消息偏移量丢失,消费者仍然需要以一种方式去向消息队列提交偏移量\n具体操作是,消费者往一个叫__\u0026quot;_consumer_offset\u0026quot;__的特殊主题上发送消息,消息包含该消费者消费分区的偏移量\n自动提交 消费者可以设置自己的提交方式为自动提交,默认下,每过5s,消费者就会把当前偏移量提交,间隔可以由某个参数设置,但是注意,提交操作是在轮询操作中的,而不是真正的定时任务,所以,提交间隔可能大于设置的参数.\n 自动提交一般以配置文件的方式设置\n 但显然,提交的offset总是要落后于当前offset的,再平衡后,消息将会被重复处理\n手动同步提交 调用consumer.commitSync()来提交当前poll()返回的最新的offset\n手动异步提交 同步提交会阻塞进程,可以使用consumer.commitAsync()来避免对程序吞吐量的降低\n错误处理 我们在poll_loop里面,将会使用异步的提交,但是如果发生错误要退出进程了,将会在退出前使用同步提交同步一次offset\n再均衡回调 当消费者订阅一个主题时,允许其传入一个再均衡处理器的回调类 ,该处理器需要实现两个函数\n onPartitionsAssigned onPartitionsRevoked  当由于新消费者加入或旧消费者退出导致的再平衡时,该处理器将会被执行.一般的,我们借助这个处理器来提交当前处理的offset\n 在go中,其实可以定义两个接口,一个实现onPartitionsAssigned,一个实现onPartitionsRevoked,然后传入的时候,参数形式是interface{},内部再断言一下就可以了\n可以参考rpcx的插件开发,它会将所有的插件无差别的注册在一起,以interface{}存储,然后使用的时候,我们在一个特定的地方需要调用一个特定的插件,此时便遍历所有插件断言能否转成特定的插件\n 流指针改变 我们说消息队列是一种伪流,因为我们仍然可以操作流指针,使之回退或前进,相当于文件流指针的用法,通过seek方法改变当前读取位置\n优雅退出 我们可能希望能在其他线程关闭所有的或一些消费者,在go语言里这是简单的,只需要一个经典的for{select{}}即可\n对于信号,我们也要捕捉,因为在关闭前,我们需要做一些收尾工作,比如首先停止poll,但是对正在处理的消息,我们仍然要等它处理完成,然后提交offset.最后退出\n独立消费者 有时候,我们可能不想让消费者加入某个消费组,而只是让他独立存在,这时候我们可以手动分配分区\n前面我们订阅分区是通过consumer.subscribe(\u0026quot;topic\u0026quot; , rebalanceHandler),消费组的id是在创建consumer时指定的.\n手动分配分区时,首先去查询某个topic的所有分区列表partitionInfos = consumer.partitionsFor(\u0026quot;topic\u0026quot;),然后遍历列表,组合成assign api要求的数据形式,最后调用assign.\n注意consumer.assign(partitions)中,这个partitions是类似于[]TopicPartition一样的数组,TopicPartition是{topic,partition}是结构,因此,这是为了能订阅不同主题的不同partition而设计的.\n","id":6,"section":"posts","summary":"kafka3 consumer [TOC] 消费组 往群组里增加消费者是横向伸缩消费能力的主要方式 消费组内的消费者可以订阅不同的topic,这意味着不是所有的消费者都能接收到某个t","tags":["mq","kafka"],"title":"[mq] kafka3 consumer","uri":"https://liwm29.github.io/2021/04/mq-kafka3-consumer/","year":"2021"},{"content":"安装kafka 我们知道apt-get install只能安装某个版本的软件,这取决于在软件源那里的最新软件版本,你可以使用apt-get search搜索看有没有自己想要的版本\n一般的,为了安装特定的版本,或自己没有root权限,我们需要自己手动下载安装包编译,或解压\n[TOC]\n安装zookeeper 首先安装zk\n解压 对于.tar.gz格式的压缩包,使用tar -zxvf 轻松解压\n对于.zip格式的压缩包,需要使用unzip\n默认安装目录 一般的,程序会被安装到/usr/local/\n所以我们执行如下的命令:\ntar -zxf zookeeper-3.4.6.tar.gz\rmv zookeeper-3.4.6 /usr/local/zookeeper  usr目录,也许可以理解成user shared resource,总之就是只读资源目录的意思\n  如果是配置文件,一般放在/etc目录\n editable text configuration    如果是日志文件或数据文件,一般放在/var目录\n variable,可变数据,即需要常更新写入的日志    创建配置 可以使用__here document__的用法,即使用cat \u0026gt; file \u0026lt;\u0026lt; EOF来在终端写入一个多行文本\ncat \u0026gt; /usr/local/zookeeper/conf/zoo.cfg \u0026lt;\u0026lt; EOF \u0026gt; tickTime=2000 \u0026gt; dataDir=/var/lib/zookeeper \u0026gt; clientPort=2181 \u0026gt; EOF\r 配置说明 zookeeper是一个分布式数据库,基于某种一致性协议进行节点同步\n当节点个数有一半不可提供服务时,zookeeper就不对外提供服务(即如果有多数节点能提供服务,zookeeper就能提供服务)\n 因此,一般建议配置奇数个节点,比如3个节点,则允许坏1台;5个节点,允许坏2台;一般不建议大于7,因为会增加一致性协议同步的负担  TickTime 服务器会主动的轮询自身集群的状态,这个间隔就是ticktime,一切的其他与时间有关的任务,比如从节点与主节点最大的不同步时间,比如从节点和主节点初始化连接的超时时间\n这样好处是,在底层实现上,我们的确是以一定的时间间隔来轮询的.\n通信端口与选举端口 对内,zk集群内节点会暴露两个端口,一个是用于通信的端口,一个是用于leader选举的端口\n对外,整个zk暴露一个clientPort,用于客户端的连接\nPaxos\u0026amp;ZAB协议 paxos是Lesile Lamport于1990年提出的基于消息传递且具有高容错特性的一致性算法\nzookeeper的一致性算法并没有完全采用paxos,而是使用了一种称为zookeeper atomic broadcast(ZAB,zookeeper原子消息广播协议)\nPaxos是通用算法,ZAB是非通用的专用于zk的一致性算法\nleader\u0026amp;follower\u0026amp;observer 在zookeeper中,节点有三种类型:\n leader follower observer  其中,leader和follower称为公民,用于计算存活节点;follower和observer称为learner.\nleader只有一个,为客户端和follower提供读写服务.leader也可以拒绝客户端的连接,而只向follower提供写服务.\nfollower只提供读服务,对于写请求,会统一转发到leader,由leader进行统一的调度\n对于写操作,leader接收到来自follower的写请求后,向所有follower转发写请求,当有过半follower返回ack后,则在leader服务器上提交写请求,代表写成功. 对于那些在leader提出但未提交的写事务,则会被丢弃\n以上只是简略的一个介绍,其目的是知道这些名词,详细介绍应该去看书,或者zk系列文章\n 注意zookeeper需要设置三个端口,分别用于接收客户端请求clientPort,节点间通信peerPort和节点间选举leaderPort.\n 安装Broker 解压后移动到/usr/local即可(因为/usr/local是在path的)\n当然,kafka还要求设置log目录和JAVA_HOME环境变量\ntar -zxf kafka_2.11-0.9.0.1.tgz\rmv kafka_2.11-0.9.0.1 /usr/local/kafka\rmkdir /tmp/kafka-logs\rexport JAVA_HOME=/usr/java/jdk1.8.0_51\r 启动脚本启动服务器:\n/usr/local/kafka/bin/kafka-server-start.sh -daemon\r/usr/local/kafka/config/server.properties\r 创建topic并打印信息\n  replication-factor=1 表示复制因子为1,即每个partition只有一个副本(这个副本,不是指额外的拷贝,而是算自身的,所以如果你想一个leader,一个follower,则应该设置复制因子为2)\n  --zookeeper localhost:2181 首先连接到zk,然后指定主题名--topic test,然后指定动作:create或describe\n  /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --replication-factor 1 --partitions 1 \u0026gt; Created topic \u0026quot;test\u0026quot;.\r/usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test\r 生产者向对应topci生产消息\n 这里Test Message 1\\nTest Message 2是自己的输入,使用ctrl-D输入EOF 这里:9092是kafka默认监听的端口,因此生产者其实不需要指定zk  /usr/local/kafka/bin/kafka-console-producer.sh --broker-list\rlocalhost:9092 --topic test\rTest Message 1\rTest Message 2\r^D\r 消费者从对应topic消费消息\n/usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper\rlocalhost:2181 --topic test --from-beginning\rTest Message 1\rTest Message 2\r^C\rConsumed 2 messages\r 很奇怪,为什么一会是连接zk,一会是连接kafka呢?\n","id":7,"section":"posts","summary":"安装kafka 我们知道apt-get install只能安装某个版本的软件,这取决于在软件源那里的最新软件版本,你可以使用apt-get sea","tags":["mq","kafka"],"title":"[mq] kafka1.5 install","uri":"https://liwm29.github.io/2021/04/mq-kafka1.5-install/","year":"2021"},{"content":"kafka producer  参考kafka技术内幕:图文详解kafka源码设计和实现\n 本节主要讲关于kafka的生产者相关的事情,比如同步与异步的api调用,底层的网络通信框架(比如rpc)\n回顾 在kafka1 intro中,我们知道了典型的kafka架构,我们有producer,broker,consumer,connector(目前我们对connecter还基本没有什么了解)\nbroker就是所谓的消息中心,它是分布式的,并且是partition相关的分布式.\n一个topic有多个partition,每个partition仅与一个消费组中的消费者关联,topic将会在多个broker中存在,作为备份,那么就会有主从之分,但是主从区分的粒度不是topic,而是partition.这样可以保证broker的负载均衡,因为消费者只会读写主partition,从partition将会作为另类的消费者去读写主partition来同步.\n同步与异步api 同步api将会造成阻塞,而异步api立即返回.\n这里我们主要关注设计,异步api需要传入回调函数,用于在broker返回ack后执行,显然,这需要新开一个线程,监视网络入包.\n无论是同步还是异步api,其下一层应该都调用同样api,事实上,kafka的producer.send()方法会返回一个future,如果调用future.get(),那么自然阻塞.\n 注意异步api要设计 传入回调函数\n 分区路由 对于给定key的消息,我们先对key散列,然后对分区数取模,这样就能保证同一个key的消息能发送到同一个partition\n对于未指定key的消息,我们采用轮询partition的方法\n 这里的轮询指round-robin,也就是顺序循环,说成轮询其实不太好\n  显然还可以有更多的路由算法,比如如果分区数与消费者数不匹配,那么显然有一些分区的负担低一点,这时候可以更多的往该分区发送消息(基于加权的路由,可以参考nginx的加权平滑路由算法)\n 为什么要增加分区路由,而不增加一个负载均衡器,producer将信息发往负载均衡器,然后由负载均衡器进行消息的路由呢?\n主要是这因为:\n 一台负载均衡器负责所有producer的转发路由,负担较重 从producer到load balancer,再从load balancer到broker,是位于一个网络中的,于是造成了两倍的网络开销  消息缓冲 kafka设计了消息缓冲器RecordAccumulater,当producer调用send方法后,首先会向accumulater追加消息,如果收集器满了,就唤醒sender线程,异步发送消息\n记录(消息)是按批发送的,目的也是为了减少io次数,网络开销\n在kafka的设计中,accumulater是一个双端链表,每个链表节点是一个固定长度的数组,代表一批. 显然,有多少个分区,就有多少个链表.\n发送线程 一种朴素的方法就是迭代accumulater的所有链表,直接往分区的主副结点发送.\n另一种较高效的方法是先将分区按其主副结点分组(即不同的分区的leader可能在同一个broker),那么这时候将这两个分区打包发送,又减少了网络开销\n 我想到的一种方式就是accumulater维护一个map\u0026lt;brokerId , [ ]accumulater_partition\u0026gt;,记录节点到分区的映射,sender线程只需要遍历这个map,即可完成对partition的分组\n 在kafka的设计中,sender线程并不真正发送数据,这是因为网络连接需要更多的封装和抽象,sender线程仅准备好一次连接发送的所有数据\n网络连接 NetworkClient对象提供了对客户端和服务端之间通信的封装,包括连接建立,发送请求,读取响应等.\n为了保障服务器性能,在网络连接对象中,我们限制了对同一broker的连接数为1,即当上一次send还未收到ack时,这次的对同一broker的connect将会被禁止\n 从源码阅读上看,清晰度完全不如go啊\n ","id":8,"section":"posts","summary":"kafka producer 参考kafka技术内幕:图文详解kafka源码设计和实现 本节主要讲关于kafka的生产者相关的事情,比如同步与异步的api调用,底层的网","tags":["mq","kafka"],"title":"[mq] kafka2 producer","uri":"https://liwm29.github.io/2021/03/mq-kafka2-producer/","year":"2021"},{"content":"虚拟内存virtual memory 什么是虚拟内存,应该不用多言.本质就是一个逻辑的虚拟地址空间,这些地址空间中,有的地址真正的对应到了物理内存的地址,有的地址却是对应到了磁盘上的地址(通过swap交换换页进入物理内存).\n对进程来说,虚拟内存屏蔽了底层的物理内存和外存,为进程提供简洁易用的接口.\n进程持有的虚拟地址会经过内存管理单元(mmu,memory management unit)转变为物理地址,然后访问物理内存.\n 主存的随机访问速度是磁盘的100K倍,但是顺序访问速度却只是磁盘的10倍(因此某些服务比如kafka,redis在持久化时,会采用aof文件顺序写)\n 虚拟页 虚拟内存以页作为基本组织单位,一般一个页4KB.\n页有三种状态:\n 未分配 未缓存 已缓存  显然,其中未缓存和已缓存都代表已分配.未缓存指的是该虚拟内存指向了磁盘上的地址,尚未交换到物理内存,而已缓存指的是已加载到物理内存\n当用户访问未被缓存的物理页时,触发缺页中断,于是被访问页被加载到物理内存上\n 页表存储了虚拟内存到物理内存的映射,每个PCB都有一个页表指针,即每个进程都拥有一个自己的页表\n 交换区 磁盘上不是所有空间都能被虚拟地址空间映射的,我们专门在磁盘上划分了一个交换区.这里的数据可以被页面调度或交换\n页面调度和交换 页面调度指的是物理内存上的单个物理页是否和磁盘上交换区的物理页交换(页面swap)\n交换一般指整个进程的交换,是一种进程状态,表示整个进程在内存中的映像都换到了外存\n不过一般来说,一次页面调度也是一次页的交换\n无图无真相 cat /proc/cpuinfo\raddress sizes : 39 bits physical, 48 bits virtual\r liwm29@lwm:/mnt/c/WINDOWS/system32$ free\rtotal used free shared buff/cache available\rMem: 6399360 72100 6284536 68 42724 6180340\rSwap: 2097152 0 2097152\r liwm29@lwm:/mnt/c/WINDOWS/system32$ cat /proc/meminfo\rMemTotal: 6399360 kB\rMemFree: 6253264 kB\rMemAvailable: 6164212 kB\rBuffers: 9564 kB\rCached: 49864 kB\rSwapCached: 0 kB\rActive: 23280 kB\rInactive: 38232 kB\rActive(anon): 2156 kB\rInactive(anon): 8 kB\rActive(file): 21124 kB\rInactive(file): 38224 kB\rUnevictable: 0 kB\rMlocked: 0 kB\rSwapTotal: 2097152 kB\rSwapFree: 2097152 kB\rDirty: 252 kB\rWriteback: 0 kB\rAnonPages: 2056 kB\rMapped: 4092 kB\rShmem: 68 kB\rSlab: 27232 kB\rSReclaimable: 13536 kB\rSUnreclaim: 13696 kB\rKernelStack: 1808 kB\rPageTables: 168 kB\rNFS_Unstable: 0 kB\rBounce: 0 kB\rWritebackTmp: 0 kB\rCommitLimit: 5296832 kB\rCommitted_AS: 7256 kB\rVmallocTotal: 34359738367 kB\rVmallocUsed: 0 kB\rVmallocChunk: 0 kB\rPercpu: 1888 kB\rAnonHugePages: 0 kB\rShmemHugePages: 0 kB\rShmemPmdMapped: 0 kB\rHugePages_Total: 0\rHugePages_Free: 0\rHugePages_Rsvd: 0\rHugePages_Surp: 0\rHugepagesize: 2048 kB\rHugetlb: 0 kB\rDirectMap4k: 17408 kB\rDirectMap2M: 3446784 kB\rDirectMap1G: 4194304 kB\r 共享内存 我们知道线程(pthread_create)之间是共享全局变量的,而进程(fork)之间是不共享的,这是为什么呢?\n其内部就是虚拟内存有关,当调用fork后,子进程会copy父进程的页表,所以此时它们指向了同样的物理内存空间,如果使用clone(),使用CLONE_VM 参数,那么它们就真的共享同一个内存空间了,否则的化,会触发写时复制\npage cache 虚拟内存将主存看成是磁盘的缓存,所以叫cache\nDRAM与SRAM dram指内存,sram指cpu与内存之间的高速缓存,比如L1 cache,L2 cache\u0026hellip;\nPage cache \u0026amp; Disk buffer 首先是cache和buffer的区别\n cache是缓存,加快读的速率 buffer是缓冲,主要是为了减少io次数,进行批量读和批量写   In computing, a page cache, sometimes also called disk cache,[1] is a transparent cache for the pages originating from a secondary storage device such as a hard disk drive (HDD) or a solid-state drive (SSD). The operating system keeps a page cache in otherwise unused portions of the main memory (RAM), resulting in quicker access to the contents of cached pages and overall performance improvements. A page cache is implemented in kernels with the paging memory management, and is mostly transparent to applications.\nUsually, all physical memory not directly allocated to applications is used by the operating system for the page cache. Since the memory would otherwise be idle and is easily reclaimed when applications request it, there is generally no associated performance penalty and the operating system might even report such memory as \u0026ldquo;free\u0026rdquo; or \u0026ldquo;available\u0026rdquo;.\n  The disk buffer is physically distinct from and is used differently from the page cache typically kept by the operating system in the computer\u0026rsquo;s main memory. The disk buffer is controlled by the microcontroller in the hard disk drive, and the page cache is controlled by the computer to which that disk is attached. The disk buffer is usually quite small, ranging between 8 and 256 MiB, and the page cache is generally all unused main memory. While data in the page cache is reused multiple times, the data in the disk buffer is rarely reused\n 也就是说,对于主存没有直接分配的内存,那么就都是作为page cache存在(注意区分malloc和read)\n也就是说,主存有两个功能,一个是作为进程的存储空间(malloc),一个是作为磁盘的page cache\n所谓的那些零拷贝技术里面常讲的内核缓冲区,其实就是page cache\n","id":9,"section":"posts","summary":"虚拟内存virtual memory 什么是虚拟内存,应该不用多言.本质就是一个逻辑的虚拟地址空间,这些地址空间中,有的地址真正的对应到了物理内存的地址,","tags":null,"title":"[sys] 虚拟内存与缓存缓冲","uri":"https://liwm29.github.io/2021/03/sys-virtmempage-cachebuffer-cache/","year":"2021"},{"content":"UnderTheHood 这里记录一些具有高度总结性质的格言\nPage Cache  主存充当两个功能,一个是进程的存储空间(堆栈),一个磁盘的缓存(page cache)  如此一来,一切都说得通了,我们常说read要从内核缓冲区拷贝到用户缓冲区,你也许和我有一样的疑惑,为什么要先拷贝到内核缓冲区呢?不能直接拷贝到用户缓冲区呢?\n其实,这是属于名词的误用,这个内核缓冲区,其实不是缓冲区,而是磁盘的缓存page cache.当我们读取磁盘时,为了降低缺失率,我们会在内存中缓存磁盘的数据,这称为page cache.大部分未被分配给进程的内存都作为page cache存在.\n因此,这里内核缓冲区到用户缓冲区的拷贝,实际是page cache到用户buffer的拷贝!\n那为什么不直接从磁盘拷贝到用户缓冲区呢?\n 为了缓存  如果是直接拷贝到用户缓冲区,那么同时还要拷贝到page cache上,这是愚蠢的.就像cpu的cache一样,寄存器永远是从cache读数据,而不是从内存读数据,当cache缺失时,会read allocate,从内存拷贝到缓存,再从缓存拷贝到寄存器.这里也是一样的道理,从磁盘buffer拷贝到page cache,再从page cache拷贝到user buffer.(注意到磁盘也是有buffer,常称为disk buffer,是位于磁盘上的内存,用于减少io次数)\n接受接口，返回结构 这是一个go谚语(或Gopherism),我们期望函数能接收抽象的类型,但是返回实际的类型.\n接受接口,这是因为函数内部只需要调用有限的对象的方法,因此我们不期望限定死对象的类别,只要实现了对应的方法即可.\n返回结构,这是因为接口定义了特定的有限的方法集,我们无法访问该结构其他的方法或内置变量,除非type assertion.这降低了用户的可操作性.\n第三方库不应该panic,应该返回错误 ","id":10,"section":"posts","summary":"UnderTheHood 这里记录一些具有高度总结性质的格言 Page Cache 主存充当两个功能,一个是进程的存储空间(堆栈),一个磁盘的缓存(page cache) 如此一来,一切都说得通了,","tags":["underTheHood"],"title":"[underTheHood]  underTheHood","uri":"https://liwm29.github.io/2021/03/aaaunderthehood-underthehood/","year":"2021"},{"content":"kafka1 intro  部分参考\n kafka技术内幕:图文详解kafka源码设计和实现 kafka权威指南 https://zhuanlan.zhihu.com/p/68052232   kafka是一种流式数据处理平台(消息队列的进阶版,即除了完成的消息的转发外,还可以处理消息)\n消息队列的三大功能:\n 异步 解耦 流量削峰  kafka作为流式数据处理平台的三大功能\n 消息队列(消息系统) 数据存储(容错,对等待转发的数据备份到持久化内存) 实时流式处理数据  其中最重要的,应该是解耦这个功能,因为无论是异步还是削峰,一个进程内的并发队列都能做到,每必要独立为一个分布式消息系统服务器.只有解耦,独立成了一个服务器,才能方便的给不同的后端提供服务,比如传统的消费者,比如流量监控程序,比如机器学习数据采集器等等\n 这里,我个人倾向于将producer视作前端,broker视作中端,consumer视作后端\n 原先的架构,监控程序或消费程序,直接与数据生产者打交道,当有各式各样不同的生产者时,又有各式各样不同的消费者时,对应关系将会错综复杂\n于是我们在生产者和消费者之间增加一个用于解耦泛化订阅关系的信息队列,所有的消息统一发忘消息队列,所有的监控程序统一从消息队列取数据(通过订阅不同的topic)\n消息系统 两种常见模型\n 点对点 发布订阅topic  kafka使用消费组(consumer group)的概念,将其合并(消费组之间广播,消费组内部点对点)\n 注意: 消费组是用于负载均衡的,指的是同一个消费组内的消费者是会接收到同一topic的不同消息的,即消息队列虽然会将消息广播给所有订阅它的消费组,但不会将消息广播给同一消费组的所有消费者,而是发送给消费组内的一个消费者(也就是负载均衡),至于发送给哪个消费者,与分区有关,详见后文\n 存储系统 如果收到的消息只是存在于内存中,那么断电后会造成消息丢失.因此,对于还未持久化的数据,不能认定为消息成功被消息队列接收.\n为了保证可靠存储,消息生产者的生产请求应该是停等协议,必须收到消息队列已持久化消息的信息后(ACK),才认为生产成功. 因此生产过程是阻塞的.\n流式处理 对于流式数据平台,仅仅有消息的发布订阅,持久化存储备份是不够的,还要有实时流式处理功能.\n所谓流式处理,可以参照reactiveX这个库,它是一种类似于函数式编程里面常见的处理过程,比如映射,聚合,连接等等\n在实际处理中,由于是网络通信,还可能面临乱序数据等问题\nAPI kafka中有五个核心概念:\n producer consumer broker connector,用于连接数据库,持久化备份,或者读取静态数据进行流处理 processor,进行流处理  kafka实现: 基本概念 分区partition kafka是一个分布式的消息队列,kafka集群由多个消息代理服务器(broker server)组成.\n每个消息都有一个topic,表示消息的类别.每个topic会有多个订阅它的消费组,这个消费组会有多个消费者.当生产者发布消息后,所有的消费组都会收到消息,但是只会发送给消费组内的一个消费者.\nkafka集群为每个topic都维护了一个分布式的分区日志文件(partition),物理意义上,主题可以看作分区的日志文件(partitioned log),这时因为生产者生产的消息会首先作为日志持久化到分区上(类似于redis的append-only file)(事实上,对于这种流式消息的持久化,也只能使用日志形式的追加).每个分区都是一个有序的,不可变的记录序列.分区中的每个消息都会按照到达的时间顺序被分配一个单调递增的偏移量offset,这个偏移量用于定位当前分区的一条消息(你可以想象成数组,偏移量就是下标)\n 当消费者来取消息时,由消费者自己维护消息消费的偏移量\n 在kafka的设计中,每个topic会有多个分区,每个分区唯一匹配该topic对应的各个消费组中的一个消费者. 不同分区之间的偏移量从0开始,独立互不影响.发布到topic的每条消息都包含key-value-timestamp,到达指定分区后都会被分配一个自增的偏移量,并持久化到分区日志文件.\n 每个topic的每个分区都会有副本存在,每个副本都独立位于不同的broker,并且其中一个副本是leader,其他的副本是follower\n写数据只往leader写,然后主从更新,这是常见的读写分离优化. 往往,同一topic的不同partition的leader位于不同的机器上\n 因此,一般的,会将分区数设置为消费组内的消费者数,这样一个消费者唯一对应一个分区.如果以随机策略,那么生产者生产了该topic的消息,随机放在一个分区,然后消费组内与该分区对应的消费者去消费该分区,视为该消费组的消费.\n当分区数与消费者数不等时,要满足一个分区只能对应一个消费者.即当分区数较多时,消费者可以对应多个分区,当分区数较少时,消费组内必然有消费者无对应分区\n 如果多个客户端都期望收到所有的消息,那么它们应该属于不同的消费组,并订阅该topic\n 消息有序性 只有单个分区内才保证消息的有序性,这是指消费该分区的消费者读取处理消息的顺序将总是和分区内的顺序是一致的\n不同分区之间的消息有序性不保证,这是指某个消息虽然后到达某个分区,但却先被对应的消费者消费\n如果想保证某些信息的强有序性,我们需要给该系列消息设置相同的键,使之映射到相同的分区. 或者更极端的,仅设置一个分区.\n磁盘组织 partition就是一个一个的文件夹,每个partition的文件夹下面会有多个segment文件,每个segment文件包含三个文件\n .index文件 .log文件 .timeindex文件  前面我们说了,message是以partition log的方式作为aof持久化的,所以消息其实存在.log文件中,,index文件和.timeindex文件是顾名思义的,都是索引文件\nTODO: 具体的方式涉及持久化那章,目前还没找到完整的书,待更\n生产模式 同一topic的不同partition之间是一层负载均衡,同一消费组的消费者之间也是一层负载均衡\n对于生产者,它需要决定将消息写到对应topic的哪个分区,比如可以使用随机,轮询,平滑加权平均,一致性hash等手段(也就是rpc框架里的路由算法,也就是负载均衡算法). 当它确定了分区后,便去查询该分区对应的leader所属的broker,因为只有leader可写.\n前面说过,生产者生产消息是一个阻塞的过程,需要收到消息队列(也就是broker)的ack. 实际上,有三种生产模式\n按照如下图的工作流程:\n 生产者可以在2后直接返回(完全异步) 生产者可以在3后直接返回(阻塞,主持久化) 生产者可以在6后直接返回(阻塞,主从同步持久化)  消费模型 消息的消费模式有两种:\n 推送push 拉取pull  如果使用推送模式,则会增加broker消息代理服务器的负担,这是因为服务器应该为每个消息都记录消费状态,只要当收到消费者返回的ACK后,服务器才能有信心的将消息状态置为已消费,而在broker中,消息是大量的,维护这些状态的负担是较大的.此外,不同消费者消费的进度是不同的,需要额外存储各个消费者的进度.\n简单来看,broker需要记录:\n 消息状态,是否已消费(比如,是否已被所有订阅的消费组消费) 不同消费者的消费进度(offset) 不同消费者的消费速率和broker的推送速率要对等  于是,Kafka采用拉取模型,有消费者自己记录消费状态,此时,消息是无状态的,broker不需要记录消息是否被处理过(但为了方便,其实还是会记录,这里只是说不记录也不影响主要功能).每个消费者独立且顺序的读取与自己相对应的那些分区的消息(典型情况下,分区与消费者是一对一的)\n此时,由消费者自己维护的消息状态,其实是一个指针或偏移量offset,记录自己下一个要消费的位置.生产者最新写入的消息对消费者是不可见的,必须备份后才会更新watermark(最高水位),watermark存在的意义即是限制消费者的消费(颇有点len和cap的感觉).\n简单来看,customer需要记录:\n 消费进度offset   这里的备份详见后文的副本与容灾,简单来说就是一个消息只有被所有从副本同步后(称为消息的提交),才能够被消费者看见从而消费,表现上就是watermark的增加\n  事实上,也可能同时将offset记录在zk上,以确保消费者的宕机不会丢失消费记录位置\n kafka不会像有些消息队列一样,当消息被所有消费组消费后,就立马删掉消息.而是会将生产者发布的所有消息保存在kafka集群,无论消费者是否已经消费.用户需要设置保留时间来清理过期数据.\n这样的一个好处是,消费者可以通过更改自己的offset来消费以前的消息.(比如消费者逻辑出错,导致的回滚)\n分布式模型 这里的分布式模型,也就是主从模型. 一个topic的不同partition在不同的broker上都将维护一个同样的副本.其中一个节点作为leader(主副本),其他节点作为follower(从副本).读写操作都只会打到leader上,当leader故障时,某个follower晋升为leader.\n 不是读写分离,而是读写都施加到leader上.\n一个topic不同的partition在同一台broker上,有的是leader,有的是follower,有效减轻了一台broker的负担\n 单个broker可以处理数千个分区和每秒百万级别的消息量\n分区路由 生产者需要自己决定将消息发送到哪个分区,然后再去寻找该分区的leader所在的broker的ip\n当消息没有键时,将采用轮询的方式;当消息有键时,将通过某种手段将相同的键发到相同的分区(很显然,一种hash方法)\n每个broker将会保存一份关于主题分区leader的metadata(元数据),这样就不需要一个统一的服务注册中心了. 生产者在生产消息之前,首先向任意一个broker申请元数据,以此确定每条消息的目的地\n 这里似乎表述有误,虽然原文说是每个broker维护一份metadata,但是其他地方又说是zookeeper作为统一的注册中心维护一份metadata,我个人倾向于是zk维护,代价低\n 副本与容错 不同分区的主副本应该均匀地分配到各个服务器上,在主从同步上,从副本同步消息的过程和消费者消费消息的过程是一致的,只不过从副本会将消息写到自己的分区日志文件.\n节点存活 节点存活必须满足两个条件:\n 节点与zookeeper保持会话 节点作为备份副本时,其备份进度不能落后主副本太多  此时,称其状态为in-sync,这些节点的集合为ISR(in-sync-replicas).\n如果一个副本挂掉,没有响应或备份进度落后太多,那么主副本就会将其从ISR中移出,直到该从从副本赶上备份进度\n消息提交 一个消息只有被ISR中的所有broker都持久化到本地的分区日志文件后,才被认为消息提交.只有消息被提交后,才能被消费者消费.如此而来,对消费者来说,消息是永不丢失的.\n如果新生产的消息能立即被消费者看见,那么如果主副本宕机了,这些消息到底有没有被成功消费呢?如果没有,就需要生产者重新生产一份,这增加了很多额外的成本.不如直接设计成只有消息提交了才算生产成功\n优化技术 零拷贝技术 显然,消息已经被持久化到了磁盘上,从磁盘上读取文件发送到消费者处,需要使用send_file,避免从内核态到用户态的拷贝与切换.\n批量生产 在某些实时性要求不强(实际上,超时时间是极短)的任务中,生产者可以先尝试在内存中收集足够的数据,然后在一次请求中一次性发送一批消息(并会设置一个超时时间)\n比如: 消息大小达到64B,就立刻发送,否则100ms后也立刻发送\n批量消费 消费者理所当然的也可以一次接收一批数据,但是如果partition中消息数量不够呢?\n消费者需要不断轮询broker(这时拉取式的缺点),解决方法是允许拉取请求是阻塞式,长轮询的,直到有足够的一批数据.\n为什么选择kafka  支持消费组的概念,一个消息只会被一个消费组消费一次 partition的概念,并发度较高 消息默认持久化,可消费历史消息 可伸缩性,轻松拓展broker数量  使用场景  用户行为跟踪  前端会将用户的行为,比如页面点击量等,作为消息发送到消息中心   传统的传递业务消息 度量指标  也就是监控,收集系统度量指标   提交日志  将数据库的更新发布到kafka上,应用程序订阅特定topic来实时同步   流处理   下一章: kafka2 生产者\n","id":11,"section":"posts","summary":"kafka1 intro 部分参考 kafka技术内幕:图文详解kafka源码设计和实现 kafka权威指南 https://zhuanlan.zhihu.com/p/68052232 kafka是一种流式数据处理平台(消息队列的进阶版,即除","tags":null,"title":"[mq] kafka1 intro","uri":"https://liwm29.github.io/2021/03/mq-kafka1-intro/","year":"2021"},{"content":"列举我心目中的go的优点  实现开源,源代码可以很方便的通过代码跳转去追踪,而不像c/c++都是链接库,或者只能追踪到头文件 现代的包管理go get/go mod,类似pip一样方便的包安装,但是也有很多不足,经常被人诟病  但就我个人使用上,感觉还是比较方便   类,结构与方法分离. 这在阅读源代码时很方便清爽,不必被各种inline函数搞得眼花缭乱  虽然go严格并没有类的概念   方便的方法函数拓展,只需要新写一个方法即可,不需要改动任何原来的代码 简洁的语法,不必把时间花费在底层理解上,但这也导致了无法极度的优化,不过相信大多数程序员都没有那么强,仍然利大于弊,不同的语言用来解决不同领域的问题 go的文档是直接放在一页的,直接ctrf-f搜索,很方便 待更  ","id":12,"section":"posts","summary":"列举我心目中的go的优点 实现开源,源代码可以很方便的通过代码跳转去追踪,而不像c/c++都是链接库,或者只能追踪到头文件 现代的包管理go get/go m","tags":["go","other"],"title":"[Other] Go优点","uri":"https://liwm29.github.io/2021/03/other-go%E4%BC%98%E7%82%B9/","year":"2021"},{"content":"字节二面  算法题: 二叉树中的最长距离  又拉跨了,太久没做题了,做了很久   并发和并行的区别 讲讲go的协程调度  GMP模型,balabala讲一堆,提到了netpoller,触发linux io复用剧情 讲到了steal机制,面试官问我为什么在全局队列未空的时候要去steal呢?  回答,应该不会吧,毕竟其他p的g可能不在一个核上,会增加cahce缺失率     讲讲linux的io复用  select/poll/epoll   select和epoll的区别  说了些常见的,比如select用链表不限制fd个数,但是触发后要遍历所有fd,epoll只需要遍历已经激活的fd,数组的前n个 似乎不是面试官想要的,让我回去再看看   提到epoll只返回激活的fd的个数,问我怎么设计这个数据结构  其实没搞懂想问什么,于是我balabal扯了一堆   讲讲docker  一种linux容器 虚拟化,轻量级,隔离 dockerfile可以很方便的构建容器镜像   讲讲TCP的分包  tcp是面向流的协议 基于长度 基于分隔符   分隔符和内容冲突了怎么办?  转义  这里可以参考http协议,使用\\r\\n来分隔,对于body,会使用base64编码转义成文本字符,header和body之间有两个\\r\\n来区分   配对  比如json,xml这种,但显然面临注入的风险,也要转义   定长  对于简单的报文,直接定长即可     看我实验室的经历,问我知道哪些机器学习算法  讲了些简单的   怎么对垃圾邮件分类  首先肯定是要特征工程,将邮件编码为欧氏空间中的一个点(向量,embedding),然后就是加标签之类的,丢到算法里面fit参数,我只懂些皮毛   问我svm怎么分类  没搞懂要问什么,以为要讲原理,我说一个分类间隔,支持向量啥啥啥的,反正我不懂,瞎扯一堆 最后说只需要怎么使用  那不是直接丢进去fit参数就行了嘛,重点在特征工程,分词那些吧,没搞懂面试官的逻辑     其他,忘了,暂时只想起来这么多  ","id":13,"section":"posts","summary":"字节二面 算法题: 二叉树中的最长距离 又拉跨了,太久没做题了,做了很久 并发和并行的区别 讲讲go的协程调度 GMP模型,balabala讲一堆,提到","tags":["interview","ByteDance"],"title":"[interview] ByteDance2","uri":"https://liwm29.github.io/2021/03/interview-bytedance2/","year":"2021"},{"content":"grpc grpc是一种rpc框架,先不管其实现或特点.首先我们明确,不管是什么rpc框架,其最终目标都是让用户能够在应用层轻松的调用远程的函数,就像在本机上调用一样.\n如果你还不知道这个,请移步另一个文章[rpc] intro,以及[rpc] net-rpc\ngRPC是Google公司基于Protobuf开发的跨语言的开源RPC框架。gRPC基于HTTP/2协议设计，可以基于一个HTTP/2链接提供多个服务，对于移动设备更加友好\ndesc 很明显了,grpc使用protobuf作为序列化协议,基于http/2作为通信协议\n","id":14,"section":"posts","summary":"grpc grpc是一种rpc框架,先不管其实现或特点.首先我们明确,不管是什么rpc框架,其最终目标都是让用户能够在应用层轻松的调用远程的函数,就","tags":["rpc"],"title":"[rpc] grpc","uri":"https://liwm29.github.io/2021/03/rpc-grpc/","year":"2021"},{"content":"什么是RPC? rpc: remote procedure call,顾名思义,指的就是远程过程调用,在大多数语境下,过程指的都是函数\n在传统的单体服务中,所有的函数都写在一个进程映像里,我们调用函数只需要跳转到对应的代码段即可.\n但是单体服务已经注定是不可行的了,解耦是永恒的话题.操作系统已经从传统的宏内核演变成微内核,原先非必要的函数都以服务的形式作为进程运行在主机上.\n随着互联网的发展,微服务也逐渐大放光彩.在同一主机上不同的服务可以通过各种各样的ipc手段进行通信,但在web领域,位于不同主机的服务之间只能通过网络通信.\n事实上,网络过程中的通信是复杂的,但我们仍然希望远程过程调用就像原来本机单进程内的函数调用一样简单,那么那些底层复杂的一些操作有谁来完成呢?\n这就是rpc框架提供的封装,在用户层,我们只需要使用简单的call(),即可在客户端调用服务端的函数,并可以根据不同期望选择同步或异步调用方式.至于底层的协议,序列化,路由,限流,熔断,降级等操作,都被rpc框架隐藏了.\nRPC严格来说不是一个协议,它代表的只是一种风格,即调用远程函数来完成本地任务的这种风格,其底层使用的网络协议,可以是自研的,那么就可以称之为rpc协议,但实际上,也完全可以承载在现有的应用层协议上,比如HTTP. 本质上,你只需要让服务端知道你要调用哪个函数即可,通信协议只是手段,不是目的\n关于rpc框架 如果想了解rpc框架需要哪些功能,可以看我的rpc系列的另一篇文章: [rpc] rpcx\n也可以看看 [rpc] grpc和 [rpc] net-rpc, 分别介绍了内置的rpc框架和google的grpc\n","id":15,"section":"posts","summary":"什么是RPC? rpc: remote procedure call,顾名思义,指的就是远程过程调用,在大多数语境下,过程指的都是函数 在传统的单体服务中,所有的函数都写在一个进程映","tags":["rpc"],"title":"[rpc] intro","uri":"https://liwm29.github.io/2021/03/rpc-intro/","year":"2021"},{"content":"net/rpc 如下是一段极简的net/rpc代码, client.Call()代表这是一个同步的rpc,如果是异步,net/rpc提供了client.Go()方法,典型的实现是返回一个chan,当异步完成时,这个chan就会读出消息(当然,net/rpc的Go()不是完全这样实现的,但也差不多)\n示例代码 package main\rimport (\r\u0026quot;fmt\u0026quot;\r\u0026quot;net\u0026quot;\r\u0026quot;net/rpc\u0026quot;\r\u0026quot;time\u0026quot;\r)\rtype ServiceA struct{}\rfunc (a *ServiceA) A(req int, reply *int) error {\rfmt.Println(\u0026quot;server recv:\u0026quot;, req)\r*reply = 2\rreturn nil\r}\rfunc server() {\rls, err := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;:9090\u0026quot;)\rif err != nil {\rpanic(err)\r}\rrpc.Register(new(ServiceA))\rfor {\rrpc.Accept(ls)\r}\r}\rfunc main() {\rgo server()\rtime.Sleep(1 * time.Second)\rclient, err := rpc.Dial(\u0026quot;tcp\u0026quot;, \u0026quot;:9090\u0026quot;)\rif err != nil {\rpanic(err)\r}\rvar ax int\rerr = client.Call(\u0026quot;ServiceA.A\u0026quot;, 1, \u0026amp;ax)\rif err != nil {\rpanic(err)\r}\rfmt.Println(\u0026quot;client: recv:\u0026quot;, ax)\r}\r 服务注册 通过rpc.Register()注册某个对象,该对象的所有导出方法都会被识别\n事实上,一个过程需要满足下面的条件才能被成功注册:\n 对象是导出的 对象的方法是导出 该方法只接受两个参数并返回error,一个是请求参数,一个是返回值,其中第二个reply应该是指针的形式.  rpc.Register(new(ServiceA))\r// 或\rrpc.Register(\u0026amp;ServiceA{})\r 服务调用 通过类名+方法名来调用函数\nerr = client.Call(\u0026quot;ServiceA.A\u0026quot;, 1, \u0026amp;ax)\r 编解码 net/rpc使用了gob作为编解码器\n在使用时屏蔽了所有底层的输入输出,简单的encode,decode即可还原出想要的结构体,完全不需要在意分包之类的细节\ntype gobClientCodec struct {\rrwc io.ReadWriteCloser\rdec *gob.Decoder\renc *gob.Encoder\rencBuf *bufio.Writer\r}\rcodec := \u0026amp;gobClientCodec{conn, gob.NewDecoder(conn), gob.NewEncoder(encBuf), encBuf}\rfunc (c *gobClientCodec) WriteRequest(r *Request, body interface{}) (err error) {\rif err = c.enc.Encode(r); err != nil {\rreturn\r}\rif err = c.enc.Encode(body); err != nil {\rreturn\r}\rreturn c.encBuf.Flush()\r}\rfunc (c *gobClientCodec) ReadResponseHeader(r *Response) error {\rreturn c.dec.Decode(r)\r}\rfunc (c *gobClientCodec) ReadResponseBody(body interface{}) error {\rreturn c.dec.Decode(body)\r}\r 通信机制 net/rpc并没有采用典型的一个req一个resp的形式,而是在创建client时,就开启一个goroutine去监听recvbuff,对读到数据包,解析出其中的一个seq字段,用来和当初的req对应,因此,当发送rpc请求的时候,字段会包含seq\n本机使用一个map来存储映射关系,Call 结构体就代表一个调用过程,实际上调用Go()方法的异步调用就会返回/*Call,我们需要判断call.Done来识别调用的完成\npending map[uint64]*Call\rtype Call struct {\rServiceMethod string // The name of the service and method to call.\rArgs interface{} // The argument to the function (*struct).\rReply interface{} // The reply from the function (*struct).\rError error // After completion, the error status.\rDone chan *Call // Receives *Call when Go is complete.\r}\r 数据结构 type Request struct {\rServiceMethod string // format: \u0026quot;Service.Method\u0026quot;\rSeq uint64 // sequence number chosen by client\rnext *Request // for free list in Server\r}\rtype Response struct {\rServiceMethod string // echoes that of the Request\rSeq uint64 // echoes that of the request\rError string // error, if any.\rnext *Response // for free list in Server\r}\r 发送 err := client.codec.WriteRequest(\u0026amp;client.request, call.Args)\r 接收 response = Response{}\rerr = client.codec.ReadResponseHeader(\u0026amp;response)\rcall := client.pending[response.Seq]\rerr = client.codec.ReadResponseBody(call.Reply)\rcall.Done \u0026lt;- call\r func (client *Client) Call(serviceMethod string, args interface{}, reply interface{}) error {\rcall := \u0026lt;-client.Go(serviceMethod, args, reply, make(chan *Call, 1)).Done\rreturn call.Error\r}\r ","id":16,"section":"posts","summary":"net/rpc 如下是一段极简的net/rpc代码, client.Call()代表这是一个同步的rpc,如果是异步,net/rpc提供了client.Go","tags":["rpc"],"title":"[rpc] net/rpc","uri":"https://liwm29.github.io/2021/03/rpc-net-rpc/","year":"2021"},{"content":"Buddy system linux底层使用buddy-system+slab\n slab位于buddy-system的上层\n 伙伴系统是一种基于二分的动态分区算法,一开始他有k大小的空间,当有新的内存申请到达时,他会对k进行二分,直到满足那个大小恰好是最合适的大小时,返回给用户.比如,申请18KB内存,伙伴系统最初是128KB,那么会一直二分成32KB,16KB,发现16\u0026lt;18,所以返回给用户32KB的大小,这造成了很大的内部碎片\n伙伴系统的合并机制只能合并由同一个区块分裂的子区块,对于相邻的由不同区块分裂的子区块,不能合并\n ref\nIn a buddy system, the entire memory space available for allocation is initially treated as a single block whose size is a power of 2. When the first request is made, if its size is greater than half of the initial block then the entire block is allocated. Otherwise, the block is split in two equal companion buddies. If the size of the request is greater than half of one of the buddies, then allocate one to it. Otherwise,one of the buddies is split in half again. This method continues until the smallest block greater than or equal to the size of the request is found and allocated to it\nIn this method, when a process terminates the buddy block that was allocated to it is freed. Whenever possible, an unmallocated buddy is merged with a companion buddy in order to form a larger free block. Two blocks are said to be companion buddies if they resulted from the split of the same direct parent block.\n 这里,A=70K代表分配A, A ends代表回收A\n如何实现 逻辑很清楚了,现在的问题是怎么去记录哪些区块是分配了的,哪些是没分配的呢?\n如果单纯的是一个内存池的话,我们可以直接再申请一个内存空间去存储bitmap,来代表分配回收情况. 当然也可以直接在这片内存上划出一个区域放置bitmap\n但bitmap只适合固定分区的情况,对于动态分区,还要维护分区的大小\n from wiki\nTypically the buddy memory allocation system is implemented with the use of a binary tree to represent used or unused split memory blocks. The \u0026ldquo;buddy\u0026rdquo; of each block can be found with an exclusive OR of the block\u0026rsquo;s address and the block\u0026rsquo;s size.\n 建议阅读:\n https://people.kth.se/~johanmon/ose/assignments/buddy.pdf https://www.cs.au.dk/~gerth/papers/actainformatica05.pdf  find buddy 我们知道,每一个区块都有一个唯一的buddy(伙伴),并且有一个很快速的方法可以得到其伙伴的首地址\n如果一个区块a大小是2^k,首地址是\u0026amp;a,那么它的伙伴就一定是\u0026amp;a+2^k或\u0026amp;a-2^k,因为伙伴之间的大小一定是相等的.\n\u0026amp;a+2^k或\u0026amp;a-2^k,等价于直接flip(\u0026amp;a,k+1),翻转第k+1位(从右边开始数,从1开始计数)[前提是一定的内存对齐条件]\n隐式free-list 所谓的隐式free-list,指的是node不维护指针,而只维护自己的大小,由于内存的连续性,自己的首地址+大小,便找到了下一个node,每个node有一个标志位决定其是否已被分配\n显式free-list 隐式free-list的缺点是我们要遍历所有的node去寻找未分配的node\n显式free-list则显式的使用指针作为其头部字段,将所有的未分配的node连在一起\n变长分配 现在我们认为一个free-list就存储一个特定大小的node的节点集合,对于不同的大小,我们使用不同的free-list\n对于每个内存区域区块的大小,我们预先定义好,但是并不是按2的n次幂 ,因为这样会造成严重的内部碎片(比如需要65,却分配了128)\n因此,free-list其实是某种静态分配策略,而buddy则是半动态的\n","id":17,"section":"posts","summary":"Buddy system linux底层使用buddy-system+slab slab位于buddy-system的上层 伙伴系统是一种基于二分的动态分区算法,一开","tags":["mem"],"title":"[mem] Buddy system","uri":"https://liwm29.github.io/2021/03/mem-buddyfreelist/","year":"2021"},{"content":"TCMalloc thread-caching malloc\n顾名思义,这个malloc算法是与thread有关的,直观理解上,就是每个thread单独维护一个内存池,这样,各个thread之间的malloc操作就不会相互造成锁的竞争了\n不同的malloc算法,就是不同的内存池算法,一是为了减少从os申请内存的次数,二也要增加分配给用户的速度\n 但是注意,os本身其实也有不同的内存分配算法\n Prerequisite 要了解比较高阶的tcmalloc,我们首先要知道传统的内存分配算法,比如伙伴关系,slab,隐式free-list,显式free-list等(slab应该也是一种free-list),基于bitmap的等等\n可以看看这个回答, 这个答主给出了从简单到复杂的内存池设计\nTCMalloc 实际上,官网的文档已经讲的相对很清楚了: tcmalloc\n实现细节 重命名 #define TCMALLOC_ALIAS(tc_fn) \\ __attribute__((alias(#tc_fn), visibility(\u0026quot;default\u0026quot;))) extern \u0026quot;C\u0026quot; { void* malloc(size_t size) noexcept TCMALLOC_ALIAS(TCMallocInternalMalloc); void free(void* ptr) noexcept TCMALLOC_ALIAS(TCMallocInternalFree); }  alias可用于完成的函数调用的重命名,此时,调用malloc,将会重定向到TCMallocInternalMalloc\n但是__attribute__((alias(...)))是gcc的拓展,对于其他编译器,最差的情况也不过是覆盖掉这个weak symbol而已(也就是重定义redefine)\n 只有弱符号才可被覆盖,如果是强符号(一般的函数名),则会panic报错函数重定义\n extern \u0026quot;C\u0026quot; { void* malloc(size_t s) noexcept { return TCMallocInternalMalloc(s); } void free(void* p) noexcept { TCMallocInternalFree(p); } }  对于不同的libc,有不同的实现,甚至对不同的编译器,操作系统都有不同的实现:\n // Every libc has its own way of doing this, and sometimes the compiler\n// matters too, so we have a different file for each libc, and often\n// for different compilers and OS\u0026rsquo;s.\n 我们常用的是glibc+gcc,也就是都属于gnu\nTCMallocInternalMalloc extern \u0026quot;C\u0026quot; ABSL_CACHELINE_ALIGNED void* TCMallocInternalMalloc( size_t size) noexcept { // Use TCMallocInternalMemalign to avoid requiring size % // alignof(std::max_align_t) == 0. TCMallocInternalAlignedAlloc enforces this // property. return TCMallocInternalMemalign(alignof(std::max_align_t), size); } extern \u0026quot;C\u0026quot; void* TCMallocInternalMemalign(size_t align, size_t size) noexcept { ASSERT(absl::has_single_bit(align)); return fast_alloc(MallocPolicy().AlignAs(align), size); }  fast_alloc template \u0026lt;typename Policy, typename CapacityPtr = std::nullptr_t\u0026gt; static inline void* ABSL_ATTRIBUTE_ALWAYS_INLINE fast_alloc(Policy policy, size_t size, CapacityPtr capacity = nullptr) { // If size is larger than kMaxSize, it's not fast-path anymore. In // such case, GetSizeClass will return false, and we'll delegate to the slow // path. If malloc is not yet initialized, we may end up with cl == 0 // (regardless of size), but in this case should also delegate to the slow // path by the fast path check further down. uint32_t cl; bool is_small = Static::sizemap().GetSizeClass(size, policy.align(), \u0026amp;cl); if (ABSL_PREDICT_FALSE(!is_small)) { return slow_alloc(policy, size, capacity); } // When using per-thread caches, we have to check for the presence of the // cache for this thread before we try to sample, as slow_alloc will // also try to sample the allocation. #ifdef TCMALLOC_DEPRECATED_PERTHREAD ThreadCache* const cache = ThreadCache::GetCacheIfPresent(); if (ABSL_PREDICT_FALSE(cache == nullptr)) { return slow_alloc(policy, size, capacity); } #endif // TryRecordAllocationFast() returns true if no extra logic is required, e.g.: // - this allocation does not need to be sampled // - no new/delete hooks need to be invoked // - no need to initialize thread globals, data or caches. // The method updates 'bytes until next sample' thread sampler counters. if (ABSL_PREDICT_FALSE(!GetThreadSampler()-\u0026gt;TryRecordAllocationFast(size))) { return slow_alloc(policy, size, capacity); } // Fast path implementation for allocating small size memory. // This code should only be reached if all of the below conditions are met: // - the size does not exceed the maximum size (size class \u0026gt; 0) // - cpu / thread cache data has been initialized. // - the allocation is not subject to sampling / gwp-asan. // - no new/delete hook is installed and required to be called. ASSERT(cl != 0); void* ret; #ifndef TCMALLOC_DEPRECATED_PERTHREAD // The CPU cache should be ready. ret = Static::cpu_cache().Allocate\u0026lt;Policy::handle_oom\u0026gt;(cl); #else // !defined(TCMALLOC_DEPRECATED_PERTHREAD) // The ThreadCache should be ready. ASSERT(cache != nullptr); ret = cache-\u0026gt;Allocate\u0026lt;Policy::handle_oom\u0026gt;(cl); #endif // TCMALLOC_DEPRECATED_PERTHREAD if (!Policy::can_return_nullptr()) { ASSUME(ret != nullptr); } SetClassCapacity(ret, cl, capacity); return ret; }  略复杂,没看懂\nSlab class TcmallocSlab { public: struct Slabs { std::atomic\u0026lt;int64_t\u0026gt; header[NumClasses]; void* mem[((1ul \u0026lt;\u0026lt; Shift) - sizeof(header)) / sizeof(void*)]; }; private: struct Header { // All values are word offsets from per-CPU region start. // The array is [begin, end). uint16_t current; // Copy of end. Updated by Shrink/Grow, but is not overwritten by Drain. uint16_t end_copy; // Lock updates only begin and end with a 32-bit write. uint16_t begin; uint16_t end; // Lock is used by Drain to stop concurrent mutations of the Header. // Lock sets begin to 0xffff and end to 0, which makes Push and Pop fail // regardless of current value. bool IsLocked() const; void Lock(); }; Slabs* slabs_ = nullptr; }  算了,折磨人\n","id":18,"section":"posts","summary":"TCMalloc thread-caching malloc 顾名思义,这个malloc算法是与thread有关的,直观理解上,就是每个thread单独维护一个内存池,这样,各个thread之间的","tags":["mem"],"title":"[mem] tcmalloc","uri":"https://liwm29.github.io/2021/03/mem-tcmalloc/","year":"2021"},{"content":"排序算法 稳定性 假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]=r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的\n堆排序、快速排序、希尔排序、直接选择排序是不稳定的排序算法\n基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序是稳定的排序算法\n快排 package main\rimport (\r\u0026quot;fmt\u0026quot;\r\u0026quot;math/rand\u0026quot;\r\u0026quot;reflect\u0026quot;\r\u0026quot;sort\u0026quot;\r)\rfunc swap(a []int, i, j int) {\ra[i], a[j] = a[j], a[i]\r}\rfunc partition(a []int) int {\rr := rand.Int() % len(a)\rswap(a, r, len(a)-1)\r// j指针遍历数组a\r// i指针 a[:i]均是比a[len(a)-1]小的数\ri, j := 0, 0\rfor j \u0026lt; len(a)-1 {\rif a[j] \u0026lt; a[len(a)-1] {\rswap(a, i, j)\ri++\r}\rj++\r}\rswap(a, i, len(a)-1)\rreturn i\r}\rfunc qsort(a []int) {\rif len(a) == 0 {\rreturn\r}\rmid := partition(a)\rqsort(a[:mid])\rqsort(a[mid+1:])\r}\rfunc main() {\ra := []int{rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int()}\rb := make([]int, len(a))\rcopy(b, a)\rsort.Ints(a)\rqsort(b)\rfmt.Println(reflect.DeepEqual(a, b))\r}\r 归并 // 此处其实可以充分利用a,b的有序性\rfunc merge(a, b []int) {\rlen := len(a) + len(b)\ra = a[:len]\rqsort(a) }\rfunc msort(a []int) {\rif len(a) == 0 || len(a) == 1{\rreturn }\rleft := a[:len(a)/2]\rright := a[len(a)/2:]\rmsort(left)\rmsort(right)\rmerge(left, right)\r}\r ","id":19,"section":"posts","summary":"排序算法 稳定性 假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]=r[","tags":["alg"],"title":"[alg] sort","uri":"https://liwm29.github.io/2021/03/alg-sort/","year":"2021"},{"content":"设计模式 聊聊我熟悉的设计模式\n首先,推荐一下这门课: https://time.geekbang.org/column/intro/100039001\n我看了目录,确实很有吸引力,可惜太贵了:(\n创建型 用于创建类型\n单例 单例模式常用于创建全局唯一变量,大多数时候都增加了耦合,降低了可测试性\n直接使用sync.Once,只调用一次是由once变量保证的\ntype Once struct {\rdone uint32\rm Mutex\r}\r 使用示例:\npackage singleton\rvar (\ronce sync.Once\rGlobalStatus map[string]string\r)\rfunc New() singleton {\ronce.Do(func() {\rGlobalStatus = make(map[string]string)\r})\rreturn GlobalStatus\r}\r 实现:\nfunc (o *Once) Do(f func()) {\r// Note: Here is an incorrect implementation of Do:\r//\tif atomic.CompareAndSwapUint32(\u0026amp;o.done, 0, 1) {\r//\tf()\r//\t}\rif atomic.LoadUint32(\u0026amp;o.done) == 0 {\ro.doSlow(f)\r}\r}\rfunc (o *Once) doSlow(f func()) {\ro.m.Lock()\rdefer o.m.Unlock()\rif o.done == 0 {\rdefer atomic.StoreUint32(\u0026amp;o.done, 1)\rf()\r}\r}\r  注释说的很清楚,一个简单的CAS是不行的!\n我们必须在f()调用完后,再将o.done置位\n   工厂 以根据不同的文件名后缀创建不同的解析器为例\n简单工厂 直接根据不同的后缀,返回不同的解析器实例\n工厂方法 直接根据不同的后缀,返回不同的解析器工厂,由该工厂去创建解析器实例\n实现上,一般用map存各个解析器工厂\n 好处: 如果要添加新的解析器,只需要在map中添加即可,而不需要改变逻辑代码\n 抽象工厂 直接根据不同的后缀,返回不同的解析器工厂,该解析器工厂可以创建不同类的解析器\n 即不仅是不同类产品,同类产品本身也有区别\n比如解析器,分为json parser,xml parser\u0026hellip; 对于json parser本身,还分为fast json parser, portable json parser..等\n ","id":20,"section":"posts","summary":"设计模式 聊聊我熟悉的设计模式 首先,推荐一下这门课: https://time.geekbang.org/column/intro/100039001 我看了目录,确实很有吸引力,可惜太贵了:( 创建型 用于创建类型 单例 单例模式常用于创建全局唯","tags":["arch"],"title":"[arch] design pattern","uri":"https://liwm29.github.io/2021/03/arch-design-pattern/","year":"2021"},{"content":"总结一下在c语言中遇到的诸多Tricks 柔性数组 一个典型的柔性数组如下所示,数组本身是不占空间的\nstruct skipnode {\rint key;\rint value;\rstruct sk_link link[0];\r};\rstruct skipnode *node = malloc(sizeof(*node) + level * sizeof(struct sk_link));\r 关于柔性数组也可以看看redis的sds,也是用这个数组实现的\n搭配Union 柔性数组也可以搭配Union联合体\nunion node {\rnode* next;\rchar data[0];\r};\r 这样,这个node既可以充当链表节点,指向下一个链表. 也可以使用data指向malloc后的分配的内存.\n从成员还原出首地址 本质是我们需要知道偏移量,但我们不可能知道,这时可以借助编译器帮我们计算\n完整代码是:\n#define list_entry(ptr, type, member) \\\r((type *)((char *)(ptr) - (size_t)(\u0026amp;((type *)0)-\u0026gt;member)))\r 首先计算偏移量\noffset = (size_t)(\u0026amp;(((type *)0)-\u0026gt;member)))\r ((type *)0表示将地址0解释为type类型,然后取出member,这自然的其内存地址就是相较于0的偏移,对其取值后转换成size_t,则就是字节偏移了\n本质上等同于\noffset = (size_t)(\u0026amp;(((type *)123)-\u0026gt;member))-123)\r void*泛型 \u0026hellip;\n","id":21,"section":"posts","summary":"总结一下在c语言中遇到的诸多Tricks 柔性数组 一个典型的柔性数组如下所示,数组本身是不占空间的 struct skipnode { int key; int value; struct sk_link link[0]; }; struct skipnode *node = malloc(sizeof(*node) + level * sizeof(struct sk_link)); 关","tags":["c"],"title":"[c] trick1","uri":"https://liwm29.github.io/2021/03/c-trick1/","year":"2021"},{"content":"应用层缓存 通常我们不希望所有数据的请求都去查询数据库,这一方面是慢,另一方面对数据库的压力也大.\n因此,类似硬件层面的缓存,我们在应用层也会使用in-memory cache\n 通常,我们使用redis,或mongoDB,memcached等\n 缓存虽好,但也面临着一些问题,比如缓存穿透,缓存击穿,缓存雪崩\n缓存穿透 如果某些请求一直查询一些不存在的数据,那么将会大幅提高缓存缺失率,这些请求将会去数据库查询,增加数据库压力,但是由于这些数据是不存在的,所以这是一次无用功,平白无故的增加了数据库压力,我们需要对其优化\n 一般的, cpu缓存命中率可达90%以上\n  所谓穿透,就是指缓存缺失了,请求穿透了缓存达到数据库\n 白名单: 布隆过滤器  布隆过滤器可以用于检索一个元素是否在一个集合中。布隆过滤器存储空间和插入/查询时间都是常数 O(K)\n 布隆过滤器是基础结构是一个较大的bitmap\n 插入: 对输入,通过K个散列函数,映射到k个bit上,置为1 查询: 对输入,通过k个散列函数,映射到k个bit上,若这k个bit均为1,则判定为存在,否则判定为不存在  它使用了多个hash函数,这是与普通的哈希表的差别,目的是为了降低hash冲突,如果一个hash函数的冲突率是0.5,那k个hash函数的冲突率就是(0.5)^k,很可观\n 但显然,这无法保证不发生冲突. 而且,其他键的hash值和自己的的hash值是存在交集的,所以这导致了布隆过滤器的特性: 存在误判率(只会误判为存在)\n  一般的缓存就是一个动态hash表\n 如果误判,则必定是认为数据存在,然后去查找缓存,查找数据库,这是可以忍受的,因为这种误判不会使得服务提供差错,而只是增加延时\n 如果是将存在的误判为不存在,则千万不可使用,否则就相当于拒绝服务了\n我们倾向于有损服务,而不是不服务\n 黑名单: 缓存空结果 除了在缓存前,再前置一个过滤器,还可以当在数据库中查询到空结果时,重新设置缓存(read allocate).\n但是一般的,这个缓存的过期时间要比较短,毕竟你无法知道这个数据是否真的马上被创建了\n但显然,这种方法有着很大的缺陷,它相当于每查询一次设置一个黑名单,我们无法阻止恶意的用户持续的进行查询不存在数据的攻击(这也算一种dos攻击),\n缓存击穿 某个热点数据在某个时间点过期,但这时有大量的请求打过来,由于缓存缺失,全部穿透到数据库\n 为什么会过期? 这里先假设过期时间是不实时更新的,过期时间仅在第一次读时设置\n SETNX  SET if Not eXists\n 这就是类似一个cas(compare and swap)原子指令,我们知道击穿的痛点在于突然大量对同一数据的请求达到数据库,那么我们可以不让这些请求同时达到数据库,由于是对同一数据的请求,我们可以在缓存层面设计,当第一个请求没查到数据时,用SETNX新建一个与key唯一相关的key_mutex键,置1,这样后续的请求如果未读到缓存,再去读这个key_mutex,读到了1,就会自旋或阻塞或睡眠,一般让其睡眠50ms就好,或者将key_mutex的value设成一个semaphore,让线程在这个信号量上阻塞,但很显然,调度的时间应该超过50ms,毕竟有大量的请求,没必要!\n过期时间策略 针对过期时间的一定优化,但无法解决对可写的热点数据的缓存穿透\n 一个数据被写后,通常是先写数据库,再delete缓存,这会导致缓存中数据不存在而击穿,用setnx可以很好解决\n 更新过期时间1,每次 只要我们每读一次数据,就用原子指令atomic.Add()增加过期时间,那么缓存击穿的概率也大大降低\n更新过期时间2,阈值 我们不再每次都更新缓存的过期时间,而是在value字段内置一个fake过期时间,这个fake过期时间比缓存的过期时间早,当我们每读一次数据,都要检查一下fake过期时间是否过期,如果过期,就更新缓存\n热点不过期 如果给热点数据,设置一个较长的过期时间,就能防止其失效了\n缓存雪崩 多个缓存在同一时间全部失效\n随机过期时间 给不同的资源设置不同的随机的过期时间,防止一起失效\n","id":22,"section":"posts","summary":"应用层缓存 通常我们不希望所有数据的请求都去查询数据库,这一方面是慢,另一方面对数据库的压力也大. 因此,类似硬件层面的缓存,我们在应用层也会使","tags":["cache"],"title":"[cache] base concepts","uri":"https://liwm29.github.io/2021/03/cache-base-concepts/","year":"2021"},{"content":"[Go] 可交互动态终端 \u0026lt;1, 事件注册分发中心\u0026gt; github.com/mum4k/termdash\n如何完成一个好看的terminal呢?在以前我们大都会使用简单的printf来打印数据到终端,进阶一点,可能会加上颜色,再后来可能又做个贪吃蛇游戏,了解了如何高效刷新terminal\u0026hellip;\u0026hellip;\n我们先来看看该库的Feature List\n Full support for terminal window resizing throughout the infrastructure. Customizable layout, widget placement, borders, margins, padding, colors, etc. Dynamic layout changes at runtime. Binary tree and Grid forms of setting up the layout. Focusable containers and widgets. Processing of keyboard and mouse events. Periodic and event driven screen redraw. A library of widgets, see below. UTF-8 for all text elements. Drawing primitives (Go functions) for widget development with character and sub-character resolution.  这些Feature,就是要学习的地方\n计划阅读学习的部分:\n 事件注册分发系统 终端事件轮询器 基于cell的终端结构体 容器二叉树 容器focusTracker 布局 鼠标事件之有限状态机 segmentDisplay 类似于七段数码管的display模式  1. 事件注册分发系统eventDistributionSystem(eds) 依赖于事件监听第三方库: tcell \u0026ldquo;github.com/gdamore/tcell/v2\u0026rdquo;\n针对每个订阅,都启动一个go程轮询自己,看自己的事件队列是否为空,不为空则消费\n 用更go的style,这里应该使用channel,而不是用 链表+sync.cond+sync.Mutex\n 可以认为订阅没有发起者,只是一个个平行同一的item,当事件触发后,调用订阅的回调函数,该函数一般是闭包函数,由此改变逻辑上的订阅发起者\nupdate2021/3/14 今天在看消息队列的时候,了解到,原来这个事件分发中心的设计模式是观察者模式\n 消息队列的特性: 异步解耦削峰\n 下一章 就像netpoller网络事件轮询器一样,要实现可交互终端,我们需要终端事件轮询器\n","id":23,"section":"posts","summary":"[Go] 可交互动态终端 \u0026lt;1, 事件注册分发中心\u0026gt; github.com/mum4k/termdash 如何完成一个好看的terminal呢?在以前我们大都会使用简单的printf来打印数据到终端,进","tags":["cli"],"title":"[cli] 事件分发系统","uri":"https://liwm29.github.io/2021/03/1.-eventdistributionsystem/","year":"2021"},{"content":"可交互动态终端 \u0026lt;2, 刷新屏幕\u0026gt;  ref: github.com/gdamore/tcell/v2\n 我们知道,对于终端的刷新来说,如果我们直接刷新整个屏幕,将会有明显的帧刷新感,由此,我们需要只对更新的数据刷新,而跳过不变的数据.\n这依赖于 0. 找到dirty数据 1. 设置输出光标的位置 2. printf (syscall.WriteConsole)\n创建screen 这里有两种类型的screen,\n功能是为了: NewScreen returns a default Screen suitable for the user\u0026rsquo;s terminal environment.\n win下默认使用NewConsoleScreen\n  Terminfo is a library and database that enables programs to use display terminals in a device-independent manner.\n简单来说就是一个第三方库,类似于pcap这种,用于提供posix终端控制\n查看本地是否支持terminfo: echo $TERM\n  NewConsoleScreen() NewTerminfoScreen()  我们这里介绍windows下的NewConsoleScreen()\n这些函数都是返回我们自己的定义的一个逻辑上的终端结构体.\n打开输入输出 对于windows下:\nin, e := syscall.Open(\u0026quot;CONIN$\u0026quot;, syscall.O_RDWR, 0)\rout, e := syscall.Open(\u0026quot;CONOUT$\u0026quot;, syscall.O_RDWR, 0)\r 这里CONIN$,CONOUT$,指console in/out,简单来看就是stdin/stdout,但是有时候你可能对stdin/stdout重定向到了文件,所以为了直接获取对终端的控制,用这个.\nTrue color 所谓的true color,是指支持RGB颜色的color,即3*8=24-bit的颜色设置\n但是历史原因,较古老的终端就不支持,比如cmd\n加载kernel32.dll 在windows中,我们需要先加载dll,以获取某些系统调用\nGo语言的built-in syscall并未包含一些不常用的系统调用\nvar (\rk32 = syscall.NewLazyDLL(\u0026quot;kernel32.dll\u0026quot;)\ru32 = syscall.NewLazyDLL(\u0026quot;user32.dll\u0026quot;)\r)\r 注意这里NewProc指的是New Procedure\nvar (\rprocReadConsoleInput = k32.NewProc(\u0026quot;ReadConsoleInputW\u0026quot;)\rprocWaitForMultipleObjects = k32.NewProc(\u0026quot;WaitForMultipleObjects\u0026quot;)\rprocCreateEvent = k32.NewProc(\u0026quot;CreateEventW\u0026quot;)\rprocSetEvent = k32.NewProc(\u0026quot;SetEvent\u0026quot;)\rprocGetConsoleCursorInfo = k32.NewProc(\u0026quot;GetConsoleCursorInfo\u0026quot;)\rprocSetConsoleCursorInfo = k32.NewProc(\u0026quot;SetConsoleCursorInfo\u0026quot;)\rprocSetConsoleCursorPosition = k32.NewProc(\u0026quot;SetConsoleCursorPosition\u0026quot;)\rprocSetConsoleMode = k32.NewProc(\u0026quot;SetConsoleMode\u0026quot;)\rprocGetConsoleMode = k32.NewProc(\u0026quot;GetConsoleMode\u0026quot;)\rprocGetConsoleScreenBufferInfo = k32.NewProc(\u0026quot;GetConsoleScreenBufferInfo\u0026quot;)\rprocFillConsoleOutputAttribute = k32.NewProc(\u0026quot;FillConsoleOutputAttribute\u0026quot;)\rprocFillConsoleOutputCharacter = k32.NewProc(\u0026quot;FillConsoleOutputCharacterW\u0026quot;)\rprocSetConsoleWindowInfo = k32.NewProc(\u0026quot;SetConsoleWindowInfo\u0026quot;)\rprocSetConsoleScreenBufferSize = k32.NewProc(\u0026quot;SetConsoleScreenBufferSize\u0026quot;)\rprocSetConsoleTextAttribute = k32.NewProc(\u0026quot;SetConsoleTextAttribute\u0026quot;)\rprocMessageBeep = u32.NewProc(\u0026quot;MessageBeep\u0026quot;)\r)\r 设置光标位置,注意\nfunc (p *LazyProc) Call(a ...uintptr) (r1, r2 uintptr, lastErr error)\n的签名,参数都要转换成uintptr\ntype coord struct {\rx int16\ry int16\r}\rfunc (c coord) uintptr() uintptr {\r// little endian, put x first\rreturn uintptr(c.x) | (uintptr(c.y) \u0026lt;\u0026lt; 16)\r}\r// s.out 是 screen\r// out, e := syscall.Open(\u0026quot;CONOUT$\u0026quot;, syscall.O_RDWR, 0)\rprocSetConsoleCursorPosition.Call(uintptr(s.out),coord{int16(x), int16(y)}.uintptr())\r 将以ch[0]为首地址的一段buffer输出到屏幕s.out\nsyscall.WriteConsole(s.out, \u0026amp;ch[0], uint32(len(ch)), nil, nil)\r VT转义字符序列 对于更高级的终端,可以支持VT100/XTerm 转义字符\nVT100/XTerm 转义字符,使用这些转义字符,那么就不用调用syscall了,只要把这些字符print出去,就能达到一些系统调用的效果,比如设置颜色,设置光标位置\nconst (\r// VT100/XTerm escapes understood by the console\rvtShowCursor = \u0026quot;\\x1b[?25h\u0026quot;\rvtHideCursor = \u0026quot;\\x1b[?25l\u0026quot;\rvtCursorPos = \u0026quot;\\x1b[%d;%dH\u0026quot; // Note that it is Y then X\rvtSgr0 = \u0026quot;\\x1b[0m\u0026quot;\rvtBold = \u0026quot;\\x1b[1m\u0026quot;\rvtUnderline = \u0026quot;\\x1b[4m\u0026quot;\rvtBlink = \u0026quot;\\x1b[5m\u0026quot; // Not sure this is processed\rvtReverse = \u0026quot;\\x1b[7m\u0026quot;\rvtSetFg = \u0026quot;\\x1b[38;5;%dm\u0026quot;\rvtSetBg = \u0026quot;\\x1b[48;5;%dm\u0026quot;\rvtSetFgRGB = \u0026quot;\\x1b[38;2;%d;%d;%dm\u0026quot; // RGB\rvtSetBgRGB = \u0026quot;\\x1b[48;2;%d;%d;%dm\u0026quot; // RGB\r)\r 如果是自己测试,可以使用诸如echo -e \u0026quot;\\x1b[?25l\u0026quot;\n可以通过GetConsoleMode系统调用来查看终端是否支持ENABLE_VIRTUAL_TERMINAL_PROCESSING\n基于cell的终端屏幕模拟 屏幕是二维的,我们用一个二维逻辑buffer(实际上用一维buffer实现)来模拟屏幕,众所周知,屏幕本质就是由像素点组成的二维阵列,在模拟中,我们__将cell作为最小单元__,它的宽度占比就是一个普通的ascii字符打印出来的宽度\ncell cell结构体存储3+3+1个字段,分别为current(3),last(3),width(1),current/last中包含main,comb,style,分别指主字,加字,风格\n在大多数语言中,比如英文/中文,都不存在加字comb,只包含主字main\n之所以要设置last,是为了判断这个cell是否被更新,如果更新,则要输出到屏幕覆盖旧值,如果未更新,则跳过\n对于width,大多数东亚字符的width都是2,这意味着,下一个cell将不能存储东西,要跳过下一个cell\n// main: primary rune\r// comb: any combining character runes (which will usually be nil) combining:一般是音调,或者藏语里面的上加字下加字或元音,这些字符是依附在前一个字符身上的,即自己不占空间,在存储到cell时,通常的做法是设置main为' '(空格),将其本身放在comb里面,详见本文后面的示例\r// style: the style, and the display width in cells\r// width: The width can be either 1, normally, or 2 for East Asian full-width characters.\rtype cell struct {\rcurrMain rune\rcurrComb []rune\rcurrStyle Style\rlastMain rune\rlastStyle Style\rlastComb []rune\rwidth int\r}\t// CellBuffer represents a two dimensional array of character cells.\r// This is primarily intended for use by Screen implementors; it\r// contains much of the common code they need. To create one, just\r// declare a variable of its type; no explicit initialization is necessary.\r// CellBuffer is not thread safe.\rtype CellBuffer struct {\rw int\rh int\rcells []cell\r}\r 坐标 屏幕是二维的\u0026lt;width , height\u0026gt;,但存储时,设计成一维的,对于位于(x,y)的点,通过cb.cells[(y*cb.w)+x]取出,这里cb代表cellbuffer\n(设计成一维的,可能是为了得到一个连续的空间buffer,来模拟二维的屏幕)\n 对于计算机屏幕的坐标系不用多说,左上角为原点(0,0),向右是x轴正方向,向下是y轴正方向\n如果想hideCursor() , 通常的做法是setCursor(-1,-1)\n 扫描buffer,刷新屏幕 这里只考虑ascii字符,对于utf-8字符完整的处理,可看源码\n每检测到脏数据,就添加进一个buffer,直到遇到第一个不需要更新的数据,然后将buffer写到屏幕,不断重复.\nbuf := make([]uint16, 0, s.w)\rwcs := buf[:]\rlx, ly := -1, -1\rfor y := 0; y \u0026lt; s.h; y++ {\rfor x := 0; x \u0026lt; s.w; x++ {\rmainc := s.cells.GetContent(x, y) // 注意,原本是返回mainc, combc, style, width,这里略去\r// cells.Dirty()判断x,y位置的cell是否是脏数据,这意味着要刷新到屏幕覆盖旧数据\rdirty := s.cells.Dirty(x, y)\rif !dirty {\r// write out any data queued thus far\r// because we are going to skip over some\r// cells\rs.writeString(lx, ly, wcs)\rwcs = buf[0:0]\rcontinue\r}\rif len(wcs) == 0 {\rlx = x\rly = y\r}\rwcs = append(wcs, utf16.Encode([]rune{mainc})...)\r}\rs.writeString(lx, ly , wcs)\rwcs = buf[0:0]\r}\r func (s *cScreen) writeString(x, y int, style Style, ch []uint16) {\rs.setCursorPos(x, y, s.vten)\rsyscall.WriteConsole(s.out, \u0026amp;ch[0], uint32(len(ch)), nil, nil)\r}\r 问题: 为什么syscall.WriteConsole(s.out, \u0026amp;ch[0], uint32(len(ch)), nil, nil)这里,ch必须是[]uint16,len必须是uint32?\n我们来看看微软官方的开发文档给的函数签名:\n// Writes a character string to a console screen buffer beginning at the current cursor location.\rBOOL WINAPI WriteConsole(\r_In_ HANDLE hConsoleOutput,\r_In_ const VOID *lpBuffer,\r_In_ DWORD nNumberOfCharsToWrite,\r_Out_opt_ LPDWORD lpNumberOfCharsWritten,\r_Reserved_ LPVOID lpReserved\r);\r  lpBuffer [in] A pointer to a buffer that contains characters to be written to the console screen buffer. This is expected to be an array of either char for WriteConsoleA or wchar_t for WriteConsoleW.\n 这里,wchar_t就是16位的类型(windows platform),但是注意,wchar_t,在其他平台可能是32位的,不过由于我们使用的是windows的系统调用,所以直接用就将buffer设置成[]uint16{}就行\n The wchar_t type is an implementation-defined wide character type. In the Microsoft compiler, it represents a 16-bit wide character used to store Unicode encoded as UTF-16LE, the native character type on Windows operating systems.\n这里UTF-16LE,LE指little endian\n DWORD: double word,双字,一个字是2字节\nUTF16编码 因为windows默认是UTF-16LE编码,我们需要对[]rune编码为utf16,这里rune是int32,也就直接是unicode码点\nfunc (s *cScreen) emitVtString(vs string) {\resc := utf16.Encode([]rune(vs))\rsyscall.WriteConsole(s.out, \u0026amp;esc[0], uint32(len(esc)), nil, nil)\r}\r UTF-8/UTF-16 我们知道除了ascii字符(1 byte)之外,我们还需要打印诸如中文这样的宽字符,不同的字符需要用不同的码点(数字编码)来表示,这个编码集就是Unicode\n Unicode 是容纳世界所有文字符号的国际标准编码，使用四个字节为每个字符编码\n 但是Unicode每个字符都是四字节,对于英文来说,一个ascii字符只需要1字节,对于英文国家的人来说,如果使用unicode编码来编码字符串,就会有4倍的开销,因此,产生了UTF(Unicode Transformation Format)的各个版本,这些版本都能表示所有的Unicode字符,但是有不同的优化方式(压缩方式)\n UTF-8: 使用一至四个字节为每个字符编码,其中大部分汉字采用三个字节编码 UTF-16: 使用二或四个字节为每个字符编码,其中大部分汉字采用两个字节编码 UTF-32: 使用四个字节为每个字符编码   除了字符本身的编码外,还存在大端序小端序的前置记号,UTF-16是2字节,UTF-32是4字节,UTF-8没有,这些记号在存储时将放置在文件的首部\n 一般的,大多编程语言就原生支持unicode,只需要在前面加上\\u即可, \u0026lsquo;\\u1234\u0026rsquo;\n","id":24,"section":"posts","summary":"可交互动态终端 \u0026lt;2, 刷新屏幕\u0026gt; ref: github.com/gdamore/tcell/v2 我们知道,对于终端的刷新来说,如果我们直接刷新整个屏幕,将会有明显的帧刷新感,由此,我们需要只对更新的数","tags":["cli"],"title":"[cli] 刷新屏幕","uri":"https://liwm29.github.io/2021/03/2.-createandfreshscreen/","year":"2021"},{"content":"Promise\u0026amp;future 函数式编程是一个新的编程范式,基本上,只要你的编程语言支持函数是一等公民这个说法,那么就至少支持部分的函数式编程\n[TOC]\npromise 所谓的promise,是指对异步函数返回值的一个封装,比如就是对单个int的封装,但是由于是异步的,所以只能注册回调函数来完成当函数结束后对int进行访问\n我们知道对异步函数的一般做法是,创建的同时要传入回调函数,比如:\nfunc createAudioFileAsync(successCallback func(result interface{})interface{}, failureCallback func(err interface{})interface{}) interface{}{\rgo func(){\r// dosomething\rif ok{\rreturn successCallback(result)\r}else{\rreturn failureCallback(err)\r}\r}()\r}\r 这里successCallback func(result interface{}), failureCallback func(err interface{})这些函数可以传入闭包,如果希望同时修改外部变量,这就是某种意义上的观察者模式\ncreateAudioFileAsync(func(resutlt interface{}){\r//dosomething\r},func(err interface{}){\r//dosomething\r})\r 但很明显,这陷入了某种意义上的回调地狱(callback hell),比如如果我们想有多步,先执行func1,成功了就执行func2,再成功就执行func3,\u0026hellip;\nfunc func1/2/3 (succCb , failCb){\r// dosomthing\rif ok{\rsuccCb()\r}else{\rfailCb()\r}\r}\rfunc1(\rfunc2(\rfunc3(\rfunc(resutlt interface{}){\r//dosomething\r},func(err interface{}){\r//dosomething\r}\r),func(err interface{}){\r//dosomething\r}\r),func(err interface{}){\r}\r)\r//如果写的清晰一点,就是:\rfunc1(\rfunc2(\rfunc3(\rfunc(resutlt interface{}){\r// dosomething\r},failureCallback\r),failureCallback\r),failureCallback\r)\r 于是,Promise引入了,我们不再直接在异步函数参数中传递callback,而是让异步函数返回一个promise,这个promise结构体支持注册回调,哪怕异步函数已经完成了,也会触发一次回调;\n这样,原本嵌套的回调函数,变成了级联的调用链\nfunc func1()promise{\r// dosomthing\rreturn promise\r}\rpromise := func1()\rpromise.then(func(resutlt interface{}){\r// dosomething\r},failureCallback)\r 级联调用时(successCb()要返回promise):\nfunc1().then(func(){return func2()},failureCallback).then(func(){return func3()},failureCallback)\r 为了更好的减少代码,我们将failureCallback抽离,形成一个统一的错误处理\nfunc1().then(func(){return func2()}).then(func(){return func3()}).catch(failureCallback)\r  一般的,每个successCb都应该以一个result为参数,在go里面,可以用interface{}替代,假装自己是动态类型\n await async/await 是promise的语法糖,可以不必再刻意的写出.then()调用链\n比如如下代码,只要有一个await失败,就直接跳转到catch\nasync function foo() {\rtry {\rconst result = await doSomething();\rconst newResult = await doSomethingElse(result);\rconst finalResult = await doThirdThing(newResult);\rconsole.log(`Got the final result: ${finalResult}`);\r} catch(error) {\rfailureCallback(error);\r}\r}\r  async函数,代表这是一个可能的异步函数(如果async内部不包含await,那么就失去async语义,转为同步函数)\nasync函数可能包含0个或者多个await表达式。await表达式会暂停整个async函数的执行进程并出让其控制权，只有当其等待的基于promise的异步操作被兑现或被拒绝之后才会恢复进程。promise的解决值会被当作该await表达式的返回值。使用async / await关键字就可以在异步代码中使用普通的try / catch代码块。\n C++中的future/promise std::promise\u0026lt;int\u0026gt; p;\rstd::future\u0026lt;int\u0026gt; f3 = p.get_future();\rstd::thread( [\u0026amp;p]{ p.set_value_at_thread_exit(9); }).detach();\rf3.wait();\r  这里detach,是指分离这个thread,让他独立执行,而不再需要主线程join()来回收资源,可以回顾进程中的僵尸进程,就是子进程执行完了,但是父进程没有join它(wait/waitpid),导致资源未回收\n 可以看出,这里future,就是异步值的承载,是只读的,promise则用来设置值,是只写的\n如果以go语言为例,promise就是管道的左端,chan \u0026lt;- ,future就是管道的右端\u0026lt;- chan\n 注意,使用promise/future时,就不再只限定于返回值了,可以异步执行的过程中,由promise.setValue,和go的channel很像\n 当然,也可以直接将返回值作为future\nstd::future\u0026lt;int\u0026gt; f2 = std::async(std::launch::async, [](){ return 8; });\rf2.wait()\rf2.get()\r Go中的future/promise 如上所述\nasyncTask := func(){\rch := make(chan int,1)\rgo func(){\r//dosomething\rch\u0026lt;-1 // work as a kind of promise\r}()\rreturn ch\r}\rfuture := asyncTask()\r\u0026lt;- future // this will be blocked\r 当然,对future的读会导致阻塞,我们可以再包装一下\nasyncTask := func(){\rpromise := \u0026amp;promise_st{}\rgo func(){\r//dosomething\rpromise.SetVal(1)\r}()\rreturn promise.getFuture()\r}\rfuture := asyncTask()\rfuture.Wait()\rval := future.get()\r 设计上也不难,本质是个单生产者,单消费者的问题\ntype promise_st struct{\rval interface{}\rok bool\rch chan interface{}\r}\rfunc (p *promise_st) SetVal(a interface{}){\rch \u0026lt;- a\r}\rfunc (p *promise_st) Wait(){\rp.val = \u0026lt;- ch\r//atomic.CAS(\u0026amp;p.ok , false , true)\rp.ok = true\r}\rfunc (p *promise_st) Get()interface{}{\rif p.ok{\rreturn p.val\r}\rreturn nil\r}\r 由于go的channel已经足够强大,所以到没必要去使用future/promise,await/async\n但是知道这些东西还是很有必要的\n","id":25,"section":"posts","summary":"Promise\u0026amp;future 函数式编程是一个新的编程范式,基本上,只要你的编程语言支持函数是一等公民这个说法,那么就至少支持部分的函数式编程 [TOC] promise 所谓的promise,","tags":["concurrency"],"title":"[concurrency] promise\u0026future","uri":"https://liwm29.github.io/2021/03/concurrency-promisefuture/","year":"2021"},{"content":"skipList 跳表具有平均的O(logn)的时间复杂度,但最坏情况仍是O(n)\n跳表是二叉搜索树,AVL,RBTree的替代品\n这里我们不介绍如何从头开始编写skipList,但仍然介绍其中可能存在的一些关键点\n数据结构 C 如果是用c语言,我们可以这样实现一个skipList的底层数据结构\n摘自: begeekmyfriend/skiplist\n 其中用到了1.柔性数组 2.从成员还原出结构体首地址 等一些trick\n用1.柔性数组,是为了保证link与skipnode是内存连续性,以便于使用2来还原出首地址,这样,st_link就不必去记录*node了,少了一个开销\n柔性数组也是动态分配的,用多少分配多少,避免多余浪费\n struct sk_link {\rstruct sk_link *prev, *next;\r};\rstruct skiplist {\rint level;\rint count;\rstruct sk_link head[MAX_LEVEL];\r};\rstruct skipnode {\rint key;\rint value;\rstruct sk_link link[0];\r};\r 在st_link中,我们记录了prev,这是为了方便插入.否则如果只记录next,那么在插入前的search时,就要记录一张表,便于插入时的指针赋值\nGo 在go中,一般实现成:\n摘自: https://github.com/sean-public/fast-skiplist\ntype elementNode struct {\rnext []*Element\r}\rtype Element struct {\relementNode\rkey float64\rvalue interface{}\r}\r 这里,len(next)就表示这个node的高度,next[i]就是第i层指向的下一个节点,不同层可能会指向到相同的节点,所以有可能next[0] == next[1]\n思考 为什么不适用上层节点也是node结构呢? 我在youtube的某些视频上看到上层节点也是node,从代码上看,很优美对称,但是会有数据的冗余.\n而且当使用额外的link结构后(c的写法),也完美的继承了这种对称,即逐层的遍历节点\nstruct skipnode {\rint key;\rvoid* value;\rstruct skipnode *right;\rstruct skipnode *down;\r};\r 插入 在学习时,你可能学的是一层一层构建skiplist,先遍历第一层,每个node抛硬币,看自己是否能构建上层\n但在实践中,这没有必要,我们直接用一个random函数决定一个节点有几层即可\n 注意,不是简单的抛到几就是几,仍然是逐层增长的,因为概率是乘法,详见后文的概率表\n static struct skipnode *\rskiplist_insert(struct skiplist *list, int key, int value)\r{\rint level = random_level();\rif (level \u0026gt; list-\u0026gt;level) {\rlist-\u0026gt;level = level;\r}\rstruct skipnode *node = skipnode_new(level, key, value);\r// do search and insert\r}\r 搜索并插入 首先搜索\n从最高层开始逐步顺着指针遍历,找到end.key\u0026gt;newNode.key,prev.key\u0026lt;newNode.key\n然后插入,将newNode插入到prev和node之间\n__list_add(a,b,c) 函数将a插入在b,c之间,注意a,b,c只是单个st_link\n并向下一层移动(即pos\u0026ndash;,end\u0026ndash;),此时for循环由于条件直接满足而被跳过,直接执行插入\nint i = list-\u0026gt;level - 1;\rfor (; i \u0026gt;= 0; i--) {\rpos = pos-\u0026gt;next;\rfor (; pos != end; pos = pos-\u0026gt;next) {\rstruct skipnode *nd = list_entry(pos, struct skipnode, link[i]);\rif (nd-\u0026gt;key \u0026gt;= key) {\rend = \u0026amp;nd-\u0026gt;link[i];\rbreak;\r}\r}\rpos = end-\u0026gt;prev;\rif (i \u0026lt; level) {\r__list_add(\u0026amp;node-\u0026gt;link[i], pos, end);\r}\rpos--;\rend--;\r}\rstatic inline void\r__list_add(struct sk_link *link, struct sk_link *prev, struct sk_link *next)\r{\rlink-\u0026gt;next = next;\rlink-\u0026gt;prev = prev;\rnext-\u0026gt;prev = link;\rprev-\u0026gt;next = link;\r}\r Go中的插入 为什么要单独谈论c和go的实现呢? 因为c的语言特性决定了它可以写的很炫,但是go就只能很plain的实现\n首先创建新节点\nelement = \u0026amp;Element{\relementNode: elementNode{\rnext: make([]*Element, list.randLevel()),\r},\rkey: key,\rvalue: value,\r}\r 然后找到key该插入的位置在各层的前一个node(注意,这个\nprevs的各个元素可能属于不同的node),因为每个node的高都不同\nprevs := list.getPrevElementNodes(key)\r 执行插入,遍历当前element/node的高度,替换指针\nfor i := range element.next {\relement.next[i] = prevs[i].next[i]\rprevs[i].next[i] = element\r}\r 搜索 还记得我在前面说的插入前的搜索要维护一张表吗,就是这里的list.prevNodesCache\nfunc (list *SkipList) getPrevElementNodes(key float64) []*elementNode {\rvar prev *elementNode = \u0026amp;list.elementNode\rvar next *Element\rprevs := list.prevNodesCache\rfor i := list.maxLevel - 1; i \u0026gt;= 0; i-- {\rnext = prev.next[i]\rfor next != nil \u0026amp;\u0026amp; key \u0026gt; next.key {\rprev = \u0026amp;next.elementNode\rnext = next.next[i]\r}\rprevs[i] = prev // 这里prevs[i]存了整个prev,其实只需要存prev[i]即可,不过反之都是指针,开销到是一样的. 是这样吗?详见后面描述的caching and search fingers\r}\rreturn prevs\r}\r 关于重复键值 这其实取决于你的上层数据结构的逻辑,如果你是要实现一个set,那显然不能有重复键值,遇到重复的,就直接覆盖\n超参数 根据这个repo,指出了合适的超参数选择\n 抛硬币为正面的概率P为1/e,即向上增长的概率为1/e(典型的p的取值为0.25-\u0026gt;0.5)   The default P values for skip lists in the wild range from 0.25 to 0.5. In this implementation, the default is 1/e, which is optimal for a general-purpose skip list. To find the derivation of this number, see Analysis of an optimized search algorithm for skip lists Kirschenhofer et al (1995).\n 随机数生成器PRNG  我们不能使用全局的随机数生成器,因为这样的化,多个跳表之间就会造成冲突,有锁的竞争\n因此,每个跳表一个rand.Source\nrandSource: rand.New(rand.NewSource(time.Now().UnixNano())),\r 概率表 一个典型的层数将如下计算\nstatic int random_level(void)\r{\rint level = 1;\rconst double p = 0.25;\rwhile ((random() \u0026amp; 0xffff) \u0026lt; 0xffff * p) {\rlevel++;\r}\rreturn level \u0026gt; MAX_LEVEL ? MAX_LEVEL : level;\r 很明显,我们可以预先记录好一个概率表,然后只计算一次rand,这意味着,我们将这一次rand视为多次rand的乘积,而概率表也是概率的乘积,因此直接比较\nfunc probabilityTable(probability float64, MaxLevel int) (table []float64) {\rfor i := 1; i \u0026lt;= MaxLevel; i++ {\rprob := math.Pow(probability, float64(i-1))\rtable = append(table, prob)\r}\rreturn table\r}\rfunc (list *SkipList) randLevel() (level int) {\r// Our random number source only has Int63(), so we have to produce a float64 from it\r// Reference: https://golang.org/src/math/rand/rand.go#L150\rr := float64(list.randSource.Int63()) / (1 \u0026lt;\u0026lt; 63)\rlevel = 1\rfor level \u0026lt; list.maxLevel \u0026amp;\u0026amp; r \u0026lt; list.probTable[level] {\rlevel++\r}\rreturn\r}\r 缓存,caching and search fingers 当我们把整个节点缓存下来,有利于后面的搜索,而不仅仅是缓存那一层,见https://github.com/sean-public/fast-skiplist#caching-and-search-fingers\nConclusion 个人认为go中的实现可能更好,因为它避免了去逐层的访问,而是统一的去访问一个node,再去访问他的next数组,找到对应层的下一个node\n","id":26,"section":"posts","summary":"skipList 跳表具有平均的O(logn)的时间复杂度,但最坏情况仍是O(n) 跳表是二叉搜索树,AVL,RBTree的替代品 这里我们不介绍如何从头开始编","tags":["dataStructure"],"title":"[dataStructure] skip-list","uri":"https://liwm29.github.io/2021/03/data-structure-skip-list/","year":"2021"},{"content":"索引中的平衡树:b-tree,b-plus-tree 主要介绍数据库的索引,及其实现,平衡多叉树\n什么是索引  想象一下,假设db没有任何数据结构驻留在内存,其一切存储都放在disk,那么想找到一张表的一个行,就必须把表的所有页取到memory,逐个比较各行. 因此我们必须放置一些特定的数据结构在内存中,方便快速查找(但不是缓存)(也不总是在内存中)\n对于一张表结构,它自身就记录自己在磁盘上的位置和大小,我们可以快速找到它,但是它包含很多页,我们无法确定某一行在哪一页,只能扫描全表.\n 索引完成了这样一个功能, 快速找到某一列的值所在的行的在磁盘上的页(os虚拟页,实际在磁盘); 注意,无法找到在那一页的哪一个位置,最终读到内存页后还是扫描整个页,因此文档也指出了,对于小表,加不加索引意义不大,对于要查出绝大部分数据的大表,也不要用索引,不如直接全表扫描\n mysql 官方文档: mysql-indexes ,innodb-index-types\n 所谓索引(index),就是给定一个键,快速返回其在磁盘上的存储页(索引本身是一个键值存储数据结构),然后再根据这个位置磁盘的磁头快速旋转到对应扇区(一个扇区512B,但InnoDB的页16KB),读取一整块数据,通过DMA方式从磁盘缓冲区copy到内核缓冲区,然后中断,对应db进程被唤醒,read到用户缓冲区,遍历整页的数据,找到record(实际上页16KB,一条record如果1KB,就有16行,最差比较16次,其实是不慢的),通过tcp本机通信发送给client.\n你可以将其理解为一个map,其键是某一列的取值,其值是对应页所在磁盘的位置.(索引树本身是要持久化在磁盘的,一个结点一页)\n 其实这更像是搜索引擎领域中的倒排索引(反向索引),给定关键词,返回其所在页;正向索引则是像普通目录一样,给定页,返回其关键词.\n 事实上,数据库的索引常见的实现算法就是hash和b/b+树,其本身就是一个存储型数据结构,可作为in-memory cache/db,当设置特殊的kv时,便可视作索引\n hash分为静态hash和动态hash(依据其是否在runtime时会有分裂桶(增加桶数)的操作),redis作为一个in-memory cache/db,其dict结构就是用的动态哈希算法中的可拓展哈希\n hash和b/b+树的各自特点:\n  hash表是无序的,在使用==时很快,对于不等号,有点无能为力\n  b/b+树是有序数据结构,在不等号时很快,但本质还是搜索树,判断相等要多分遍历,但也不慢\n   实际上索引的树的结点都需要持久化放在磁盘,并且一般来说每个结点一个页\n  高度为 3 的 B+ 树就能够存储千万级别的数据: 比如高度为2的树,满载时根节点有16KB/14B =1170个指针,这里14是指主键8B,指针6B,由于一条记录1KB,则一页只能存放16条记录,则总共:1170*16 = 18720 条记录; 高度为3时:1170*1170*16*21902400 条记录\n 使用 ALTER TABLE students\rADD INDEX idx_name_score (name,score);\r 这一段sql就为表students,添加了名为idx_name_score的索引,它是针对列name和score的索引.\n我们常称为: 对列name,score创建索引\n显然,它将列的值作为key,行的磁盘地址作为value,当key越不同时,冲突越少,效率越高. db会默认为主键创建索引.\n 对表的增删查改,显然也要及时更新索引,因此这是一个缺点,对于hash表和b/b+树,都可能触发整个数据结构的整形(hash是桶的分裂,b/b+树是平衡化),会拖慢速度,但没办法,没有银弹.\n 在InnoDB中,默认采用B+树作索引,对于主键的索引,以\u0026lt;primary_id,page\u0026gt;的方式,辅助索引以\u0026lt;col,primary_id\u0026gt;的方式,辅助索引(secondary index)指出了聚簇索引(clustered index)(一般的,主键索引)以外的所有索引\n平衡树 由于大多数db engine会采用b/b+树,比如innodb使用b+树作为索引,我们这里就不探讨动态哈希了,哈希由于对区间查找支持太差,更适合作为键值缓存数据库,比如redis\n平衡二叉搜索树 二叉搜索树(二叉排序树,查找树),相比都知道,其在结构上是类似一个二叉堆,但是满足左子节点\u0026lt;父节点\u0026lt;右子节点,相比之下,用来实现优先队列(大/小顶堆)的二叉堆结构,只需要满足左子节点\u0026lt;父节点,右子节点\u0026lt;父子节点\n平衡化: 这意味着插入/删除元素的时候,不能直接简单的插入删除,需要对局部结构进行reshape(旋转),以满足插入/删除后仍然是平衡树\n 平衡树: 如果一棵树,其子节点都是平衡树,并且深度相差不超过1,则称为平衡树\n 平衡化的旋转操作比较复杂,如果不是专门去实现一个平衡树,我个人认为了解它需要平衡化就行了\n 有序性: 当对平衡二叉搜索树进行中序遍历时,将得到一个递增序列\n B树 B树是平衡二叉搜索树的进阶版,可以认为,B树是平衡多叉搜索树,在这里,平衡是严格平衡,不再是相差为1,而是都一样的高度\n这是google/btree的go语言实现版\n// degree指度数,一个node的最小item数是degree-1,最大是degree*2-1\r// order指阶数,一个node的最大子树个数是order,最大item数是order-1,最小item数是order/2\r// 所以: order-1 等于 degree*2-1 , 一个2度树是一个4阶数\rtype BTree struct {\rdegree int\rlength int\rroot *node\rcow *copyOnWriteContext\r}\r// node指tree中的一个节点\rtype node struct {\ritems items\rchildren children\rcow *copyOnWriteContext\r}\rtype items []Item\rtype children []Item\r// 显然items代表父节点自己存储的值数组,而children代表指向子节点的指针数组\r// Item represents a single object in the tree.\rtype Item interface {\r// Less tests whether the current item is less than the given argument.\rLess(than Item) bool\r}\r  对于m阶的b树,每个子节点不能有超过m-1个关键字,非根结点至少有Math.ceil(m/2)-1个关键字\n插入节点时,首先寻路到了叶子节点(注意一定是叶子节点,否则是replace而不是insert),正常按顺序找到位置,插入,对于go实现,可以通过*items = copy((*items)[i:] , (*items)[i+1:]) 如果叶子节点关键字数超过了m-1,则将整个items二分,将中间的关键字append到父节点\n 当一层满了之后,才会插入到下一层!\nB+树 B+树显然是B树的升级版\nB+树的特点是,非叶子节点不保存(key-value),而只是保存key用于比较,所有的数据item都在叶子节点\n叶子节点的最右指针将会指向临近的叶子节点\nB+数相对B数的优点   快速性: B+树的层级比B树小,查的更快(基本上看其他资料,都有提到这个,但我实在不懂为什么会更矮:2021/03/16更新:因为B+树的非叶子节点没有数据,而一个数据要1kb,至少相当于100个指针了,所以B+树每个节点能容纳的叉数更多(建立在一个节点存一个页的情况))\n  稳定性: B+树由于非叶子节点不存储值,所以每次查询必须一直查到叶子节点,对于不同的键查询时间差距不大(这个是建立在其本身和B树的查询速度差距不大的前提下)\n  有序性: 虽然B树作为搜索树也可以通过中序遍历获取有序列,但是B+树更加便捷,因为叶子节点之间是直接通过指针相连的(所以在查区间数据时很有优势)\n   有些地方说,B+树有利于全表扫描,但根据文档的建议,对于要查出大部分record的查询来说,不要用索引,直接全表扫描\n  2020/03/16更新,今天面试问了为什么稳定性是一个好的特性呢,可惜我不知道! 面试官说是和硬盘的特性有关,我搜索了一下,B+树比B树更满足硬盘的特性,因为硬盘读取慢,我们希望降低io次数,对于3层B+树,就可索引2kw个数据,这意味着4次io就可索引到2kw个数据,很恐怖! 反之对B树,由于数据要放在非叶子节点,所以一页最多16个指针,16^3远小于2kw\n但是对于内存中的存储,多用B树,因为不再需要io\n 使用注意: 使用B/B+树时,不建议使用自增主键,因为自增主键由于主键的严格有序性,导致每插入一个元素(最终都会在最后一个叶子节点插入),就会触发一次分裂\n 2021/03/16更新,这句话就是在放屁,自己可以压测一下,无论是avl树还是rb树还是b树,在插入递增key时,绝对是比随机key性能好的\n更何况b+树呢\n  gif来源博客\n 为什么InnoDB使用B+树 等价问题是,为什么InnoDB为什么采用B+树,而不是B树和动态哈希?\n显然,对于OLTP来说,所有提到的优点在前文已经说明了.\n","id":27,"section":"posts","summary":"索引中的平衡树:b-tree,b-plus-tree 主要介绍数据库的索引,及其实现,平衡多叉树 什么是索引 想象一下,假设db没有任何数据结构驻","tags":["DB"],"title":"[DB] b-tree","uri":"https://liwm29.github.io/2021/03/db-b-tree/","year":"2021"},{"content":"数据库中的三种锁 ref\n record锁(行锁) gap锁(间隙锁)(左开右开) next-lock锁(行+间隙)(左开右闭)  注意,锁的区间不是任意的,是依托于索引的键的.相当于说锁和非叶子节点的指针一对一的\n A record lock is a lock on an index record. For example, SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE; prevents any other transaction from inserting, updating, or deleting rows where the value of t.c1 is 10.\n 细节 首先明确,当通过索引查找数据时,innodb默认的方式是next-key lock.\n但是如果不走索引,则是按页来锁数据的\n","id":28,"section":"posts","summary":"数据库中的三种锁 ref record锁(行锁) gap锁(间隙锁)(左开右开) next-lock锁(行+间隙)(左开右闭) 注意,锁的区间不是任意的,","tags":["DB"],"title":"[DB] mutex","uri":"https://liwm29.github.io/2021/03/db-mutex/","year":"2021"},{"content":"数据库设计范式 所谓设计范式,可理解为设计一张表的各个列的规则\n定义 键和函数依赖\n键 所有的键(key) 都是 a set of one or more attributes\n主属性(prime attribute) 至少出现在一个候选键中的属性\n超键(super key) 一个超键能唯一标识一个元组,其属性集闭包是所有属性的集合\n候选键(candidate key) 最小的超键,即任何一个子集都不能是超键; 超键就是候选键加上其他属性\n主键 存在多个候选键组,选一组成为主键\n函数依赖 α-\u0026gt;β表示α能决定β, β函数依赖于α\n对键的部分函数依赖: (a,b)-\u0026gt;(c,d,e) 且 a-\u0026gt;c , 则c部分函数依赖于候选键(a,b)\n传递依赖: a-\u0026gt;b, b-\u0026gt;c, 则称c传递依赖于a;\n所有的部分函数依赖都是传递依赖: (a,b)-\u0026gt;(c,d,e) 且 a-\u0026gt;c , 则c传递依赖于候选键(a,b)\n四范式   1NF\n 给定行与列, 能得到唯一的值 每一列都不可分割成多个子属性    2NF\n  It is of historical significance only and is not used in practice.\n  非主属性不会部分函数依赖于候选键,即不存在某个主属性能决定非主属性,除非这个主属性是候选键\n  简单来看: 非主属性不能函数依赖于主属性\n 否则两个属性应该独立成表      3NF\n  学术角度: 对于一个非平凡函数依赖α-\u0026gt;β,要么α是超键,要么β-α的元素在某个候选键中(可以是不同的元素在不同的候选键中)\n  简单来讲: 非主属性不能函数依赖非主属性,即禁止传递依赖 (候选键-\u0026gt;非主属性-\u0026gt;非主属性)\n 否则两个非主属性应该独立成表      BCNF:\n 非平凡函数依赖的左端必是超键(而不能是一个候选键的某个属性) 主属性不能函数依赖于主属性     在表述中,一会是超键,一会是候选键,这其实是自然的,候选键本身就会依赖于超键\n   消去非主属性对键的部分函数依赖\n 指非主属性不依赖主属性(这个主属性不是键)    消去非主属性对键的传递函数依赖\n 指非主属性不依赖非主属性    消去主属性对键的传递函数依赖\n 指主属性不依赖主属性(一般指有多个候选键组,一个候选键组里的主属性依赖另一个候选键组的主属性)    ","id":29,"section":"posts","summary":"数据库设计范式 所谓设计范式,可理解为设计一张表的各个列的规则 定义 键和函数依赖 键 所有的键(key) 都是 a set of one or more attributes 主属性(prime attribute) 至少出","tags":["DB"],"title":"[DB] rule","uri":"https://liwm29.github.io/2021/03/db-rule/","year":"2021"},{"content":"About sql statement\u0026amp;index spec  参考但不限于Java开发手册（嵩山版）\n 关于索引 与索引有关的注意事项,基本都集中在一个sql语句它到底是否正确使用了索引,这可以通过explain后的extra列来识别语句执行速度,但是在理论上,我们知道索引是一颗B+树,所以只要了解了B+树的构造,那么自然可以从理论上去识别一个条件查询是否能使用索引\n联合索引 单键索引没什么好讲的,重点是多键索引\n其非叶子节点的搜索键是多个值,比如__(a,b,c) = (4,7,5)__\n那么(a\u0026lt;4,*,*)会排序到这个索引的左边,如果a == 4,那么再比较b\u0026hellip;\n所以最终,这个索引的左边会是\n(a\u0026lt;4,*,*) , (a=4,b\u0026lt;7,*),(a=4,b=7,c\u0026lt;5)\n右边会是\n(a\u0026gt;4,*,*) , (a=4,b\u0026gt;7,*) , (a=4,b=7,c\u0026gt;=5)\n使用场景 指定联合索引(a,b,c)\n范围查询 如果sql是(语法为EBNF)\n where (a \u0026lt; * | a \u0026gt; *) where a = * [and (b \u0026gt; * | b \u0026lt; *)] where a = * and b = * [and (c \u0026gt; * | c \u0026lt; *)] where a = * order by b  那么显然可以使用b+树的联合索引\n 这就是最左前缀匹配原则\n  并且指定了a后,b,c是天然排序的; 指定a,b同理\n 失败案例 以下无法使用索引\n where b = * where b = * and c = * where a \u0026gt; * and b \u0026gt; * where a \u0026gt; * order by b  原则  建立联合索引时,区分度最高的在左边(所谓区分度,是指唯一性)  除非,常用查询是where b = * \u0026amp; a \u0026gt; *,即使a区分度更高,也应该设置索引index_b_a 这是因为,where b = *后,对a是天然排序的,若以a为第一个索引,那么查b=*,就需要对b进行filesort    覆盖索引 所谓覆盖索引,就是说对于辅助索引,可以直接查出想要的数据,而不再需要回表查询\n其他 禁止对索引列进行计算\n使用\nselect * from users where adddate\u0026lt;'2007-01-01'\n而不是\nselect * from users where YEAR(adddate)\u0026lt;2007\nLimit 前置条件: k 是辅助索引\nselect * from table_name where k = 1 limit 3 offset 100000\n一方面是将会查找出100003条记录,再丢弃掉前100000条记录,这会导致极高的延时\n再其次就是会有100003次回表查询(即没找到一个辅助索引对应的pk,就回聚簇索引查找record)\n因此,需要使用子查询,防止超多次回表:\nselect * from table_name as t1 inner join (select pk from table_name where k =1 limit 3 offset 100000) as t2 on t1.pk = t2.pk \n这其实利用了索引覆盖的特点,由于我们在子查询中是查pk,不需要回表,所以直接放回了100003条pk,然后再统一回表查一次\nType 要精确存储某个类型时,使用decimal(定点数),而不是浮点数\n","id":30,"section":"posts","summary":"About sql statement\u0026amp;index spec 参考但不限于Java开发手册（嵩山版） 关于索引 与索引有关的注意事项,基本都集中在一个sql语句它到底是否正确使用了索引,这可以通过e","tags":["DB"],"title":"[DB] sql spec","uri":"https://liwm29.github.io/2021/03/db-sql-spec/","year":"2021"},{"content":"记一次云端部署web服务器 本来以为和在自己电脑上本地部署一样,没想到还是遇到很多自己不熟悉的地方,云端服务器会涉及到更多linux相关的知识.\n首先是云服务器的环境配置 典型的,我们是通过ssh上服务器(22端口),如果是windows,则是远程桌面的3389端口,这两个端口连同80和443端口都是默认开放的. 如果想使用其他端口必须在防火墙中设置入站白名单\nssh配置 ​\tssh客户端登陆时,需要配置ssh密钥,将私钥文件的路径放置在ssh的config文件的对应字段就行\n​\t对于你要登陆的用户,一定要在/home/$user/.ssh下有一个authorized_keys目录记录公钥. 本来如果是自己生成密钥的话,直接放在那就好了,但是如果是腾讯云,通过可视化界面帮助你生成密钥,在密钥与实例绑定时,会默认放在root目录下,即你只能登陆root用户. 解决方法也很简单,复制一份到/home/$user/.ssh/就行了\n文件夹权限 我的程序调用了err := os.MkdirAll(folderPath, 0777) 他会递归的创建文件夹/文件,本来以为这是一个正常运行的代码,结果却出乎意料,无论我怎么设置文件权限perm,都无法如愿,最终的文件夹权限都是0774\n后来才知道,还要减去默认的umask才是最终的文件权限,而普通用户的umask是others的w\n 对于文件夹的权限,r: 可以list文件夹, w:可以对文件夹内的文件增删查改, x:可以cd进文件夹\n oldMask := syscall.Umask(0)\rdefer syscall.Umask(oldMask)\r// 或者手动修改\ros.Chmod(...,0744)\r web服务器必须以root模式启动 如果你想监听80端口,那么必须以root启动,则是linux的规则,\u0026lt;1024的保留端口只对root开放\n后台运行服务器 一般的,我们会用\u0026amp;来后台启动服务器,比如: sudo ./app \u0026amp; ,\n 对于后台启动,当然也可以守护模式: 你的web后端程序代码可以dup文件描述符,fork两次,setsid然后进入守护模式\n 虽然这是服务器是成功在后台启动了,但是其还是和当前的shell绑定的,所以程序的输出还是会输出到该终端上,我们还需要重定向输出\nsudo ./app \u0026gt; ./log 2\u0026gt;\u0026amp;1 \u0026amp;\n这里, \u0026gt; ./log 代表标准输入重定向到./log , 2\u0026gt;\u0026amp;1代表标准错误重定向到标准输出,之所以是用\u0026amp;1,是为了和普通文件区分,不然我难道不可以输出到名为1的文件吗?\nsudo运行导致的两个进程 运行sudo ./app,使用ps -aux将会发现两个进程 ./app 和 sudo ./app\n 当使用sudo ./app执行代码时，会首先启动一个root用户的shell，但是这个shell的名字就叫做\u0026quot;sudo ./app\u0026quot;，直接引起歧义。\n nohup 忽略sighup信号,该信号在session shell关闭后发出给属于这个shell的所有进程\n 注意,如果以sudo启动应用,那么正如前文所说,开启了一个sudo ./app的shell,所以你关闭你的用户shell是不影响程序的,即使不用nohup\n  但实际上,只是用\u0026amp;就足够了,即使关闭了终端,也可以继续运行\n lsof -i:80 list open fd 打印出打开的文件描述符,我们知道unix一切皆文件; -i:80 80端口\n 要想看到root占用的端口,加sudo\n netstat -ntlp 查看所有的tcp端口占用情况\np: 显示program名,即对应的程序名; t: tcp; l: 只显示listen端口; n:不显示别名\n 要想看到root占用的端口,加sudo\n jobs jobs 指令可以方便的看到本用户在本shell启动的后台程序\n但如果换一个bash,就不行了\n","id":31,"section":"posts","summary":"记一次云端部署web服务器 本来以为和在自己电脑上本地部署一样,没想到还是遇到很多自己不熟悉的地方,云端服务器会涉及到更多linux相关的知识","tags":["deploy"],"title":"[deploy] server deploy","uri":"https://liwm29.github.io/2021/03/deploy-server-deploy/","year":"2021"},{"content":"Built-in map\u0026amp; sync.Map \u0026amp; ConcurrentMap 并发map,是指多线程安全的map数据结构, 我们知道go语言原生的map是不支持并发的, 要想获得一个并发map,\n我们有如下的几种方案:\n map with mutex sync.Map  读写map分级   orcaman/concurrent-map  分片    Map built-in map本质是动态哈希算法实现,在运行过程中桶会分裂,导致元素的迁移.\n 这也是经典的遍历无序,取出的value不可取地址的原因,以及衍生的value作为结构体时其字段无法赋值的原因  如何处理并发也是一个比较难的问题了,我当时学数据库实现线性哈希的时候也思考了很久这个问题.\n但是基于当时的我的知识的思考,其实无异于在想如何开汽车登上月球,没有一定知识积累的思考,真就只是想想而已!\n最后,我果断的加上了读写锁 :)\n 这里收录一点关于built-in map的一些冷知识\n  声明和初始化:\n 空map: 声明+初始化  make(map[int]int) map[int]int{}   nil map: 声明  var a map[int]int   和slice不一样,空map和nil map有着一定的差距  相同: 空map和nil map的读,都会返回default_value,false 不同: nil map的写触发panic,而空map的写正常; nil map可与nil比较为true   相比之下,slice的append操作对于空切片和nil切片都是一致的,除了与nil比较之外    任何类型都可以作为key吗?\n 错,必须是可比较类型; 其中 Slice，Map，Function 是三个内置的唯一的不可比较类型 结构体可比较吗?  同一结构体定义的不同实例: 只要其字段不包含不可比较类型,就可以比较 ref 不同结构体定义的不同实例: 显然不行,因为go是强类型语言! 如果它们定义相同,可以尝试先cast 再加上一嘴: 深度比较: reflect.DeepEqual() ,除了判断值,还会判断底层指针指向的值是否相等!      删除\n delete (map_,key_) , 只会将其删除位置1,而不会释放空间 map是一种只增不减的数据结构! 对map的clear,直接创建一个新的map覆盖,原map将会被gc    如何有序遍历map\n  type orderedMap (type T1,t2) struct{\r_map map[T1]T2\r_slice []T1\r}\r// 假装泛型,这泛型用()小括号是真的让人无语!\rfunc (m *orderedMap(T1,T2))Add(k T1,v T2){\rm._map[k] = v\rm._slice = append(m._slice , v)\rsort.Sort(m)\r}\rfunc (m *orderedMap(T1,T2))Iter() func()(T1,T2){\rm = snapshot(m)\ri := -1\rreturn func(){\ri++\rreturn m._map[m._slice[i]]\r}\r}\r   键的优化: 据说, golang为 uint32、uint64、string 作为key时提供了fast access,可以在runtime/map_fast32,\u0026hellip; runtime/map_faststr,找到\n 不过我看了半天代码,发现自己看不懂    Map with mutex 很显然,性能将不再是一个需要多么谈及的话题.mutex将会导致go程阻塞而被调度出运行队列\ntype concurrentMap(type T1,T2) struct{\r_map map[T1]T2\rrwMutx sync.RWMutex\r}\r sync.Map Go1.9 推出了sync.Map\n 以下场景适合sync.Map:  (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow  这也是concurrent-map的文档里说的,sync.Map只适合append-only的场景(only grow)   (2) when multiple goroutines read, write, and overwrite entries for disjoint sets of keys.  根据这个issue: https://github.com/golang/go/issues/21035 sync: reduce contention between Map operations with new-but-disjoint keys 我想 (2) 应该不再是一个适用场景      其内部实现是用两个built-in map 加 single-mutex 实现\n实现:\ntype Map struct {\rmu Mutex\r// read contains the portion of the map's contents that are safe for\r// concurrent access (with or without mu held).\r//\r// The read field itself is always safe to load, but must only be stored with\r// mu held.\r//\r// Entries stored in read may be updated concurrently without mu, but updating\r// a previously-expunged entry requires that the entry be copied to the dirty\r// map and unexpunged with mu held.\rread atomic.Value // readOnly\r// dirty contains the portion of the map's contents that require mu to be\r// held. To ensure that the dirty map can be promoted to the read map quickly,\r// it also includes all of the non-expunged entries in the read map.\r// 这里说dirty map can be promoted to the read map,个人感觉会误解为是dirty被promote到了read\r// 实际上也没错,但更准确的是覆盖了,后续的第一次写将会导致遍历read写回dirty.这个遍历更像是promote?\r//\r// Expunged entries are not stored in the dirty map. An expunged entry in the\r// clean map must be unexpunged and added to the dirty map before a new value\r// can be stored to it.\r//\r// If the dirty map is nil, the next write to the map will initialize it by\r// making a shallow copy of the clean map, omitting stale entries.\rdirty map[interface{}]*entry\r// misses counts the number of loads since the read map was last updated that\r// needed to lock mu to determine whether the key was present.\r//\r// Once enough misses have occurred to cover the cost of copying the dirty\r// map, the dirty map will be promoted to the read map (in the unamended\r// state) and the next store to the map will make a new dirty copy.\rmisses int\r}\rtype readOnly struct {\rm map[interface{}]*entry\ramended bool // true if the dirty map contains some key not in m.\r}\rtype entry struct {\rp unsafe.Pointer // *interface{}\r// 用指针,是为了方便的 atomic.CompareAndSwapPointer,可以直接修改read.m中本来应该只读的数据\r}\r// 这里的interface{}, 就是键值对的值,LoadOrStore(k ,v interface{}) 中的v\r// 删除: p将指向 unsafe.Pointer(new(interface{}))\rfunc newEntry(i interface{}) *entry {\rreturn \u0026amp;entry{p: unsafe.Pointer(\u0026amp;i)}\r}\r 相信这个图加上上面的注释已经解释的差不多了 ref\nsync的结构为:\rtype sync.Map{\rmutex\rread{m map[interface{}]*entry , amended } atomic.Value\rdirty map[interface{}]*entry\rmisses\r}\r 一文以蔽之 ​\t在大多数时刻,dirty都是read.m的超集,除了dirty刚覆盖read.m后,dirty被置为nil,read.amend置为false,表示read.m即为全部的数据, 在下一次写到来后,将会遍历read.m,将kv存进dirty,并将read.amend置为true,表示dirty是read.m的数据的超集!\n​\t什么时候触发dirty对read.m的覆盖? 当 m.misses \u0026gt;= len(m.dirty)时\n 注意,无效的读Load也会导致miss次数增加!\n 总结一下sync.map的关键   对于本来的map[interface{}] interface{} ,用unsafe.Pointer存储\u0026amp;value, 即unsafe.Pointer是*interface{};\n 导致可以利用atomic.CompareAndSwapPointer,直接操作readonly map,而无需加锁即可并发    dirty map大多数时候都是readonly map的超集!除了短暂的dirty覆盖read.m后的nil\n  覆盖后的第一次写dirty,会导致for range read.m, copy键值到dirty\n  适用于读多写少\n  ConcurrentMap  通过对内部map进行分片，降低锁粒度，从而达到最少的锁等待时间(锁冲突)\n 所谓分片,是指原先的map是一个大map,所有的key计算完的hash都是一个冲突域\n但是我现在不再是一个大map,而不是分成多个小map,我先计算key的一个hash,将其映射到小map上,然后对小map操作.\n这其实依赖于短时间内多个连续到来的key的hash值不同,那么它们就可以并行,否则就等待锁.\n 在此种情况下,hash函数的选择也至关重要,对于短时间内无序到来的key序列,如何尽可能的计算出短时间内不同的hash值  // A \u0026quot;thread\u0026quot; safe map of type string:Anything.\r// To avoid lock bottlenecks this map is dived to several (SHARD_COUNT) map shards.\r// shard: 碎片 var SHARD_COUNT = 32\rtype ConcurrentMap []*ConcurrentMapShared\r// A \u0026quot;thread\u0026quot; safe string to anything map.\rtype ConcurrentMapShared struct {\ritems map[string]interface{}\rsync.RWMutex // Read Write mutex, guards access to internal map.\r}\r 写 Store: 很简单,通过 shard := m.GetShard(key) 获得该key对应所在的ConcurrentMapShared,然后加锁,操作,释放锁;\n只要短时间内到来的key计算的hash值不同,那么就不会有锁竞争\n// Sets the given value under the specified key.\rfunc (m ConcurrentMap) Set(key string, value interface{}) {\r// Get map shard.\rshard := m.GetShard(key)\rshard.Lock()\rshard.items[key] = value\rshard.Unlock()\r}\r hash函数(Fowler–Noll–Vo hash function) ref\nfunc (m ConcurrentMap) GetShard(key string) *ConcurrentMapShared {\rreturn m[uint(fnv32(key))%uint(SHARD_COUNT)]\r}\r// Fowler–Noll–Vo hash function:\rfunc fnv32(key string) uint32 {\rhash := uint32(2166136261) const prime32 = uint32(16777619)\rfor i := 0; i \u0026lt; len(key); i++ {\rhash *= prime32\rhash ^= uint32(key[i])\r}\rreturn hash\r}\r 这个并发map最核心的思想已经讲完了,简单,却实用! 单个map也许做不了并发,但两个map(一读一写,写是读超集)搭配一个锁就可以做还行的并发,多个平行的map加 map级别的锁就能做很不错的并发\n除了并发的核心,这个库的其他代码其实也值得学习!\n比如并发中的扇入模式  利用chan,每个shard开启一个go程,并发返回所有的Key:   如果是同步的算法,那么时间复杂度是O(n^2),遍历了两次. 但使用了go程进行并发加速\n第一次计算有多少个key,即count,是有必要的,正是这个数值的确定,导致我们可以安心的创建count个缓冲的chan,并关闭通道\n对于无缓冲通道,适合只有一个go程生成数据,常见于lazy evaluate\n // Keys returns all keys as []string\rfunc (m ConcurrentMap) Keys() []string {\rcount := m.Count()\rch := make(chan string, count)\rgo func() {\rwg := sync.WaitGroup{}\rwg.Add(SHARD_COUNT)\rfor _, shard := range m {\rgo func(shard *ConcurrentMapShared) {\rshard.RLock()\rfor key := range shard.items {\rch \u0026lt;- key\r}\rshard.RUnlock()\rwg.Done()\r}(shard)\r}\rwg.Wait()\rclose(ch)\r}()\rkeys := make([]string, 0, count)\rfor k := range ch {\rkeys = append(keys, k)\r}\rreturn keys\r}\r 有缓冲优于无缓冲 // Iter returns an iterator which could be used in a for range loop.\r//\r// Deprecated: using IterBuffered() will get a better performence\rfunc (m ConcurrentMap) Iter() \u0026lt;-chan Tuple {\rchans := snapshot(m)\rch := make(chan Tuple)\rgo fanIn(chans, ch)\rreturn ch\r}\r// IterBuffered returns a buffered iterator which could be used in a for range loop.\rfunc (m ConcurrentMap) IterBuffered() \u0026lt;-chan Tuple {\rchans := snapshot(m)\rtotal := 0\rfor _, c := range chans {\rtotal += cap(c)\r}\rch := make(chan Tuple, total)\rgo fanIn(chans, ch)\rreturn ch\r}\r 个人认为,对于有缓冲的通道,有一个特别大的优点就是,发送完数据就可以直接关闭了;\n而如果无缓冲,就会一直阻塞,依赖于读的速度\nshard.RLock()\rchans[index] = make(chan Tuple, len(shard.items))\rwg.Done()\rfor key, val := range shard.items {\rchans[index] \u0026lt;- Tuple{key, val}\r}\rshard.RUnlock()\rclose(chans[index])\r  用一个简单的map分片解决了并发问题,而且肉眼可以看出性能不会太差,虽然占空间, 但仍然可以称之为优雅!\n","id":32,"section":"posts","summary":"Built-in map\u0026amp; sync.Map \u0026amp; ConcurrentMap 并发map,是指多线程安全的map数据结构, 我们知道go语言原生的map是不支持并发的, 要想获得一个并发map, 我们有如下的几种方","tags":["Go"],"title":"[Go] concurrentMap","uri":"https://liwm29.github.io/2021/03/go-concurrentmap/","year":"2021"},{"content":"Error go的error一直是被人诟病的,对于菜鸡来说无非是每调用一个函数就要判断一下if err!=nil{return err}\n而对于进阶一点的程序员,则会诟病它的error接口设计的太烂,只要实现了Error(),就是一个error,这导致难以比较\n直接返回error是一种错误的做法,因为当error被打印出来的时候,你无法知道这个error产生的调用过程,而只会得到一个干巴巴的最终原因\n因此,为了方便,我们要实现自己的error系统\nErrorx 这里以errorx这个包为例\nFeature 首先看看它的feature\n No extra care should be required for an error to have all the necessary debug information; it is the opposite that may constitute a special case There must be a way to distinguish one kind of error from another, as they may imply or require a different handling in user code Errors must be composable, and patterns like if err == io.EOF defeat that purpose, so they should be avoided // 这里是因为error的判断完全归结为接口类型的判断,这取决于类型和值,即使是对于一样的字符串,也有着不一样的地址,导致不等 Some context information may be added to the error along the way, and there must be a way to do so without altering the semantics of the error It must be easy to create an error, add some context to it, check for it A kind of error that requires a special treatment by the caller is a part of a public API; an excessive amount of such kinds is a code smell  看完之后,我们就大概知道std error的局限在哪里了\n在我们自定义的error系统中,我们至少要解决\n error应该是可比较的,这种可比较不应该和它Error()后的label有关(有点kind和type的感觉)  error既要有可变的类型type,也要有不变的特性trait   error应该可以较方便的追加上下文 error处理应该较快  Example var user_namespace_1 = errorx.NewNamespace(\u0026quot;user_namespace_1\u0026quot;)\rvar user_trait_1 = errorx.RegisterTrait(\u0026quot;user_trait_1\u0026quot;)\rvar user_property_1 = errorx.RegisterProperty(\u0026quot;user_property_1\u0026quot;)\rvar user_property_1_p = errorx.RegisterPrintableProperty(\u0026quot;user_property_1_p\u0026quot;)\rfunc main() {\rerr := errorx.AssertionFailed.New(\u0026quot;1\u0026quot;).WithProperty(user_property_1, \u0026quot;test1\u0026quot;).WithProperty(user_property_1_p, \u0026quot;test1_p\u0026quot;)\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rfmt.Printf(\u0026quot;typecheck: %t\\n\u0026quot;, err.IsOfType(errorx.AssertionFailed))\rfmt.Printf(\u0026quot;traitcheck: %t\\n\u0026quot;, err.HasTrait(errorx.Timeout()))\rerr = errorx.Decorate(err, \u0026quot;2\u0026quot;).WithProperty(user_property_1, \u0026quot;test2\u0026quot;).WithProperty(user_property_1_p, \u0026quot;test2_p\u0026quot;)\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rerr = errorx.IllegalArgument.Wrap(err, \u0026quot;3\u0026quot;)\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rerr = errorx.NewType(user_namespace_1, \u0026quot;userErrorType\u0026quot;, user_trait_1).Wrap(err, \u0026quot;4\u0026quot;)\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rfmt.Printf(\u0026quot;traitcheck: %t\\n\u0026quot;, err.HasTrait(user_trait_1))\r}\r PS C:\\Users\\salvare000\\Desktop\\benchmark\\errorx\u0026gt; go run .\rcommon.assertion_failed: 1 {user_property_1_p: test1_p}\rtypecheck: true\rtraitcheck: false\r2 {user_property_1_p: test2_p}, cause: common.assertion_failed: 1 {user_property_1_p: test1_p}\rcommon.illegal_argument: 3, cause: 2 {user_property_1_p: test2_p}, cause: common.assertion_failed: 1 {user_property_1_p: test1_p}\ruser_namespace_1.userErrorType: 4, cause: common.illegal_argument: 3, cause: 2 {user_property_1_p: test2_p}, cause: common.assertion_failed: 1 {user_property_1_p: test1_p}\rtraitcheck: true\r 类型系统  Error Namespace Type Trait Property  依赖关系 graph LR\rA[Error] --\u0026gt;B(Type)\rA[Error] --\u0026gt;C(Property)\rB[Type] --\u0026gt;D(Namespace)\rB[Type] --\u0026gt;E(Trait)\rD[Namespace] --\u0026gt;E(Trait)\r 类型组织Wrap graph LR\rA[Error1] --\u0026gt;B(Type1)\rA[Error1] --\u0026gt;a(Property)\rA[Error1] --\u0026gt;C[Error2]\rC[Error2] --\u0026gt;D(Type2)\rC[Error2] --\u0026gt;b(Property)\rF[Error3] --\u0026gt;E(Type3)\rF[Error3] --\u0026gt;e(Property)\rC[Error2] --\u0026gt;F[Error3]\r 类型组织Decorate 本质是设置Error的isTraparent = True\ngraph LR\rA[Error1] --\u0026gt;a(Property)\rA[Error1] --\u0026gt;C[Error2]\rC[Error2] --\u0026gt;b(Property)\rF[Error3] --\u0026gt;E(Type3)\rF[Error3] --\u0026gt;e(Property)\rC[Error2] --\u0026gt;F[Error3]\r Trait 定义trait,所有的error类型应该都包含一个或多个trait\n// Trait is a static characteristic of an error type.\r// All errors of a specific type possess exactly the same traits.\r// Traits are both defined along with an error and inherited from a supertype and a namespace.\rtype Trait struct {\rid uint64\rlabel string\r}\r 内置trait\nvar (\rtraitTemporary = RegisterTrait(\u0026quot;temporary\u0026quot;)\rtraitTimeout = RegisterTrait(\u0026quot;timeout\u0026quot;)\rtraitNotFound = RegisterTrait(\u0026quot;not_found\u0026quot;)\rtraitDuplicate = RegisterTrait(\u0026quot;duplicate\u0026quot;)\r)\rfunc newTrait(label string) Trait {\rreturn Trait{\rid: nextInternalID(),\rlabel: label,\r}\r}\r Type 每个error type都要依托于一个namespace,即error的类型是与领域有关的,我觉得这个设计挺好\n使用一个map来表示一个type是否有一个trait(优化也很简单,用一个uint64,但是只支持最多64个traits,但大多数时候够用)\ntype Type struct {\rnamespace Namespace\rparent *Type\rid uint64\rfullName string\rtraits map[Trait]bool\rmodifiers modifiers\r}\r 常见内置错误类型,注册在\u0026quot;common\u0026quot; namespace下\n这些type都没有traits\nvar (\r// CommonErrors is a namespace for general purpose errors designed for universal use.\r// These errors should typically be used in opaque manner, implying no handing in user code.\r// When handling is required, it is best to use custom error types with both standard and custom traits.\rCommonErrors = NewNamespace(\u0026quot;common\u0026quot;)\r// IllegalArgument is a type for invalid argument error\rIllegalArgument = CommonErrors.NewType(\u0026quot;illegal_argument\u0026quot;)\r// IllegalState is a type for invalid state error\rIllegalState = CommonErrors.NewType(\u0026quot;illegal_state\u0026quot;)\r// IllegalFormat is a type for invalid format error\rIllegalFormat = CommonErrors.NewType(\u0026quot;illegal_format\u0026quot;)\r// InitializationFailed is a type for initialization error\rInitializationFailed = CommonErrors.NewType(\u0026quot;initialization_failed\u0026quot;)\r// DataUnavailable is a type for unavailable data error\rDataUnavailable = CommonErrors.NewType(\u0026quot;data_unavailable\u0026quot;)\r// UnsupportedOperation is a type for unsupported operation error\rUnsupportedOperation = CommonErrors.NewType(\u0026quot;unsupported_operation\u0026quot;)\r// RejectedOperation is a type for rejected operation error\rRejectedOperation = CommonErrors.NewType(\u0026quot;rejected_operation\u0026quot;)\r// Interrupted is a type for interruption error\rInterrupted = CommonErrors.NewType(\u0026quot;interrupted\u0026quot;)\r// AssertionFailed is a type for assertion error\rAssertionFailed = CommonErrors.NewType(\u0026quot;assertion_failed\u0026quot;)\r// InternalError is a type for internal error\rInternalError = CommonErrors.NewType(\u0026quot;internal_error\u0026quot;)\r// ExternalError is a type for external error\rExternalError = CommonErrors.NewType(\u0026quot;external_error\u0026quot;)\r// ConcurrentUpdate is a type for concurrent update error\rConcurrentUpdate = CommonErrors.NewType(\u0026quot;concurrent_update\u0026quot;)\r// TimeoutElapsed is a type for timeout error\rTimeoutElapsed = CommonErrors.NewType(\u0026quot;timeout\u0026quot;, Timeout())\r// NotImplemented is an error type for lacking implementation\rNotImplemented = UnsupportedOperation.NewSubtype(\u0026quot;not_implemented\u0026quot;)\r// UnsupportedVersion is a type for unsupported version error\rUnsupportedVersion = UnsupportedOperation.NewSubtype(\u0026quot;version\u0026quot;)\r)\r Namespace // Namespace is a way go group a number of error types together, and each error type belongs to exactly one namespace.\r// Namespaces may form hierarchy, with child namespaces inheriting the traits and modifiers of a parent.\r// Those modifiers and traits are then passed upon all error types in the namespace.\r// In formatting, a dot notation is used, for example:\r//\r// namespace.sub_namespace.type.subtype\r//\rtype Namespace struct {\rparent *Namespace\rid uint64\rname string\rtraits []Trait\rmodifiers modifiers\r}\r Error Error类似一个链表,每改动一下,都不是在原Error上改动,而是生成一个新的Error,并将原Error作为新Error的cause字段(详见后续的Decorate)\n每个Error不仅有自己的Error Type,还有properties,这些properties都说动态的,指的的一些调用者希望传入的键值信息,因为单独的error可能只是表示某种错误,如果想知道现场的值的什么,用这个动态properties(怎么感觉和log很重叠)\ntype Error struct {\rmessage string\rerrorType *Type\rcause error\rstackTrace *stackTrace\r// properties are used both for public properties inherited through \u0026quot;transparent\u0026quot; wrapping\r// and for some optional per-instance information like \u0026quot;underlying errors\u0026quot;\rproperties *propertyMap\rtransparent bool\rhasUnderlying bool\rprintablePropertyCount uint8\r}\r 行为 Decorate decorate只是用于添加一些上下文信息,不会更改Error的类型,更不会改变Error的traits和properties\n从下面的代码可以看出,即使是Decorate,也是新建了一个Error结构体,并将原err作为自己的cause字段,为了表示自己不是一个真正的Error类型,标识自己是transparentWrapper\n// 装饰不会改变error的type,traits,properties\rfunc Decorate(err error, message string, args ...interface{}) *Error {\rreturn NewErrorBuilder(transparentWrapper).\rWithConditionallyFormattedMessage(message, args...).\rWithCause(err).\rCreate()\r}\rfunc NewErrorBuilder(t *Type) ErrorBuilder\r Wrap 如果你想改变Error的type(这导致在与原Error进行type check时失败,有时这的确是我们想要的)\nfunc (t *Type) Wrap(err error, message string, args ...interface{}) *Error {\rreturn NewErrorBuilder(t).\rWithConditionallyFormattedMessage(message, args...).\rWithCause(err).\rCreate()\r}\r Type Check 判断两个Error是否是同一个类型,或对方是否是自己类型的祖先\n// IsOfType is a type check for errors.\r// Returns true either if both are of exactly the same type, or if the same is true for one of current type's ancestors.\r// For an error that does not have an errorx type, returns false.\rfunc IsOfType(err error, t *Type) bool {\re := Cast(err)\treturn e != nil \u0026amp;\u0026amp; e.IsOfType(t)\r}\rfunc Cast(err error) *Error // Cast函数将标准库error接口断言成errorx.Error\r 这个函数单纯的使用for loop跳过透明Error层,即Decorate:\nfunc (e *Error) IsOfType(t *Type) bool {\rcause := e\rfor cause != nil {\rif !cause.transparent { return cause.errorType.IsOfType(t)\r}\rcause = Cast(cause.Cause())\r}\rreturn false\r}\r 判断自己是否是对方的类型的继承者(必须在一个namespace内),或自己是否就是对方类型\n// Returns true either if both are of exactly the same type, or if the same is true for one of current type's ancestors.\rfunc (t *Type) IsOfType(other *Type) bool {\rcurrent := t\rfor current != nil {\rif current.id == other.id {\rreturn true\r}\rcurrent = current.parent\r}\rreturn false\r}\r Trait Check 无他,就是单纯检查type的trait,type祖先的trait,namespace的trait,namespace祖先的trait\n编码技巧 builder模式创建error 由于error的参数较多,选择建造者模式来构造error\n建造者模式的好处是,我们是对option结构体不断修改,最终build出一个完整的error,这样,只要error出现,就是完好的,而不是一步一步的去设置error的字段\ntype ErrorBuilder struct {\rmessage string\rerrorType *Type\rcause error\rmode callStackBuildMode\risTransparent bool\r}\r 使用链式调用来set字段 func (eb ErrorBuilder) WithCause(err error) ErrorBuilder\rfunc (eb ErrorBuilder) Transparent() ErrorBuilder\rfunc (eb ErrorBuilder) EnhanceStackTrace() ErrorBuilder\rfunc (eb ErrorBuilder) WithConditionallyFormattedMessage(fmt string, args ...interface{}) ErrorBuilder\r 打印特性 实现fmt.Printf()接口 func (e *Error) Format(s fmt.State, verb rune) {\rmessage := e.fullMessage()\rswitch verb {\rcase 'v':\rio.WriteString(s, message)\rif s.Flag('+') {\re.stackTrace.Format(s, verb)\r}\rcase 's':\rio.WriteString(s, message)\r}\r}\r 运行时静态断言 以这样的方式明确指出,\n*Error类型满足fmt.Formatter接口\u0026hellip;\nvar _ fmt.Formatter = (*Error)(nil)\rvar _ encoding.TextMarshaler = (*Type)(nil)\r 设计缺陷与思考 Namespace与Type 个人感觉,完全没必要设置这个Namespace作为一个单独的结构体,但是Namespace作为逻辑上的一个域,是有必要的,但实现时,完全可以就直接只使用Type,因为目前来看,它的结构体字段上,二者是相似的,几乎无差.\n从逻辑的角度看,type不断继承,需要一个baseType,和type在一个namespace下,都说说的通的,所以,baseType和namespace,几乎是可以不加区分的\n再不济\ntype Namespace Type\r ","id":33,"section":"posts","summary":"Error go的error一直是被人诟病的,对于菜鸡来说无非是每调用一个函数就要判断一下if err!=nil{return err} 而对于进阶一点的程序员,则会诟病它的error接口设","tags":["Go"],"title":"[Go] errorx","uri":"https://liwm29.github.io/2021/03/go-errorx/","year":"2021"},{"content":"逃逸分析 首先,逃逸分析发生在编译时,由分析结果决定运行时对象应该在堆还是栈上分配\n注意: 这个编译时分析似乎是以函数为单位的静态分析,因此才有当函数参数是interface{}时,不知其具体类型\n规则  堆对象不能指向栈对象,否则栈对象被分配在堆上 其他\u0026hellip;.  典型场景 1.函数返回指向栈内对象的指针 func NewA()*a{\rreturn \u0026amp;a{123}\r}\r 2.调用反射(interface{}动态类型) 在反射的实现中,比如 reflect.ValueOf :\nfunc ValueOf(i interface{}) Value {\rif i == nil {\rreturn Value{}\r}\r// TODO: Maybe allow contents of a Value to live on the stack.\r// For now we make the contents always escape to the heap. It\r// makes life easier in a few places (see chanrecv/mapassign\r// comment below).\rescapes(i)\rreturn unpackEface(i)\r}\r 直接对i逃逸了,那么i指向的内存必然也逃逸,所以传进去的值便逃逸了\n 因此,不是说往func(interface{})传值,或者往func(*struct)传指针就会导致逃逸分析.\n  只是大多数场景下,其内部都会用到反射,导致逃逸(switch type不会导致逃逸)\n 拼接字符串 比如:\nvar strt = \u0026quot;asdf\u0026quot;\r//go:noinline\rfunc t(i *int) string{\r*i += 1\rreturn \u0026quot;asdf\u0026quot;+strt\r}\r .\\a.go:15:15: \u0026quot;asdf\u0026quot; + strt escapes to heap\r 很奇怪,直接return string(\u0026ldquo;asdf\u0026rdquo;)却不会导致逃逸,按道理string{ptr,len}的结构,这个ptr应该会逃逸才对\n-gcflags \u0026ldquo;-m -l\u0026rdquo;  -m 设置打印信息 -l禁止内联, 也可用//go:noinline  三个典型输出的意义: (https://groups.google.com/g/golang-dev/c/Cf4tpaWP6rc)\n \u0026ldquo;moved to heap\u0026rdquo; means that a local variable was allocated on the heap\nrather than the stack.\n  \u0026ldquo;leaking param\u0026rdquo; means that the memory associated with some parameter\n(e.g., if the parameter is a pointer, the memory to which it points)\nwill escape. This typically means that the caller must allocate that\nmemory on the heap.\n  \u0026ldquo;escapes to heap\u0026rdquo; means that some value was copied into the heap.\nThis differs from \u0026ldquo;moved to heap\u0026rdquo; in that with \u0026ldquo;moved to heap\u0026rdquo; the\nvariable was allocated in the heap. With \u0026ldquo;escapes to heap\u0026rdquo; the value\nof some variable was copied, for example when assigning to a variable\nof interface type, and that copy forced the value to be copied into a\nnewly allocated heap slot.\n \u0026ldquo;moved to heap\u0026rdquo; and \u0026ldquo;escapes to heap\u0026rdquo; both always mean a heap allocation occurs. The difference is \u0026ldquo;moved to heap\u0026rdquo; is used for named variables, and \u0026ldquo;escapes to heap\u0026rdquo; is used for anonymous variables (e.g., as allocated by \u0026ldquo;new\u0026rdquo; or \u0026ldquo;make\u0026rdquo;; taking the address of a composite literal).\n个人理解:\nmove常用于普通变量的,由于生命周期的原因导致的需要分配在堆上\nescape常用于匿名变量,比如st.a = new(int),或者传入interface{}\n编译指令 运行时判断一个对象在不在堆上\n 一般的,如果//后没有空格,那么就是编译指令,常见的还有generate\n  https://www.yuque.com/flipped-aurora/gqbcfk/io1db4\n //go:linkname inheap runtime.inheap\rfunc inheap(b uintptr) bool\r// example\rprintln(inheap(uintptr(unsafe.Pointer(\u0026amp;m))))\rprintln(inheap(uintptr(unsafe.Pointer(m.b))))\r 其他 个人感觉,不必深究,知道基础的就好\n声明:看看就好,不一定对\n","id":34,"section":"posts","summary":"逃逸分析 首先,逃逸分析发生在编译时,由分析结果决定运行时对象应该在堆还是栈上分配 注意: 这个编译时分析似乎是以函数为单位的静态分析,因此才有当","tags":["Go"],"title":"[Go] escape analysis","uri":"https://liwm29.github.io/2021/03/go-escape-analysis/","year":"2021"},{"content":"垃圾回收算法 https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/\n有两种常见的自动管理堆内存的方法:\n 引用计数/智能指针 追踪式垃圾回收(对堆内存的对象关系图进行可达性分析)  术语  根对象: 包括所有栈上对象,全局变量  标记-清扫法(mark-sweep) 典型的STW(stop the world)算法,当进行垃圾回收时,先暂停用户程序,然后从根对象出发对堆对象进行可达性标记(比如bfs/dfs),标记完后遍历所有的堆对象,回收掉不可达对象\n三色标记法  这是一种并发算法,不需要或只需要短暂的暂停用户程序\n 定义三色: 黑白灰\n 灰色: 可达对象 黑色: 由灰色衍生出来的可达对象 白色: 不可达对象  算法流程:\n首先所有根对象置为灰色\n 从灰色对象中选择一个,置为黑色对象 将黑色对象指向的所有对象置为灰色 重复1,2,直到不存在灰色对象 回收剩余的白色对象  由于在标记过程中,对象图可能改变,所以需要作如下操作:\n 修改指针之前,必须先对被指向的对象标记为灰色,由于现代cpu的乱序执行和多发射,这需要我们用写内存屏障来实现  屏障   插入写屏障\n  writePointer(slot, ptr):\rshade(ptr) //染灰\r*slot = ptr\r     删除写屏障\n  writePointer(slot, ptr)\rshade(*slot) //染灰\r*slot = ptr\r     混合写屏障(v1.8引入)\n  writePointer(slot, ptr):\rshade(*slot)\rif current stack is grey:\rshade(ptr)\r*slot = ptr\r      注意: 不会在所有的根对象上开启写屏障,因为一个程序可能由成百上千个goroutine,如果在所有的goroutine的栈上开启写屏障,压力太大\n  看了了b站刘丹冰的视频后,有了更深的理解\ngo的gc算法:\nv1.3 StopTheWorld 标记清扫法 stw-\u0026gt;mark-\u0026gt;sweep-\u0026gt;stw\n优化: stw-\u0026gt;mark-\u0026gt;stw-\u0026gt;sweep(串行标记,并发清扫)\nv1.5 三色标记法 这里的mark是分层的bfs.\n这个方法可以解决并发吗?\n对于新创建的对象:\n对于已有对象的并发标记问题:\n如果一个白色对象原来被正常引用(或是作为白色新创建节点,被黑色对象引用), 在mark过程中变为仅被黑色对象引用,显然就会最终仍是白色,被丢失,这是因为三色标记法是基于灰色对象标记下一个灰色对象的,不会对黑色对象所引用的对象标记\n解决方法:\n强三色不变性: 禁止mark过程中的黑色对象指向白色对象\n弱三色不变性: 一个白色对象的上游链路必须存在灰色对象,此时其可被黑色对象引用(只要上游灰色存在,最终一定会标记到自己)\n如何实现:\n屏障技术(实际上,就是在变更引用关系的时候触发回调函数)\n 初始时 A.field1 = B\n变更: A.field1 = C\n则: B触发删除写屏障,C触发插入写屏障(要么开启删除写屏障,要么开启插入写屏障)\n最后v1.8 优化为混合写屏障\n 插入写屏障:\n​\t被黑色节点引用的对象置灰色\n​\t1. 堆空间作为根节点时,白色对象若被黑色对象引用,触发回调,自己置为灰色\n​\t2. 栈空间不触发插入屏障,这是为了保证速度. 所以为了保证新节点不丢失,要最后stw扫描栈,重新扫描mark一次\n因此:\n插入写屏障的不足: 结束时stw扫描栈,10-100ms\n删除写屏障:\n​\t被删除的对象直接置为灰色\n​\t显然,如果这个对象确实是不再被引用,而不是变更为被黑色对象引用,那么这个对象就会在本轮不被删除,但是无论如何,下轮gc仍然删除.所以缺点就是有可能造成延迟删除.但是这不可避免,因为你无法判断他是变更引用关系到黑色对象上,还是真的删了,只能先妥协一轮.\nv1.8混合写屏障:\n 栈上对象(根节点为栈)全部置为黑色,后续被栈引用的新对象均置为黑色(防止重复stw扫描栈)  栈不开启写屏障   堆上被删除的对象置为灰色 堆上被插入的对象置为灰色  满足弱三色不变性\n 注意这里,栈对象也是分配在堆上的,因为go程是用户态的,详见GMP\n ","id":35,"section":"posts","summary":"垃圾回收算法 https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/ 有两种常见的自动管理堆内存的方法: 引用计数/智能指针 追踪式垃圾回收(对堆内存的对象关系图进行可达性分析) 术语 根对象: 包括所有栈","tags":["Go"],"title":"[Go] GC","uri":"https://liwm29.github.io/2021/03/go-gc/","year":"2021"},{"content":"Goroutine Pool  代码来自:gobwas/ws-example\n 在go中,由于goroutine是完全的用户态线程,所以创建新线程的开销很小,在这种情况下,复用goroutine形成goroutine池的优化效果很有限\n但是,池不仅减少了创建开销,还能有效的限制对象个数\n因此,假如我们的服务期望有最大的goroutine个数限制,将需要使用goroutine pool\n设计 一个goroutine pool需要什么呢?\n需要: 当前运行的gorotine数,最大goroutine数,任务队列,条件变量/信号量(用于线程阻塞等待任务)\n但是在go中,chan是天然的一个阻塞队列,任务队列本身就完成了阻塞唤醒的功能\n对于curr_n_thread和max_n_thread,本来应该用两个int去存,但是在go中,也可以用chan struct{},因为有缓冲的通道天然有上限,并且增加减少都是并发安全的\n 虽然用sem chan struct{}表示goroutine数目的限制很炫,但是确实不如int去存有用,毕竟int能反映当前运行的goroutine数目,而sem chan struct{}只能限制最大数\n type Pool struct {\rsem chan struct{}\rwork chan func()\r}\r NewPool 创建一个pool\n size: max_n_thread\nqueue: 等待队列上限(最大等待任务数)\nspawn: 立即运行多少工作线程\n func NewPool(size, queue, spawn int) *Pool {\rif spawn \u0026lt;= 0 \u0026amp;\u0026amp; queue \u0026gt; 0 {\rpanic(\u0026quot;dead queue configuration detected\u0026quot;)\r}\rif spawn \u0026gt; size {\rpanic(\u0026quot;spawn \u0026gt; workers\u0026quot;)\r}\rp := \u0026amp;Pool{\rsem: make(chan struct{}, size),\rwork: make(chan func(), queue),\r}\rfor i := 0; i \u0026lt; spawn; i++ {\rp.sem \u0026lt;- struct{}{}\rgo p.worker(func() {})\r}\rreturn p\r}\r 分配任务 只需要简单的往通道里丢任务就可以了\n注意,这里的实现是有问题的,原作者可能是想实现:优先想p.work发送任务,如何P.work满了还没有被消费,就新开一个工作线程\n但是go的select是没有顺序的,所以我们必须拆分一下\nfunc (p *Pool) Schedule(task func()) {\rp.schedule(task, nil)\r}\rfunc (p *Pool) schedule(task func(), timeout \u0026lt;-chan time.Time) error {\rselect {\rcase \u0026lt;-timeout:\rreturn ErrScheduleTimeout\rcase p.work \u0026lt;- task:\rreturn nil\rcase p.sem \u0026lt;- struct{}{}:\rgo p.worker(task)\rreturn nil\r}\r}\r =\u0026gt;\nfunc (p *Pool) schedule(task func(), timeout \u0026lt;-chan time.Time) error {\rselect{\rcase p.work \u0026lt;- task:\rreturn nil\rdefault:\r}\rselect {\rcase \u0026lt;-timeout:\rreturn ErrScheduleTimeout\rcase p.work \u0026lt;- task:\rreturn nil\rcase p.sem \u0026lt;- struct{}{}:\rgo p.worker(task)\rreturn nil\r}\r}\r 或:\nselect {\rcase \u0026lt;-timeout:\rreturn ErrScheduleTimeout\rcase p.work \u0026lt;- task:\rreturn nil\rcase p.sem \u0026lt;- struct{}{}:\rselect{\rcase p.work \u0026lt;- task:\r\u0026lt;- p.sem\rreturn nil\rdefault:\r}\rgo p.worker(task)\rreturn nil\r}\r 工作线程等待分发任务 由于chan的自阻塞性,极易实现,当然这个没有实现线程的退出,如果想实现,可以使用一个退出chan,然后每个线程去竞争done,就像竞争任务一样\nfunc (p *Pool) worker(task func()) {\rdefer func() { \u0026lt;-p.sem }()\rtask()\rfor task := range p.work {\rtask()\r}\r}\r 加了退出通道的工作线程\nfunc (p *Pool) worker(task func()) {\rdefer func() { \u0026lt;-p.sem }()\rtask()\rfor task := range p.work {\rtask()\rselect{\rcase \u0026lt;- p.done:\rreturn\rdefault:\r}\r}\r}\rfunc (p *Pool) ReduceOne(){\rp.done \u0026lt;- struct{}{}\rp.work \u0026lt;- func(){} // 发送一个空任务,防止工作线程阻塞在p.work而接收不到p.done\r}\r 当然,更好的写法是直接同等地位的判断p.work和p.done:\nfunc (p *Pool) worker(task func()) {\rdefer func() { \u0026lt;-p.sem }()\rtask()\rfor {\rselect{\rcase task := \u0026lt;- p.work:\rtask()\rcase \u0026lt;- p.done\rreturn\r}\r}\r}\r Ants库 github上看到了一个5.2k star的协程库,首先不管技术架构和代码风格,看到readme的几张大图,就感动的哭了,这就是所谓的一分钟上手!\n1h后,我只想说挺捞的.\nreadme有很多错误或不足:\n 作者似乎区分不清throughput和one-way latency; 配图也比较老旧了,和代码对不上; go test , 某些协程发生了panic 性能测试是基于工作是sleep的,这相当于又将开销放到了go自己的阻塞调度上  我自己基于如下的工作函数重新测了下:\nfunc demoFunc() {\rbegin := time.Now()\ri := 0\rfor {\ri++\rend := time.Now()\rif end.UnixNano()-begin.UnixNano() \u0026gt; int64(time.Millisecond)*10 {\rreturn\r}\r}\r}\r goos: windows\rgoarch: amd64\rpkg: a/ants\rcpu: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\rBenchmarkPlainPool\rBenchmarkPlainPool-8 1 13103489000 ns/op 6123848 B/op\r54292 allocs/op\rBenchmarkGoroutines\rBenchmarkGoroutines-8 1 13296742800 ns/op 4290672 B/op\r10006 allocs/op\rBenchmarkAntsPool\rBenchmarkAntsPool-8 1 13276752000 ns/op 2631920 B/op\r41997 allocs/op\rPASS\rok a/ants 39.795s\r 这里的plainPool指的就是我们上面自己实现的pool\n可以看到,整个的吞吐率是差不多的,测试完成时间都是13s(所以加起来是39s),但是ants确实降低了1倍的内存消耗\n至于单向提交延迟,我个人感觉意义不太大.协程池的主要优点应该在内存上,避免了无节制的新建内存.\n但是话又说回来,如果只是避免内存,那只需要加个计数器来限制就好了\n于是给ants提了个issue: https://github.com/panjf2000/ants/issues/144\nConclusion 协程池是有必要的,它所保证的__内存消耗与协程调度的上限__,增强了服务器对DOS攻击的耐受性.\n除此之外,在go中的优势似乎没有太多,不过,即使只有一点,也够了.\n","id":36,"section":"posts","summary":"Goroutine Pool 代码来自:gobwas/ws-example 在go中,由于goroutine是完全的用户态线程,所以创建新线程的开销很小,在这种情况下,","tags":["Go"],"title":"[Go] goroutine pool","uri":"https://liwm29.github.io/2021/03/go-goroutine-pool/","year":"2021"},{"content":"Monkey patch 猴子补丁 ref: https://bou.ke/blog/monkey-patching-in-go/\nIntro: 什么是monkey patch? package main\rfunc a() int { return 1 }\rfunc b() int { return 2 }\rfunc main() {\rreplace(a, b)\rprint(a()) // 2\r}\r monkey patch将做到如上的效果,当你调用a函数时,实际却调用了b函数,看起来有点神奇!\n这实际上是运行时改变了函数的行为\n实现原理 We need to modify function a to jump to b’s code instead of executing its own body\nfunc replace(orig, replacement func() int) {\rbytes := assembleJump(replacement) functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig))\rwindow := rawMemoryAccess(functionLocation)\rcopy(window, bytes)\r}\r   bytes := assembleJump(replacement) \n  生成跳转replacement的机器码,将用它来替换跳转orig的机器码\n  func assembleJump(f func() int) []byte {\rfuncVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f))\rreturn []byte{\r0x48, 0xC7, 0xC2,\rbyte(funcVal \u0026gt;\u0026gt; 0),\rbyte(funcVal \u0026gt;\u0026gt; 8),\rbyte(funcVal \u0026gt;\u0026gt; 16),\rbyte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal\r0xFF, 0x22, // JMP [rdx]\r}\r}\r     functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig))\n  获取orig的函数位置\n  注意,这里涉及函数赋值,原函数赋值给了orig,这也是原文为什么先分析func a(){} ; f := a的原因\n  函数变量的内部结构(注意区分函数变量和函数):\ntype funcval struct {\rfn uintptr\r// variable-size, fn-specific data here (典型的,闭包的实现需要引用外部变量,放在这)\r}\r 因此,functionLocation 将等于fn\n    window := rawMemoryAccess(functionLocation)\n  获取由functionLocation开始的0xFF大小的内存空间\n  func rawMemoryAccess(b uintptr) []byte {\rreturn (*(*[0xFF]byte)(unsafe.Pointer(b)))[:]\r}\r     copy(window, bytes)\n 注意不是全部覆盖0xFF那么大,因为bytes没有那么大    ","id":37,"section":"posts","summary":"Monkey patch 猴子补丁 ref: https://bou.ke/blog/monkey-patching-in-go/ Intro: 什么是monkey patch? package main func a() int { return 1 } func b() int { return 2 } func main() { replace(a, b) print(a()) // 2 } monkey patch将做到如上的效果,当你调用a函数时,实际","tags":["Go"],"title":"[Go] monkey patch","uri":"https://liwm29.github.io/2021/03/go-monkey-patch/","year":"2021"},{"content":"mutex 结构 type Mutex struct {\rstate int32\rsema uint32\r}\r 自旋\nfor{\rcas(m.state)\r}\r 阻塞\nwait(m.sema)\r 状态  普通模式  就是正常的模式,线程相互竞争获得锁   饥饿模式  由于线程竞争失败会阻塞,而这些被唤醒的线程会和其他第一次来申请锁的线程一起竞争,显然,不可能竞争过,因为新的线程是占据着cpu的 这会导致阻塞线程的饥饿,因此,mutex加入了饥饿模式,当进入饥饿模式后,锁直接赋予阻塞队列的第一个线程,新线程自动加入阻塞队列     注意,对锁的竞争,有两大来源,一是新线程,二是被阻塞线程(由于锁的释放而被唤醒),新线程如果自旋一段时间后未获得锁,便进入阻塞态,加入该锁的等待队列\n 加锁 Lock 对申请锁的情况分为三种：\n 无冲突，通过 CAS 操作把当前状态设置为加锁状态 有冲突，开始自旋轮询，并等待锁释放，如果其他 goroutine 在这段时间内释放该锁，直接获得该锁；如果没有释放则为下一种情况 有冲突，且已经过了自旋阶段，通过调用 semrelease 让 goroutine 进入等待状态   摘自 https://golang.design/under-the-hood/zh-cn/part4lib/ch15sync/mutex/\n  goroutine会自旋轮询四次,如果失败,就在信号量上阻塞睡眠\n FSM  进入饥饿模式  如果一个 goroutine 等待 mutex 释放的时间超过 1ms，它就会将 mutex 切换到饥饿模式   退出饥饿模式  它是等待队列中的最后一个 它等待的时间少于 1ms    ","id":38,"section":"posts","summary":"mutex 结构 type Mutex struct { state int32 sema uint32 } 自旋 for{ cas(m.state) } 阻塞 wait(m.sema) 状态 普通模式 就是正常的模式,线程相互竞争获得锁 饥饿模式 由于线程竞争失败会阻塞,而这些被唤醒的线程会和","tags":["Go"],"title":"[Go] mutex","uri":"https://liwm29.github.io/2021/03/go-mutex/","year":"2021"},{"content":"","id":39,"section":"posts","summary":"","tags":["Go"],"title":"[Go] netaddr","uri":"https://liwm29.github.io/2021/03/go-netaddr/","year":"2021"},{"content":"Radix树 又叫压缩前缀树,基数树,常用于路由匹配上,会将路由组织成一颗radix树\n","id":40,"section":"posts","summary":"Radix树 又叫压缩前缀树,基数树,常用于路由匹配上,会将路由组织成一颗radix树","tags":["Go"],"title":"[Go] radix-tree","uri":"https://liwm29.github.io/2021/03/go-radix-tree/","year":"2021"},{"content":"什么是反射? 反射提供了一种运行时能对对象增删查改的方法.\n换句话说,当函数参数的interface{}时,提供了一种访问原来的类型和值的方法. 这与switch type类似,但是switch只能对type进行判断,而你根本不知道会传进来何种自定义的结构体,这就是需要判断reflect.kind了\n(Value) Elem() Value  Elem returns the value that the interface v contains or that the pointer v points to. It panics if v\u0026rsquo;s Kind is not Interface or Ptr. It returns the zero Value if v is nil.\n reflect.Value.Elem(),必须接收Interface或Ptr类型的Kind,它将会返回其指向或包含的类型.\n这很好理解,如果reflect.Value{\u0026amp;a},那么Elem()后,就会返回reflect.Value{a}.\n但是,什么时候reflect.Value会是一个Interface呢?\nValueOf(i interface{}) Value  ValueOf returns a new Value initialized to the concrete value stored in the interface i. ValueOf(nil) returns the zero Value.\n 当我们执行如下代码时:\nvar i interface{} = 1\rx := reflect.ValueOf(i).Kind()\rfmt.Println(x) // int\r 为什么呢?\n 明明传入的是一个interface{}类型的 i  再看文档,它明确的说明了 initialized to the concrete value stored in the interface,因此,具体值将会被取出,那么既然都会被取出,难道还存在interface包一个interface吗? 即取出来后还是一个interface?\n 答案是不可能的,https://blog.golang.org/laws-of-reflection 说明了 An interface variable can store any concrete (non-interface) value  再看另一个问题,为什么reflect.ValueOf一定要把interface里面的具体值取出来呢,留在那里,我们自己调用Elem取出来不行吗?\n  我们要注意,reflect.ValueOf(i interface{})的函数签名,我们知道对于空接口,其内部和reflect.Value是类似的结构,都是(type,dataPtr)\n  如果传入的是a (int, \u0026amp;1),那么首先发生简单的浅复制: i = a =\u0026gt; i(int,\u0026amp;1). 然后返回reflect.Value{i.type,i.dataPtr,\u0026hellip;},可以看出,所谓的取出,本质是interface{}的type,dataPtr被复制转移到了reflect.Value\n  如果传入的是\u0026amp;a, 那么经过浅复制,i将会是 (interface , \u0026amp;a). 这是自然的,对x T取地址\u0026amp;x将产生*T指向x,所以\u0026amp;a将产生*interface{}指向a\n  func test(i interface{}) {\rswitch i.(type) {\rcase *int:\rfmt.Println(\u0026quot;*int\u0026quot;)\rcase int:\rfmt.Println(\u0026quot;int\u0026quot;)\rcase *interface{}:\rfmt.Println(\u0026quot;*interface\u0026quot;)\rdefault:\rfmt.Println(\u0026quot;not this\u0026quot;)\r}\r}\rfunc main(){\rvar i interface{} = 1\rtest(i) // int\rtest(\u0026amp;i) // *interface\r}\r Value.Kind() == Interface 执行如下代码:\nvar i interface{} = 1\rx := reflect.ValueOf(i).Kind()\rfmt.Println(x) // int\rfmt.Println(reflect.ValueOf(\u0026amp;i).Elem().Kind()) // interface\rv := reflect.ValueOf(struct{ a interface{} }{1})\rfmt.Println(v.Field(0).Kind()) // interface\r 当我们传递\u0026amp;i给ValueOf的时候,就会返回一个Ptr,然后我们调用Elem(),便得到了interface\n或者访问结构体的字段,也可以得到interface.\nType.Kind() == Interface 前面介绍了Value.Kind(),与之类似的,还有Type.Kind()\nreflect.TypeOf([]interface{}{1, 2}).Elem().Kind() == reflect.Interface // true\n (Type)Elem() : Elem returns a type\u0026rsquo;s element type. It panics if the type\u0026rsquo;s Kind is not Array, Chan, Map, Ptr, or Slice.\n ","id":41,"section":"posts","summary":"什么是反射? 反射提供了一种运行时能对对象增删查改的方法. 换句话说,当函数参数的interface{}时,提供了一种访问原来的类型和值的方法.","tags":["Go"],"title":"[Go] reflect","uri":"https://liwm29.github.io/2021/03/go-reflect/","year":"2021"},{"content":"Runtime Struct: 运行时结构体构造方法 参考:\nhttps://github.com/itsubaki/gostruct\nhttps://pkg.go.dev/reflect#example-StructOf\nreflect.New(typ reflect.Type) reflect.Value  New returns a Value representing a pointer to a new zero value for the specified type. That is, the returned Value\u0026rsquo;s Type is PtrTo(typ).\n 因此,给定一个结构体类型的type,我们就可以构造出value\nreflect.StructOf(fields []reflect.StructField) reflect.Type  StructOf returns the struct type containing fields. The Offset and Index fields are ignored and computed as they would be by the compiler.\nStructOf currently does not generate wrapper methods for embedded fields and panics if passed unexported StructFields. These limitations may be lifted in a future version.\n 因此,给定[]reflect.StructField,就可以构造出type\n注: 其他类型同理,比如reflect.ChanOf,reflect.ArrayOf,reflect.SliceOf\nreflect.StructField // A StructField describes a single field in a struct.\rtype StructField struct {\r// Name is the field name.\rName string\r// PkgPath is the package path that qualifies a lower case (unexported)\r// field name. It is empty for upper case (exported) field names.\r// See https://golang.org/ref/spec#Uniqueness_of_identifiers\rPkgPath string\rType Type // field type\rTag StructTag // field tag string\rOffset uintptr // offset within struct, in bytes\rIndex []int // index sequence for Type.FieldByIndex\rAnonymous bool // is an embedded field\r}\r 根据reflect.StructOf的文档和自身的注释(见上文),Offset,Index都不需要指定,Anonymous也不支持(go1.13),name必须capital,PkgPath也为空\n总结来说,我们需要指定:\niField := reflect.StructField{\rName: \u0026quot;Id\u0026quot;,\rType: reflect.TypeOf(uint64(0)),\rTag: `json:\u0026quot;id\u0026quot;`, // optional\r}\r Build typ := reflect.StructOf([]reflect.StructField{\r{\rName: \u0026quot;Height\u0026quot;,\rType: reflect.TypeOf(float64(0)),\rTag: `json:\u0026quot;height\u0026quot;`,\r},\r{\rName: \u0026quot;Age\u0026quot;,\rType: reflect.TypeOf(int(0)),\rTag: `json:\u0026quot;age\u0026quot;`,\r},\r})\rv := reflect.New(typ).Elem()\rv.Field(0).SetFloat(0.4)\rv.Field(1).SetInt(2)\rs := v.Addr().Interface()\r 一般来说,使用时,比如将其返回,要转换成Interface{}\n为了方便的用string访问字段,而不是index,我们可以自己包装一层,然后加上Interface(),Addr()两个方法\ntype myStruct struct {\rinternal reflect.Value\rindex map[string]int\r}\rfunc (i *myStruct) Field(name string) reflect.Value {\rreturn i.internal.Field(i.index[name])\r}\rfunc (i *myStruct) Interface() interface{} {\rreturn i.internal.Interface()\r}\rfunc (i *myStruct) Addr() interface{} {\rreturn i.internal.Addr().Interface()\r}\r 调用Addr()方法,可用于取地址,常用于调用指针接收者的方法\n Addr is typically used to obtain a pointer to a struct field or slice element in order to call a method that requires a pointer receiver.\n 用处 母鸡,暂时不太知道运行时构建结构体的用处\n我唯一用到反射的地方,就只有解析结构体字段了,比如把struct转成map这种\n但是以此来作为熟悉refelct包,还是不错的\n","id":42,"section":"posts","summary":"Runtime Struct: 运行时结构体构造方法 参考: https://github.com/itsubaki/gostruct https://pkg.go.dev/reflect#example-StructOf reflect.New(typ reflect.Type) reflect.Value New returns a Value representing a pointer to a new zero value for the specified type. That is, the returned Value\u0026rsquo;s Type is PtrTo(typ). 因此,给定一个结构体类型的type,我们就可以构造出","tags":["Go"],"title":"[Go] runtime struct builder","uri":"https://liwm29.github.io/2021/03/go-runtime-struct-builder/","year":"2021"},{"content":"[Go] 短变量声明 := 在Go中,提供了动态语言常用的一种直接声明并赋值的语法糖,即 := 短变量声明\n := 这个符号,可能是借鉴了Pascal\n 短变量声明有一定的要注意的地方,它与先声明后赋值有着一定的区别:\n1 短变量声明无法用于全局变量的创建\n2 短变量定义函数时无法使用递归\na := func(){\ra() // undeclared name: a\r}\rvar a func()\ra = func(){\ra() // ok!\r}\r 3 多变量赋值,左端必须有一项是新定义的变量\n 若在同一作用域, 已存在的变量将被覆盖. 否则,是定义新的局部变量  a,_ := f()\rif a,err := f();!err{\ra++\r}\rfmt.Println(a) // 这个a还是原来的a,因为if{}是个局部作用域\r ","id":43,"section":"posts","summary":"[Go] 短变量声明 := 在Go中,提供了动态语言常用的一种直接声明并赋值的语法糖,即 := 短变量声明 := 这个符号,可能是借鉴了Pascal 短变量声明有一定的","tags":["Go"],"title":"[Go] short var declare","uri":"https://liwm29.github.io/2021/03/go-short-var-declare/","year":"2021"},{"content":"[Go] Slice的下标索引细节 在刷oj的时候,经常遇到要对一个数组取一部分的场景,用来递归分治\n常见的比如快排,恢复二叉树等\n在c/c++中,我会使用func(int* array , int lo , int hi)来标识数组的范围,但是在python这种动态语言中,可以直接使用数组的切片,很方便的传入递归函数 func (slice[lo:hi])\n在go中,也有切片,也可以达到类似的效果,但是会存在一些你平时没有注意到的地方\n1. a[len(a):] 对于边界情况,要注意:\na := []int{1,2,3}\rlen(a[:0]) == 0 // true\rlen(a[len(a):]) == 0 // true\rlen(a[cap(a):]) == 0 // true\r 对于Line#3/4,一定要注意,不会越界!\n a[2:] // same as a[2 : len(a)]\ra[:3] // same as a[0 : 3]\ra[:] // same as a[0 : len(a)]\r  只要按如上的规则还原low和high后,若满足 rule 就不会越界\n但是如果cap=4,a[5:],就越界了\n2. cap 一定要注意\n high是否越界取决于cap low是否越界取决于len  当我们往递归函数不断传入切片后,因为都在引用同一个底层内存,所以其实存在某些时候看似越界,实则是因为cap比len大的原因\n如果想严格限制切片cap,那么在切片的时候,可以设置max参数:\nb := a[low : high : max]\r rule 这是spec上的切片下标的规则:\n0 \u0026lt;= low \u0026lt;= high \u0026lt;= max \u0026lt;= cap(a)\r 但我想补充一下:\nlow和high都可以 \u0026gt;=len(a),只要小于cap(a),都是合法的\r 新切片:\ncap(b) = max - low , len(b) = high - low\nref https://golang.org/ref/spec#Slice_expressions\n","id":44,"section":"posts","summary":"[Go] Slice的下标索引细节 在刷oj的时候,经常遇到要对一个数组取一部分的场景,用来递归分治 常见的比如快排,恢复二叉树等 在c/c++中,我会使","tags":["Go"],"title":"[Go] slice index detail","uri":"https://liwm29.github.io/2021/03/go-slice-index-detail/","year":"2021"},{"content":"Standard Package Layout 标准包布局 -Ben Johnson https://www.gobeyond.dev/standard-package-layout/\nVendoring和Generics,它们在go社区似乎都是big issue,但还有一个很少提及的issue,就是应用的包布局(application package layout)\n每个我所参与的go应用都似乎对一个问题有不同的答案,我应该如何组织我的代码?有些应用将所有东西堆到一个包里面,但是还有一些应用会选择按type或module来分组. 如果没有一个好的策略能在整个团队中贯彻使用,你会发现代码会分散在应用的各个包中(译者注:即强耦合).我们需要一个更好的go应用设计的标准\n我建议这样的一个更好的方法. 通过遵循一些简单的规则我们可以解耦我们的代码,使得它更加容易测试,并且为我们的项目带来一致性的结构.在我们深入探讨之前,先看看现在最常见的一些人们组织包的方法\n有缺陷的方法 似乎存在一些常用的方法来组织go包,但它们都有这自己各自的缺陷\n方法#1: 单包(译者注:类比单内核/宏内核) 将你的代码扔在一个包里确实对于一些小应用来说可以运行的很好.它避免了循环依赖的可能,因为在你的应用里面,没有任何依赖(译者注:即引用别的包)\n我曾看见过这样的方式能对至多10k行源码的应用起效.但超过这个大小后,就会使浏览代码和隔离代码变得非常困难\n方法#2: Rails风格布局 另一种方法是按功能类型来对代码分包.比如,你所有的handlers放在一个package,所有的controllers放在一个package,所有的models放在一个package.我在过去的Rails开发者中经常看见这种布局\n但是这个方法仍然存在两个问题.首先,你的命名是atrocious的.你最终得到类似controller.UserController这样的类型名称,这意味着你在类型名中重复了包名.我倾向于对命名有一定的质量要求(stickler).当你陷入杂草般的代码中时,我相信名字是最好的文档.名字也被用作是对代码质量的代理(译者注:即命名是代码质量的外显/一部分)(a proxy for quality)-因为它是某个人阅读代码时最先注意到的东西.\n但是,最大的问题是环形依赖. 不同的功能类型也许需要互相引用彼此. 这样的按功能类型分包的布局只会在你的依赖都是单向时才有效,但是大部分情况你的应用都不会那么简单.\n方法#3: 按模块分包  译者注: 类似于按照类来分包?\n 这个方法与Rails风格布局相似,但此时我们按模块进行分包来组织我们的代码,而不是功能.比如,你有一个users包和一个accounts包.\n在这个方法中,我们将会发现和Rails风格中同样的问题.再一次,我们最终得到了类似users.User这样糟糕的命名.我们也同样面临环形依赖的问题,如果accounts.Controller需要和users.Controller进行交互,反之亦然.\n一个更好的方法 我使用的应用在我们项目中的分包策略包括四个简单的宗旨:\n 根包用于领域类型(译者注:根包即net/http中的net,其含有与http子包并列的代码文件) 按依赖对子包分组 使用共享的mock子包(mock模拟,译者注:用于测试) Main包将捆绑所有依赖(译者注:Main包是可执行包,将会引用所有需要的依赖,此外的子包不可以平行引用子包)  这些规则帮助隔离我们的包和在整个应用中定义一个清晰的领域语言.让我们看看每一个规则是如何在实践中生效的\n1.根包用于领域类型 你的应用有一个逻辑的,高层次的语言来描述数据和进程的交互. 这就是你的领域(domain).如果你有一个电商应用,你的领域将包含诸如顾客,账户,对信用卡收费,处理库存等.如果你是Facebook,那么你的领域将是用户,爱好,关系网等. 领域所包含的东西就是一些不依赖于你底层技术的东西\n我将我们的领域类型放在根包中.这个包只包含简单的数据类型比如User结构体,用于持有用户数据或UserService接口用于存取用户数据\n代码可能长这样:\npackage myapp\rtype User struct {\rID int\rName string\rAddress Address\r}\rtype UserService interface {\rUser(id int) (*User, error)\rUsers() ([]*User, error)\rCreateUser(u *User) error\rDeleteUser(id int) error\r}\r 这会使得你的根包非常小. 你也可以包含执行操作的类型,但前提是它们仅依赖于其他领域类型.比如,你可以有一个用于周期性轮询UserService的类型.但是它不可以访问外部的服务(service)或保存数据到数据库.这是一个实现细节.(译者注:即不能引入更多的包(外部包/子包),只能用现有的类型)\n根包不应该依赖其他任何在你应用中的包(译者注:不应该依赖子包)\n2.按依赖来分包  (译者注:比如http依赖在一个包,数据库依赖在一个包)\n 如果你的根包不允许有外部的依赖,那么我们必须将这些依赖放置在子包中(译者注:根包不应该有任何import).在这个关于包布局的方法中,子包作为一个你的领域和你的实现之间的适配器存在(译者注:核心观点,子包作为领域与实现的适配器,而实现将使用外部依赖,这中间通过接口适配,便于mock)\n比如,你的UserService也许由Postgresql支持.你可以在你的应用中引入一个名为postgres的子包用于提供postgres.UserService实现(译者注:app.postgres.UserService结构体实现app.UserService接口)\npackage postgres\rimport (\r\u0026quot;database/sql\u0026quot;\r\u0026quot;github.com/benbjohnson/myapp\u0026quot;\r_ \u0026quot;github.com/lib/pq\u0026quot;\r)\r// UserService represents a PostgreSQL implementation of myapp.UserService.\rtype UserService struct {\rDB *sql.DB\r}\r// User returns a user for a given id.\rfunc (s *UserService) User(id int) (*myapp.User, error) {\rvar u myapp.User\rrow := db.QueryRow(`SELECT id, name FROM users WHERE id = $1`, id)\rif row.Scan(\u0026amp;u.ID, \u0026amp;u.Name); err != nil {\rreturn nil, err\r}\rreturn \u0026amp;u, nil\r}\r// implement remaining myapp.UserService interface...\r 这段代码隔离了我们的Posgresql依赖,简化了测试(译者注:这称为依赖注入)和提供了简单的方法用于未来可能的迁移数据库.它可以被用作一种可插拔架构(pluggable architecture),如果你决定支持其他的数据库实现比如BoltDB.\n它也给了你一种对实现分层的方法.也许你想要持有一个在内存中的,LRU算法的cache在PostgreSQL之前.那么你只需要添加一个实现了UserService的UserCache,它可以包装(wrap)你的PostgreSQL实现(译者注:装饰模式)\npackage myapp\r// UserCache wraps a UserService to provide an in-memory cache.\rtype UserCache struct {\rcache map[int]*User\rservice UserService\r}\r// NewUserCache returns a new read-through cache for service.\rfunc NewUserCache(service UserService) *UserCache {\rreturn \u0026amp;UserCache{\rcache: make(map[int]*User),\rservice: service,\r}\r}\r// User returns a user for a given id.\r// Returns the cached instance if available.\rfunc (c *UserCache) User(id int) (*User, error) {\r// Check the local cache first.\rif u := c.cache[id]]; u != nil {\rreturn u, nil\r}\r// Otherwise fetch from the underlying service.\ru, err := c.service.User(id)\rif err != nil {\rreturn nil, err\r} else if u != nil {\rc.cache[id] = u\r}\rreturn u, err\r}\r 我们在标准库中也看到了这种方法.io.Reader是一个领域类型,用于读字节,它的实现按依赖进行分组(分包)\u0026mdash;-tar.Reader,gzip.Reader,multipart.Reader. 它们也可以被分层叠起来,我们经常可以看到os.File被bufio.Reader包装,再被gzip.Reader包装,再被tar.Reader包装.\n依赖之间的依赖 你的依赖们并没有隔离.你也许会存储User数据到PostgreSQL中,但你的金融交易数据存放在第三方服务中,比如Strip. 在这个例子中我们使用一个逻辑领域类型来包装Strip依赖\u0026mdash;让我们叫他TrasactionService.\n通过添加TransactionService到UserService,我们解耦了这两个依赖:(译者注:这里是myapp.posgres.UserService,而不是myapp.UserService, myapp.posgres.UserService实现了myapp.UserService)\ntype UserService struct {\rDB *sql.DB\rTransactionService myapp.TransactionService\r}\r 现在这些依赖仅通过公共领域语言来进行通信. 这意味这我们可以将PosgreSQL切换成MySql,或者切换Strip为另一个支付处理器,而不影响其他依赖.\n不要局限于第三方依赖  (译者注:对于标准库也要隔离)\n 这听起来可能很奇怪，但是我也使用这种相同的方法来隔离我的标准库依赖. 例如,net/http包只是另一个依赖. 我们也可以通过在应用程序中包含http子包来隔离它.(译者注:所谓隔离一个包,是指只在特定的包引入一个包,而不是在应用中到处引用)\n具有与其包装的依赖相同名称的包似乎很奇怪,但是,我是故意的. 除非您允许在应用程序的其他部分中使用net/http，否则您的应用程序中没有程序包名称冲突. 复制名称的好处是它要求你将所有HTTP代码(译者注:与http通信相关的代码)隔离到http包中.\npackage http\rimport (\r\u0026quot;net/http\u0026quot;\r\u0026quot;github.com/benbjohnson/myapp\u0026quot;\r)\rtype Handler struct {\rUserService myapp.UserService\r}\rfunc (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\r// handle request\r}\r 现在，http.Handler充当您的域和HTTP协议之间的适配器\n3. 使用共享的mock子包 因为我们的依赖通过领域接口与其他依赖隔离，所以我们可以使用这些连接点来注入模拟实现.(译者注:依赖注入)\n有许多模拟库（例如GoMock）可以为你生成模拟，但我个人更喜欢自己编写mock. 因为我发现许多模拟工具过于复杂.\n我使用的模拟非常简单. 例如, UserService的模拟如下所示:\npackage mock\rimport \u0026quot;github.com/benbjohnson/myapp\u0026quot;\r// UserService represents a mock implementation of myapp.UserService.\rtype UserService struct {\rUserFn func(id int) (*myapp.User, error)\rUserInvoked bool\rUsersFn func() ([]*myapp.User, error)\rUsersInvoked bool\r// additional function implementations...\r}\r// User invokes the mock implementation and marks the function as invoked.\rfunc (s *UserService) User(id int) (*myapp.User, error) {\rs.UserInvoked = true\rreturn s.UserFn(id)\r}\r// additional functions: Users(), CreateUser(), DeleteUser()\r  译者注:此处的mock只涉及了是否调用,对于更verbose的mock,还可能涉及调用顺序等\n 这个mock让我们可以注入函数到任何使用myapp.UserService接口的地方,我们可以借此来验证参数,返回期望数据,或者注入失败\n比如我们想测试我们之前定义的http.Handler:\npackage http_test\rimport (\r\u0026quot;testing\u0026quot;\r\u0026quot;net/http\u0026quot;\r\u0026quot;net/http/httptest\u0026quot;\r\u0026quot;github.com/benbjohnson/myapp/mock\u0026quot;\r)\rfunc TestHandler(t *testing.T) {\r// Inject our mock into our handler.\rvar us mock.UserService\rvar h Handler\rh.UserService = \u0026amp;us\r// Mock our User() call.\rus.UserFn = func(id int) (*myapp.User, error) {\rif id != 100 {\rt.Fatalf(\u0026quot;unexpected id: %d\u0026quot;, id)\r}\rreturn \u0026amp;myapp.User{ID: 100, Name: \u0026quot;susy\u0026quot;}, nil\r}\r// Invoke the handler.\rw := httptest.NewRecorder()\rr, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;/users/100\u0026quot;, nil)\rh.ServeHTTP(w, r)\r// Validate mock.\rif !us.UserInvoked {\rt.Fatal(\u0026quot;expected User() to be invoked\u0026quot;)\r}\r}\r mock让我们完全隔离单元测试到仅仅的http协议的处理上(译者注:如果没有mock,则单元测试将包含UserService的创建和http协议的处理,UserService的创建可能依赖很多东西)\n4.Main包将捆绑所有依赖 现在所有这些依赖都被隔离地漂浮在那里了, 您可能想知道它们是如何组合在一起的. 这就是main包的工作.\nMain包的布局 一个应用也许会产生出很多二进制文件,所以我们将使用Go的传统,将main包作为cmd包的一个子目录.比如,我们的项目也许有一个myapp的服务器二进制文件,但也有一个myappctl的客户端二进制文件用于通过终端管理服务器.我们列出这个main包的布局:\nmyapp/\rcmd/\rmyapp/\rmain.go\rmyappctl/\rmain.go\r  译者注: 一定要在app/cmd下再创建一个子目录,否则go build/go install出来默认是目录名,即cmd,且go install没办法rename\n 编译时注入依赖 术语\u0026quot;依赖注入\u0026quot;从字面上描述的并不好.它使人想到了冗长的Spring XML文件. 但是,这个术语真正表示的是我们将要向对象传递依赖(译者注:作为NewXXX函数的参数传入),而不是要求这个对象自己建立或找到依赖.\nmain包就是我们选择哪个依赖被注入哪个对象的地方. 因为main包简单地将一小块一小块的依赖连接在一起(译者注:原文:wires up the pieces, 可见google/wire命名由来),它往往是比较小且琐碎的代码:\npackage main\rimport (\r\u0026quot;log\u0026quot;\r\u0026quot;os\u0026quot;\r\u0026quot;github.com/benbjohnson/myapp\u0026quot;\r\u0026quot;github.com/benbjohnson/myapp/postgres\u0026quot;\r\u0026quot;github.com/benbjohnson/myapp/http\u0026quot;\r)\rfunc main() {\r// Connect to database.\rdb, err := postgres.Open(os.Getenv(\u0026quot;DB\u0026quot;))\rif err != nil {\rlog.Fatal(err)\r}\rdefer db.Close()\r// Create services.\rus := \u0026amp;postgres.UserService{DB: db}\r// Attach to HTTP handler.\rvar h http.Handler\rh.UserService = us\r// start http server...\r}\r 同样重要的是要注意到,你的main包也是一个适配器(adapter). 它连接终端到你的领域.\n结论 应用设计是一个很难的问题. 存在太多需要做出的设计决策,并且如果没有一系列可靠的原则去指引你,问题将会被弄得更糟. 我们研究了当前Go应用程序设计的几种方法,并且发现了它们的许多缺陷.\n我相信从依赖关系的桀骜都着手进行设计将会使得代码组织的更简单,也更容易究因. 首先我们设计领域语言.然后我们隔离依赖.再接着我们引入mock来隔离测试. 最后,我们将所有内容捆绑在一起放在main包\n在下一个你设计的应用程序中考虑这些原则. 如果你有任何问题或想要讨论设计, contact me at @benbjohnson on Twitter or find me as benbjohnson on the Gopher slack.\n 译者: @https://github.com/liwm29\n概括: 按依赖分包,各子包将实现根包定义的interface,且它们之间不可以互相import. 根包定义领域类型,如果依赖外部服务,则定义interface.最终在cmd/app/main.go中完成依赖注入\n","id":45,"section":"posts","summary":"Standard Package Layout 标准包布局 -Ben Johnson https://www.gobeyond.dev/standard-package-layout/ Vendoring和Generics,它们在go社区似乎都是big issue,但还有一个很少提及的issue,就是应用","tags":["Go"],"title":"[Go] standard package layout","uri":"https://liwm29.github.io/2021/03/go-standard-package-layout/","year":"2021"},{"content":"用户线程与核心线程 ref: Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism\n论文观点:\n We argue that the performance of user-levelthreads is inherently better than that of kernel threads, rather than thisbeing an artifact of existing implementations. kernel threads are the wrong abstraction on which to support user-level management of parallelism.  1.用户线程的优势  The cost of accessing thread management operations.  ","id":46,"section":"posts","summary":"用户线程与核心线程 ref: Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism 论文观点: We argue that the performance of user-levelthreads is inherently better than that of kernel threads, rather than thisbeing an artifact of existing implementations. kernel threads are the wrong abstraction on which to support user-level management of parallelism. 1.用户线程的","tags":["Go"],"title":"[Go] user thread","uri":"https://liwm29.github.io/2021/03/go-user-thread/","year":"2021"},{"content":"About Content-Type Content-Type 用来指定在POST请求中body的数据类型(或格式),是一个非常重要的Header字段\n三种Content-Type application/x-www-form-urlencoded  默认类型,当form不指定enctype时使用此content-type 看名字就知道,urlencoded,当自己构造时,要对参数进行url转义 示例: a=123\u0026amp;b=123 go语言中,可以直接传string/[]byte给body,也可以是map[string]string,也可以是url.Values(typedef map[string][]string)  虽然这些都可以,但推荐url.Values,可以直接调用.encode(),自己构造的是没有encode的,但一般来说都没有问题,因为只有特殊字符需要encode!    go server 解析:   multipart/form-data(mime)  用于上传文件 html form 构造: form.enctype=\u0026quot;multipart/form-data\u0026quot; i.put:type=\u0026quot;file\u0026quot; go client 构造: import \u0026quot;mime/multipart\u0026quot; go server 解析:  首先解析: r.ParseMultipartForm(1024 * 1024) 取出来:image := r.MultipartForm.Value[\u0026quot;image\u0026quot;]    也可以看看gin的api,更方便  application/json  json.marshall之后传进body即可  gin解析: id := c.Query(\u0026quot;id\u0026quot;)\rc.PostForm(\u0026quot;name\u0026quot;)\r// 也可以bind进一个结构体\r// 推荐使用bind,可以很方便的进行表单验证\r// get:BindQuery , post:bindjson/bindxml/...\rc.ShouldBind(\u0026amp;person)\r// 单文件\rrouter.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 file, _ := c.FormFile(\u0026quot;file\u0026quot;)\rc.SaveUploadedFile(file, dst)\r// 多文件\rform, _ := c.MultipartForm()\rfiles := form.File[\u0026quot;upload[]\u0026quot;]\r ","id":47,"section":"posts","summary":"About Content-Type Content-Type 用来指定在POST请求中body的数据类型(或格式),是一个非常重要的Header字段 三种Content-Type application/x-www-form-urlencoded 默认类型,当for","tags":["HTTP"],"title":"[HTTP] Content-Type","uri":"https://liwm29.github.io/2021/03/http-content-type/","year":"2021"},{"content":"ByteDance\u0026amp;Tencent 2021/3 暑期实习\n腾讯一面  上来抛了道js,问我输出  const a = (\ri : 0,\rtoString(){\rreturn i++\r}\r)\rprint(a == 0 \u0026amp;\u0026amp; a==1 \u0026amp;\u0026amp; a==2)\r  答案是false,没答出来,我当时主要纠结于为什么会调用toString呢  问了下闭包,以及和方法引用对象变量的区别 union结构体,柔性数组 讲讲TCP三次握手,序数是从0开始吗  不是   讲讲数据包从本机到公网的历程  讲了arp,交换机,路由器这些   讲讲物理层的冲突  载波侦听多路访问   交换机和路由器的区别 交换机的端口分向内向外吗  不分,一个广播域,一个子网   了解tcmalloc吗  不懂,查了下,是thread cache malloc,一种内存管理中的内存分配方法   介绍自己的项目,聊到多态哈希,问我的并发控制是怎么做的  读写锁,map分片   哈希怎么做的内存管理  用bitmap,不是像slab用链表   等等,多数忘了  二面 今天早上过了tx的二面,感觉面的很简单\n 讨论项目 问我了不了解第三方登陆接口  不了解,查了下,和OAuth有关   做题  用三种方法,计算一个数字转化为二进制后有多少个1  for{b = a\u0026amp;1,a = a\u0026raquo;1,\u0026hellip;..}   经典leetcode,找到数组第k大数  快排/优先队列 问了下算法复杂度   12个鸡蛋,一个天平,怎样快速识别出来唯一的坏鸡蛋 忘了    字节  接雨水,本菜鸡没写出来 TCP三次握手,四次挥手  额外讲了个两个positive socket之间的主动连接   四次挥手可以是3次吗  回答可以,关闭连接的本质在于自己不再写socket,所以只要收到对方的fin,并且自己不再需要写,便可以返回fin+ack,没必要分开发   SYN半连接攻击  导致SYN队列满 额外讲了个TCP cookie,用来解决SYN队列满的问题   go GC  标记清扫法,三色标记法,混合写屏障   数据库事务的特性  ACID 原子性:要么发生要么不发生 一致性:相容性,互相不矛盾 隔离性:四个隔离级别 持久性: 刷回硬盘,分数据和日志   讲讲隔离性中的幻读  即读出了其他事务插入的行,本质是只锁了行,可以通过gap锁来锁区间   innoDB的索引  B+树   B+树的特点  叶子节点存数据,且链起来,方便顺序遍历   B+树的优点  有序性:区间查找快,相较于B树的中序遍历,和hash的无序性 快速性: B+树更矮胖,查找的层级会更少,3层B+树可以容纳2kw个数据 稳定性: 因为数据都在叶子节点,所以搜索数据都必须搜到最底层 稳定性的好处,其实在于其非叶子节点容纳了更多的指向下一层的指针,这导致io次数急剧下降,所以应该说,不是稳定性的好处,而是B+树非叶子节点不存数据的好处(这导致了稳定性),想象一下.任意2kw数据,都可以只通过3次io就查出来,快到极致,反观B树,一层最多16个指针,16^6=1.6kw  可惜,当时我不会     结束  可以看出字节会偏向八股文一点,但是我个人觉得这是有必要的,因为虽然都是些基础概念,但每个人都会有自己的理解,而且都是比较简单的吧,如果不会,一是基础问题,二是态度问题.\n并且字节问了我go的GC,这是我比较感动的,毕竟我简历上写着目标岗位是go后端开发:)\n","id":48,"section":"posts","summary":"ByteDance\u0026amp;Tencent 2021/3 暑期实习 腾讯一面 上来抛了道js,问我输出 const a = ( i : 0, toString(){ return i++ } ) print(a == 0 \u0026amp;\u0026amp; a==1 \u0026amp;\u0026amp; a==2) 答案是false,没答出来,我当时主要纠结于为什么会调用t","tags":["interview"],"title":"[interview] ByteDance\u0026Tencent","uri":"https://liwm29.github.io/2021/03/interview-bytedancetencent/","year":"2021"},{"content":"记录一下为面试做的准备  声明: 以下知识点可能不完全正确,但也不会错的太离谱\n 记录一些知识点\n 数据库事务的四个特性: ACID 原子性,一致性,隔离性,持久性 事务的隔离级别:  读未提交 : 即脏读 读提交: 解决脏读,可以读到其他事务提交了的行 读重复: 可以重复读数据,但是存在幻读(即对方插入了新的数据行,你是可以重复读出来行数不一样的)(要解决这个问题要锁全表) 读串化: 加表级锁   InnoDB的索引: B+树,有利于范围选择(对比hash和b树),B+树的数据指针节点都在叶子节点 3层的B+树可以支持2kw数据索引(基于一页放一个结点,一页16KB,一行数据1KB) 四,七层负载均衡:  四层:传输层,根据(ip:port)来映射到不同的app server,其工作本质类似于一个NAT,它不查看包的内容 七层:应用层,以http为例,它可能会解析出http request line/header,根据url来映射到不同的app server 不管是哪种方式,连接都是client和proxy建立,proxy再与app server建立   中断的分类:  外部中断: 外部io设备中断 内部中断  受迫中断: 除零等 自主中断: 系统调用     os是中断驱动的软件(指令序列) 内核态与用户态切换的开销(系统调用的开销): 几百ns左右  特权模式的切换本身应该没有多耗时,主要是这个系统调用本身底层可能要执行数百条指令 对于getpid这样的系统调用,其实也是很快的,个位数ns左右 需要切换堆栈指针寄存器等   进程上下文切换的开销(deprecated: see 16 instead)  进入内核态 切换页表寄存器指针 切换硬件寄存器上下文 执行调度代码(比如PCB进入运行队列) 冷启动造成的频繁缺页   硬件线程上下文切换的开销  切换硬件寄存器上下文 内核态进行   用户线程(协程)上下文切换的开销  用户态进行,超轻量   线程比进程轻量的原因: 页表缓存 协程比线程轻量的原因: 不用进入内核态 https: 7次握手(tcp3+tls4) io复用: select和poll类似,需要自己去遍历整个event数组寻找哪些可读可写; epoll返回激活fd的数目fds,访问event数组的前fds个event即可 进程切换的开销: ref  直接开销: pcb的各字段的load\u0026amp;store(页表指针,界限指针等)(从内存到寄存器) 间接开销: cold cache   内核线程切换的开销:  直接开销: pcb的各字段的load\u0026amp;store(页表指针,界限指针等)(从内存到寄存器) 线程和进程都是task_struct   用户态线程的开销:  不需要进入内核态(进入内核态涉及中断)   指令级并行: ILP 多发射,超标量(动态多发射)  多个取值译码器,多个ALU,单个执行上下文(所以只支持单进程的多发射乱序执行)   线程级并行: 多核程序  单核多线程也可以,比如intel的四核八线程,在指令级并行的基础上增加多个执行上下文   数据级并行: SIMD  单个取值译码器,超多个ALU   TLS握手:  client hello,client random server hello,server random,server certificate client encode premaster secret using server public key \u0026lt;-\u0026gt;通信双方根据预主密钥和random计算出对称密钥,用于后续通信的加密 server-\u0026gt;client , finished   为什么要random: 避免重放攻击?  个人感觉不是,random就只是单纯的random一下,为了生成一个不易被爆破的密钥吧 为了避免重放,应该为每一个报文加一个序号   为什么要对称密钥加密,而不是直接server公钥: 对称密钥加解密速度快 tcp三次握手,最后一次为什么要握手,没有行不行?  为了防止无意的过期连接的建立 可以类比有意的syn攻击(一种dos攻击)  防御手段? tcp cookie?     数据库并发控制  悲观锁: 一次封锁或两阶段锁  一次封锁: 有效防止死锁,在事务开始时,一次获取所有锁,事务结束后释放所有锁 两阶段锁: 可能死锁, 事务分为growing阶段和shrinking阶段,前一个阶段只能获取锁,后一个阶段只能释放锁  解决死锁:  死锁检测: 维护一个锁等待图,追踪每个事务要获得哪些锁,图中节点是事务,边是等待关系(i-\u0026gt;j, 表示事务i等待事务j释放锁) ,系统周期性检查图中是否有环, 有环则死锁,对其中一个restart或者abort 死锁避免: 当事务i想要获取事务j的某个锁,dbms杀掉i或j来避免死锁  old waits for young(wait-die)  如果请求事务比持有事务启动的早,则请求事务wait; 否则请求事务abort   young waits for old(wound-wait)  如果请求事务比持有事务启动的早,则持有事务abort,释放锁; 否则等待         悲观锁的缺点: 大多数db读多于写,减少了潜在的并行性 意向锁: An intention lockallows a higher-level node to be locked in sharedor exclusivemode without having to check all descendent nodes.  如果表有意向读锁,则说明某一行加了读锁 如果表有意向写锁,则说明某一行加了写锁 意向锁与锁有一定的兼容性,本质是为了快速判断某一事物是否能在这个表上完成:   共享意向排他锁SIX: 表示读取整个表,修改部分行(即 S + IX),只有当某个事务是读取某一行时,才让其进入表(与之兼容)       乐观锁: 基于时间戳排序的协议(保证执行效果就像按时间戳串行一样)  不加锁,每个事务启动时获取一个唯一时间戳. 表的每一行都维护读时间戳和写时间戳  行的读写时间戳不能和事务启动时间戳矛盾   另一种方法,不在运行时验证,而是先写到自己的空间,事务提交时统一验证  OCC phases(optimistic concurrency control)  读阶段,The DBMS copies every tuple that the txnaccesses from the shared database to its workspace ensure repeatable reads. 验证阶段: When txnTi invokes COMMIT, the DBMS checks if it conflicts with other txns. 写阶段:The DBMS propagates the changes in the txn’swrite set to the database and makes them visible to other txns       多版本并发控制  对于每一行,维护多个版本,只要一个事务写或修改了一行,就创建一个那一行的新版本(版本基于时间戳) 事务读时,会自己选择去读最新的与事务启动时间戳兼容的版本     日志记录(持久化机制) 高可用: 短暂的系统中断时间,能快速恢复(类比汽车的备胎) 容错: 系统故障,但继续提供服务,因为冗余节点(类比飞机的多个发动机) 灾备(disaster recovery): 系统故障后,如何抢救业务数据,放弃基础设施 外排序: 以归并排序为例,对900MB数据排序,内存100MB  归并排序是divide-and-conquer算法,先分成多块,分别sort,然后对这排好序的多快进行merge 900/100 = 9,所有9路归并 divide-sort阶段: 对这9块数据,每块100MB,依次读入内存,进行内排序sort,写出内存 merge阶段: 内存分为9个input buffer和1个output buffer;每次对每块读入10MB,进行merge,output buffer满后写出内存,input buffer满后,从自己那块再从磁盘取   redis持久化机制:  RDB:redis database 将数据快照保存在磁盘上 命令: save(同步save) , bgsave(异步save),自动同步(配置文件) 缺点: 自动同步时间一般设置的较大,比如100s,实时性不够  显然不能频繁写,因为要把内存全部覆盖到磁盘,数据量还是很大的   AOF: append-only-file  存储日志,恢复时redo,可以配置每一条指令,或每秒fsync一次 缺点:aof文件比rdb文件大 优点: append-only,方便磁盘寻址 bgrewriteaof,对aof文件重写(优化),目的是为了减少指令数目,用尽可能少的指令数目完成一样的功能; 有助于数据恢复速度和磁盘空间     WAL: write ahead log  先写日志再写数据    ","id":49,"section":"posts","summary":"记录一下为面试做的准备 声明: 以下知识点可能不完全正确,但也不会错的太离谱 记录一些知识点 数据库事务的四个特性: ACID 原子性,一致性,隔离性,持久性","tags":["interview"],"title":"[interview] 杂","uri":"https://liwm29.github.io/2021/03/interview-%E6%9D%82/","year":"2021"},{"content":"[linux] 关于后台运行进程的小实验 我们经常有将进程放到后台运行的需求,我们可以通过编程实现守护模式,也可以在shell中启动进程的时候配置\n守护模式 通过编程,可以使得程序进入daemon模式\n fork和setsid\n shell启动命令  \u0026amp;  使用\u0026amp;可以让进程后台运行,但是仍然会输出到终端上\nsetsid ./test.sh \u0026amp;\r设置父进程为init进程\r ","id":50,"section":"posts","summary":"[linux] 关于后台运行进程的小实验 我们经常有将进程放到后台运行的需求,我们可以通过编程实现守护模式,也可以在shell中启动进程的时候配置 守护模式 通","tags":["server"],"title":"[linux] daemon","uri":"https://liwm29.github.io/2021/03/linux-bg-run-linux/","year":"2021"},{"content":"高性能linux服务器 服务器监听范式 一个传统的单线程服务器\ngraph LR;\rA[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd);\rB--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind]\rC--\u0026gt;D[listen]\rD--\u0026gt;E[accept]\rE--\u0026gt;|connfd|F[\u0026quot;dowork(){read/write connfd}\u0026quot;]\rF--\u0026gt;|\u0026quot;while (1)\u0026quot;| E\r 一个传统的多线程服务器, pthread也可以换成fork,多进程\ngraph LR;\rA[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd);\rB--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind]\rC--\u0026gt;D[listen]\rD--\u0026gt;E[accept]\rE--\u0026gt;|connfd|F[pthread_create]\rF--\u0026gt;|pthread|G[threadRoutine]--\u0026gt;O[\u0026quot;dowork(){read/write connfd}\u0026quot;]\rF--\u0026gt;|pthread|H[threadRoutine]--\u0026gt;Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;]\rF--\u0026gt;|pthread|I[threadRoutine]--\u0026gt;Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;]\rF--\u0026gt;|\u0026quot;while (1)\u0026quot;| E\r 一个传统的多线程服务器,多线程同时accpet同一个sockfd\n 这种方法应该会触发所谓的__\u0026ldquo;惊群现象\u0026rdquo;__,在linux2.6后,如果是多进程调用sockfd.accept(),则惊群被解决\n如果是使用epoll_wait()监听sockfd,则仍然存在惊群问题,其原因很明显,因为只是在监听文件描述符,内核没权利指定到底哪个线程epoll_wait成功,而accept()解决惊群则是因为将accept设计成了某种意义上的原子指令\n解决方法是对多个线程,任何时刻都只让一个线程去epoll_wait sockfd\n graph LR;\rA[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd);\rB--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind]\rC--\u0026gt;D[listen]--\u0026gt;F[pthread_create]\rF--\u0026gt;|pthread|G[threadRoutine]--\u0026gt;aa[accept]--\u0026gt;|connfd|O[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aa\rF--\u0026gt;|pthread|H[threadRoutine]--\u0026gt;aaa[accept]--\u0026gt;|connfd|Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaa\rF--\u0026gt;|pthread|I[threadRoutine]--\u0026gt;aaaa[accept]--\u0026gt;|connfd|Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaaa\r 一个现代的多线程服务器,使用了SO_REUSEPORT来达到多个普通的sockfd绑定到同一个port,这样的好处是内核帮你实现了负载均衡,由于是不同的sockfd,所以即使使用epoll_wait,也只会有一个sockfd被唤醒\ngraph LR;\rx[pthread_create]--\u0026gt;A\rxa[pthread_create]--\u0026gt;Aa\rxaa[pthread_create]--\u0026gt;Aaa\rA[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd);\rAa[\u0026quot;socket()\u0026quot;]--\u0026gt;Ba(sockfd);\rAaa[\u0026quot;socket()\u0026quot;]--\u0026gt;Baa(sockfd);\rB--\u0026gt;|\u0026quot;setsockopt(so_reuseport)\u0026quot;| C[bind]\rBa--\u0026gt;|\u0026quot;setsockopt(so_reuseport)\u0026quot;| Ca[bind]\rBaa--\u0026gt;|\u0026quot;setsockopt(so_reuseport)\u0026quot;| Caa[bind]\rC--\u0026gt;D[listen]\rCa--\u0026gt;Da[listen]\rCaa--\u0026gt;Daa[listen]\rD--\u0026gt;aa[accept]--\u0026gt;|connfd|O[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aa\rDa--\u0026gt;aaa[accept]--\u0026gt;|connfd|Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaa\rDaa--\u0026gt;aaaa[accept]--\u0026gt;|connfd|Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaaa\r SO_REUSEPORT\u0026amp;SO_REUSEADDR SO_REUSEADDR 常见的是用于复用监听TIME_WAIT状态的端口,对于多线程监听同一个端口,也需要使用这个参数\nSO_REUSEPORT\n为了解决上述的常见的多线程处理网络请求的需求,linux推出了一个sockopt参数:\n首先给出官方文档的介绍,很清晰了\n SO_REUSEPORT (since Linux 3.9)\nPermits multiple AF_INET or AF_INET6 sockets to be bound to an identical socket address. This option must be set on each socket (including the first socket) prior to calling bind(2) on the socket. To prevent port hijacking, all of the processes binding to the same address must have the same effective UID. This option can be employed with both TCP and UDP sockets.\nFor TCP sockets, this option allows accept(2) load distribution in a multi-threaded server to be improved by using a distinct listener socket for each thread. This provides improved load distribution as compared to traditional techniques such using a single accept(2)ing thread that distributes connections, or having multiple threads that compete to accept(2) from the same socket.\nFor UDP sockets, the use of this option can provide better distribution of incoming datagrams to multiple processes (or threads) as compared to the traditional technique of having multiple processes compete to receive datagrams on the same socket.\n 在go中如何实现呢?我们知道一般提供的都是linux c的api,对于go,当然可以通过syscall,但还是会有些不同\n具体可以看看这个repo: https://github.com/kavu/go_reuseport/blob/47bb7f1bfa3921a92422a1eb4f0941e9caed1103/tcp.go#L96\n如何完成syscall得到的fd与go语言内置的net.Listener之间的转换,可能是一个关键\n在该库中,是这样实现\n 由于SO_REUSEPORT在go中尚未提供,所有直接用 var reusePort = 0x0F 代替\n graph TD;\rfx[\u0026quot;begin\u0026quot;]--\u0026gt;|\u0026quot;syscall.ForkLock.RLock()\u0026quot;|a\ra[\u0026quot;syscall.Socket(soType, syscall.SOCK_STREAM, syscall.IPPROTO_TCP)\u0026quot;]--\u0026gt;|\u0026quot;syscall.ForkLock.RUnlock()\u0026quot;|b[fd]\rb--\u0026gt;c[\u0026quot;syscall.SetsockoptInt(fd, syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1)\u0026quot;]\rc--\u0026gt;d[\u0026quot;syscall.SetsockoptInt(fd, syscall.SOL_SOCKET, reusePort, 1)\u0026quot;]\rd--\u0026gt;f[\u0026quot;syscall.Bind(fd, sockaddr)\u0026quot;]\rf--\u0026gt;g[\u0026quot;syscall.Listen(fd, listenerBacklogMaxSize)\u0026quot;]\rg--\u0026gt;s[\u0026quot;file = os.NewFile(uintptr(fd), getSocketFileName(proto, addr))\u0026quot;]\rs--\u0026gt;ss[\u0026quot;listener, err = net.FileListener(file)\u0026quot;]\rss--\u0026gt;sss[\u0026quot;net.Listener\u0026quot;]\r 这里\n  getSocketFileName()\n 只是单纯的返回了fmt.Sprintf(\u0026quot;reuseport.%d.%s.%s\u0026quot;, os.Getpid(), proto, addr)    os.NewFile(fd uintptr, name string)*os.File\n returns a new File with the given file descriptor and name.`    net.FileListener(* os.File)\n FileListener returns a copy of the network listener corresponding to the open file f    listenerBacklogMaxSize\n fd, err := os.Open(\u0026quot;/proc/sys/net/core/somaxconn\u0026quot;) 默认最大128    非阻塞io 文件描述符应该被设置成非阻塞,如果你通过epoll等进行io复用,可以通过fcntl设置\nfcntl(fd, F_SETFL, O_NONBLOCK);\n高级封装 import \u0026ldquo;golang.org/x/sys/unix\u0026rdquo;\n直接使用syscall可能比较复杂繁琐,golang.org实现了一个类似c语言的封装,api和c语言的接口基本一致\nunix.Socket(domain int, typ int, proto int)\runix.SetsockoptInt(fd int, level int, opt int, value int)\runix.Bind(fd int, sa unix.Sockaddr)\runix.Listen(s int, n int)\runix.Accept(fd int)\r 我们之前说过将fd转换到net.Listener的方法,这里也同样适用\n减少内核态切换拷贝开销 如果是UDP类型通信,每调用一次recvmsg,都会触发内核态缓冲区到用户态缓冲区的数据拷贝,并且只会拷贝一个数据包,为了减少次数,我们期望一次接受多个UDP包,linux提供了recvmmsg,即recv multiple msg, 一次性接受多个包.\ngo中可以自己封装syscall(这里的6,指的是后面的参数个数)\nfunc (rw *ReaderWriter) read() (int, error) {\rn, _, err := unix.Syscall6(unix.SYS_RECVMMSG, uintptr(rw.fd),uintptr(unsafe.Pointer(\u0026amp;rw.msgs[0])), uintptr(len(rw.msgs)), unix.MSG_WAITFORONE, 0, 0)\rreturn int(n),err\r}\r ","id":51,"section":"posts","summary":"高性能linux服务器 服务器监听范式 一个传统的单线程服务器 graph LR; A[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd); B--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind] C--\u0026gt;D[listen] D--\u0026gt;E[accept] E--\u0026gt;|connfd|F[\u0026quot;dowork(){read/write connfd}\u0026quot;] F--\u0026gt;|\u0026quot;while (1)\u0026quot;| E 一个传统的多线程服务器, pthread也可以换成fork,","tags":["server"],"title":"[linux] high performance server","uri":"https://liwm29.github.io/2021/03/linux-high-performance-server/","year":"2021"},{"content":"Introduction to linux server linux 服务器导论\n文件目录相关 假设我们的服务器名为testServerd,这里末尾以d结尾,代表daemon守护模式\n 如果是.d结尾,则代表是文件目录\n 日志目录 /var/log/testServerd/\n /var目录承载可变的数据文件,即可写,与之对比的是/usr,只可读\n PID记录 进程在创建时应该记录自己的pid,可以放置在\n/var/run/testServerd.pid\n配置文件 程序的配置文件可以放置在\n/etc/testServerd/testServerd.conf\n etc是专用于放置配置文件的目录\n 用户信息 大部分服务器必须以root的身份启动,但不能以root的身份运行\nUID,EUID,GID,EGID userid , effective userid, groupid,effective groupid\nUID是进程的真实用户id\nEUID是进程的有效用户id,是为了方便资源访问的,它使得运行程序的用户可以拥有该程序的有效用户的权限\n 如何设置有效用户? 一个可执行文件有一个set-user-id标志位,这个标志位表示普通用户运行程序时,有效用户就是该程序的所有者,使用chown改变程序所有者\n Switch User 调用setgid()和setuid()来切换由root身份启动的程序到普通用户身份\n","id":52,"section":"posts","summary":"Introduction to linux server linux 服务器导论 文件目录相关 假设我们的服务器名为testServerd,这里末尾以d结尾,代表daemon守护模式 如果是.d结尾,则代表","tags":["server"],"title":"[linux] server intro","uri":"https://liwm29.github.io/2021/03/linux-server-intro/","year":"2021"},{"content":"12.1  重新学习了gin的一部分用法,比如参数获取,文件上传,静态文件目录之类的,我感觉任何东西还是要先学会用,再去看源码学习 看了一篇微服务的概述,看起来微服务的兴起就像操作系统的历史一样,由宏内核到微内核,将函数作为服务提供调用,微服务则是将不同的功能组件独立成独立的网络服务,分布在不同的主机;为了降低延迟,使用rpc而不是http,使用protobuf(?存疑)而不是json/xml,因为解析速度不够;带宽方面,随着计算机性能的提升,一般没问题,记得chenshuo在muduo教程里面测过通过本机tcp端口做ipc,带宽也非常可观.目的还是降低单次调用的延时 看了下go语言的sync.map源码,实现上类似于双缓冲区,涉及到写缓冲区的操作一律加锁,默认一个读一个写,加快速度,读不到了再从写的那个缓冲区读;miss次数一定后,就更新缓冲区(用写缓冲区直接覆盖读缓冲区,写缓冲区置为0,后续第一次写入写缓冲区时,会先将读缓冲区的数据拷贝过来,为什么这样设计,可能只是语言机制语法上的妥协吧);  关于写,如果在读缓冲区读到了(注意读到了还要考虑是不是被删除了),就用cas写(换指针),否则上锁,去写缓冲区; 关于读,读缓冲区没读到,并且两个缓冲区数据不一致(定义两个缓冲区数据一致指的是写缓冲区为0,即刚将写缓冲区覆盖读缓冲区),就上锁,去写缓冲区读; 删除: 将指向value的指针置为nil,但本身还存在map中,延迟删除 还有一个特点是,获取锁后,不要立即访问写缓冲区,而是再访问一次读缓冲区,因为你不知道有没有其他线程触发更新,使得写缓存区清空了   把win10升级到了专业版,可以用remote desktop了  12.2  remote desktop 的延迟还是挺高的,仅仅能用 继续说sync.map,其中还是有很多东西可以说到说到的  乐观锁与悲观锁  数据库中的概念 cas(compare\u0026amp;swap),或者是test\u0026amp;set,这些原子指令认为是无锁的,lock-free  但这并不意味着它们代价低,事实上cas作为一个写指令,一定会在总线上发出BusX(后续会写的读信号)信号,以失效多核cpu的其他核的cache,保证cache一致性,然后才读到数据,compare失败或成功 因此一个典型的优化是read and cas,先读,因为处理器读导致BusRead不会使cache失效,这其实就是要减少cas的强制占用总线,后续也可能会有多个核cas,但没关系,最多是核数而不是线程数   乐观锁,倾向于数据少写  先不加锁访问(读),直到更新的时候再用cas更新,可以通过比较version字段(或要修改的值的最新状态与之前的快照)来比较,然后update  如果是全局的version字段,就不会有ABA问题 如果失败,就回滚,重新search   所以其实乐观锁不算是一种锁   悲观锁,倾向于数据多写  强制加锁,访问     复制的效率  可以看到读缓冲区miss后将要访问写缓冲区时,写缓冲区要先copy读缓冲区,再写新的key\u0026amp;value 这是说明了复制的效率一定高于加锁PV的效率?      12.13  一下子就10天没写了,自己还是太懒了,但是这十天还是接触了很多东西的 authentication and authorization, 认证与鉴权  在go里面,认证可以用jwt,鉴权可以用casbin,一般鉴权是rbac,role-based-access-control,基于角色的访问控制,鉴权就是访问控制 这其实就类似于Kerberos,有认证服务器和票据服务器,二者分开   go语言并发,daisy chain之类的东西,输入channel,开goroutine对数据filter,输出channel reactor,proactor,两种事件处理模式,event-driven  reactor是主线程只负责监听事件发生(epoll_wait),然后分发任务给任务线程,读写数据都在工作线程中完成,accept()也在worker中完成 proactor是异步io的,将io操作交给主线程/内核完成,我们知道异步本质就是注册一个回调函数,当io结束后执行回调函数 不够,感觉没太大用,因为目前还接触不到应用的场景   reactiveX,流式处理数据,一种异步io风格  但是和回调又有点不同,它是源源不断接收流式的数据,然后对数据像流水线一样处理. 当然本质也就是注册回调函数,但可以避免过多callback时候的混乱代码,主要是语法上更简介吧   看了beego的session模块的代码,感觉写的确实收益颇多  因为可以有不同的存储场景,所以用interface在中间层抽象,应用层(应用者,user)和底层(提供者,provider)都面向interface编程,底层存储提供者可以是memory,file,redis,db等等,这需要编写对应的驱动(虽然我不知道这叫不叫驱动,但是确实在功能上给我一种驱动的感觉,一般会称之为adapter吧,适配器) 它的并发链表的实现也不错,一方面用链表存储数据,另一方面为了解决链表线性访问慢的问题,用map存储链表的node,快速查找sessionId对应的node  为什么要用container/list呢,而不直接用sync.map存储session,这是因为,我们还要计算其超时时间! 我们不可能遍历所有的node去计算其超时,所以必须要按时间排序 在这里,list就充当了这个角色,新创建的session被放到list的前面,快超时的session自然在最后面,在gc的时候只需要不断测试最后一个node就好了  另外这种定时事件,好像都是用小顶堆做的,这里用链表其实也不错 container/list提供了极其方便的api,比如:PushFront,MoveToFront,Remove   何时GC,处理超时session:  在sessionInit时,就goroutine一个线程定时gc,可以用递归的形式,比较优雅.当然放在一个for{}无穷循环里面也可 func(m *manager)gc(){m.provider.gc(); time.AfterFunc(time.Duration , m.gc)}   在哪里告诉程序,这个provider实现了?  直接在init()中register,维护一个全局的map即可,实现了就在这个文件的init函数中往map里面写就可以了,极其容易拓展,低耦合   注意session只需要管理一个sessionId和对应的value就行了,value可以是任何值的集合,可以设成map[string]interface{},虽然其实go也支持map[interface{}]interface{}  session不需要管理对应的url路径什么的,那是cookie的事,我们在response的时候要set-cookie,对应的cookie值在那里设置,value设置成对应的sessionId即可     MVC架构  model-view-controller  model就是一个个定义的结构体/类对象,其实主要还是用来访问数据库的,其他的名字:DAO,data-access-object,数据访问对象,也就是orm,object-relation-model view,就是前端视图了,可能是一些模板之类的 controller就是后端处理逻辑,hanler,middlerware,log,session,router之类的     综合看下来,beego不完全是一个web框架,它还集成了client,定时任务task之类的模块,我感觉非常值得学习,而且谢大的书go web编程也是开源的,顶礼膜拜好吧   VUE  在看奇淼在b站录的vue视频,感觉这个人教学方面是很不错的,视频看下来不会让我感觉无聊,讲的也比较有激情,知识点归纳的也不错 在我入门gin的情况下去听了下他的gin入门课,感觉还是很不错的,也有收获 之前接触的那些开源项目的目录结构都很迷,初学者完全看不懂为什么这么摆,他的gin-vue-admin的项目目录结构就比较清爽,一目了然   vue-router  前端页面路由,用来构建单页面应用 表现上就是一个页面内的标签页/导航 典型的,前端路由可以用在登陆界面上,就不用登陆界面单独写一个后端路由/html了    12.14  这一周打算:  学会vue/element ui的布局layout,一个典型的后台管理系统就是单页面的,在固定的框类切换不同的内容,所以建立好总体的布局尤为重要 了解http2,简单看了下,感觉都在说什么连接复用,头部压缩之类的,但是http1.0/1.1不是也已经支持keep-alive了吗?这两个长连接的区别? 了解redis?redis就是一个键值对的数据库,经常用作缓存 看到了vue-element-admin,是个不错的项目,而且有教程,基本和奇淼的gin-vue-admin是一个东西,不过这也是因为后台管理系统确实就是那一套.但是对我来说,依然还是有很多学习的地方的   todo  组件上的v-model 子组件的this.emit(\u0026lsquo;input\u0026rsquo;,) 根组件  就是new Vue()   组件一定要被包含? 直接获取组件对象:  根组件: $root 父组件:$parent 只读 子组件:$children 只读,无序  若想改变子组件的内容,只能直接改变子组件所引用的数组的内容,子组件由v-for生成     插槽  用来指示外部传给组件的innerHTML的显示位置 比如\u0026ldquo;this is innerHTML\u0026rdquo;   vue的入口文件:  入口可以是 main.js、index.js、App.vue 或 app.vue 中的一个 哪个定义了new Vue()实例,哪个就是入口   vue实例内置数据/方法,前加$,比如var vm = new Vue({el:\u0026quot;\u0026quot;,data:{}}),vm.$el,vm.$mount()  只有在初始创建时在data字典里面的数据才是响应式的,后面添加的都必须手动触发更新     关于layout  一般来说,后台管理系统是单页面的,简洁好用,没必要设计成跳来跳去的跳转 一般的,用侧边栏来导航,el-main块用来显示内容,如何实现点击不同的按钮,main块切换到不同的页面内容呢?  这个其实element-ui直接实现了,叫标签页 但是如果想更灵活一点,可以自己设计,是通过vue-route实现的 main块放即可     标签页是容易实现的,可以用它来练习组件,设计插槽,父子组件通信这些  本质就是一个tab组件,子组件是tab-pane代表各个标签,tab只是控制tab-pane的显示而已,而显示可以用v-if,很简单   一个标准的vue前端代码结构是: ./component , ./App.vue , ./main.js  在main.js中引入全局组件,App.vue是入口文件   组件通信: 父传子:props down ; 子传父:events up : this.$emit() 关于vue的组件,强推这个课程:https://www.bilibili.com/video/BV1nx411X7oA  12.16  前后端分离,不仅仅是独立开发,也是独立部署,这意味着后端仅仅是提供api的路由!而由前端自己提供页面的路由,这就是意味着前端有自己的路由  12.18  前后端分离,前端一般是单页面的,通过内置前端路由实现多页面,但只有一个vue实例,请求后端api服务器可能需要设置跨域 SPA,单页面应用的路由有两种模式:hash和history,这两种方法都可以改变uri而不触发浏览器的刷新(向服务器请求)  如果是history模式,又没有前后端分开部署(即服务端渲染),指浏览器直接向后端服务器请求html,这时候手动刷新页面就会触发对后端的请求,但因为是前端路由,在后端中不存在,所以需要后端特别配置,后端当收到不存在的路由时,直接返回index.html,index.html将自动根据浏览器栏的path跳转到特定的前端路由,此时要注意设置前端路由的404,用'*\u0026lsquo;匹配即可   了解了vue的路由,以及子路由 todo:  import , export default,export const这些是什么   未来目标: 重构一下sysu_jwxt_v2,前后端分离,后端仅作为api服务器  ","id":53,"section":"posts","summary":"12.1 重新学习了gin的一部分用法,比如参数获取,文件上传,静态文件目录之类的,我感觉任何东西还是要先学会用,再去看源码学习 看了一篇微服务的概述","tags":["other"],"title":"[other] everyDay","uri":"https://liwm29.github.io/2021/03/other-everyday/","year":"2021"},{"content":"What\u0026rsquo;s the diff? x86,x64,386,amd64,i386,intel64 \u0026hellip;. x86,x86-32,386,80386,i386,IA32 都是指的intel的32位cpu架构\nx86-64,x64,amd64,intel64 都是指的intel的64位cpu架构,基于x86\nIA64,一种新的64位架构,不基于x86\nLinux , Ubuntu , CentOS , RedHat \u0026hellip;. linux是内核kernel的名字\nUbuntu,CentOS都是发行版,是操作系统\nRedHat是一家企业,它有旗下的企业版linux发行版:RHEL(Red Hat Enterprise Linux)\nCentOS(Community ENTerprise Operating System)就是RHEL的社区版\nDarwin , Mac OS, macintosh ,BSD \u0026hellip; darwin是内核, Mac OS是os\nunix-\u0026gt;free BSD-\u0026gt;Darwin-\u0026gt;MacOS\nmacintosh是个人电脑的名字,就产品名\n 两大类的类Unix内核,linux和BSD 经典的 ps -aux 和 ps -elf\n ","id":54,"section":"posts","summary":"What\u0026rsquo;s the diff? x86,x64,386,amd64,i386,intel64 \u0026hellip;. x86,x86-32,386,80386,i386,IA32 都是指的intel的32位cpu架构 x86-64,x64,amd64,intel64 都是指的intel的64位cpu架构,基于x86 IA64,一种新的64位架构,不基于x86","tags":["other"],"title":"[other] term","uri":"https://liwm29.github.io/2021/03/other-term/","year":"2021"},{"content":"OAuth2.0 open authority 2.0,开放授权\n主要用于A网站向某个常用第三方社交网站请求用户信息,第三方社交网站需要给予A网站用户信息,这必须有用户的授权才行,但是如果直接给予A网站用户的用户名密码,又太不安全,并且我们希望只提供给A网站受限的资源访问权限,比如只能获取到用户名等.因此需要使用OAuth2.0\n ref:\nhttps://aaronparecki.com/oauth-2-simplified/#web-server-apps\nhttps://blog.bearer.sh/understanding-auth-part-1-what-is-oauth/\n 多种授权模式 客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。\n 这里用户的授权,是在从第三方网站跳转到社交网站进行授权,用户需在社交网站登陆,并点击授权\n  authorization code implicit resource owner password credentials   The authorization code grant type is the most common variant of OAuth 2.0\n User-Agent Flow流程 以qq的OAuth2为例,qq采用了隐式(implicit)授权(client-side模式，是OAuth2.0认证的一种模式，又称User-Agent Flow)\n即不涉及后端,全在浏览器操作\nA网站向第三方注册 对于要使用第三方登陆功能的web service(此时,社交网站是第三方),必须先向第三方社交网站注册自己,获得唯一的Client ID and Secret,以qq第三方登陆为例,将会获得唯一的appid and apikey\n 对于secret/apikey必须机密保存在后端,如果是前端单页面服务,没有后端,则不应该向它们发送密钥,使用PKCE拓展\n  似乎 Client ID and Client Secret 被称为client credentials\n 用户在A网站点击第三方登陆 前端跳转到如下URL\nhttps://graph.qq.com/oauth2.0/authorize?response_type=code\u0026amp;client_id=CLIENT_ID\u0026amp;redirect_uri=REDIRECT_URI\u0026amp;scope=photos\u0026amp;state=1234zyx\r    参数 isNeed 含义     response_type 必须 授权类型，此值固定为“token”。   client_id 必须 申请QQ登录成功后，分配给应用的appid。   redirect_uri 必须 成功授权后的回调地址。   scope 可选 请求用户授权时向用户显示的可进行授权的列表。 可填写的值是API列表中列出的接口，以及一些动作型的授权（目前仅有：do_like），如果要填写多个接口名称，请用逗号隔开。 例如：scope=get_user_info,list_album,upload_pic,do_like 不传则默认请求对接口get_user_info进行授权。 建议控制授权项的数量，只传入必要的接口名称，因为授权项越多，用户越可能拒绝进行任何授权。   state 可选 client端的状态值。用于第三方应用防止CSRF攻击，成功授权后回调时会原样带回    如果用户成功登录并授权，则会跳转到指定的回调地址，并在URL后加“#”号，带上Access Token以及expires_in等参数。如果请求参数中传入了state，这里会带上原始的state值。如果redirect_uri地址后已经有“#”号，则加“\u0026amp;”号，带上相应的返回参数。如：  http://graph.qq.com/demo/index.jsp?#access_token=FE04************************CCE2\u0026amp;expires_in=7776000\u0026amp;state=test\n expires_in是该access token的有效期，单位为秒。\n Tips：\n 可通过js方法：window.location.hash来获取URL中#后的参数值。 建议用js设置cookie存储token。  获取openID  openid是qq用户的唯一标识\n 拿到access_token后,get如下的url:\nhttps://graph.qq.com/oauth2.0/me?access_token=YOUR_ACCESS_TOKEN \n返回\ncallback( {\u0026quot;client_id\u0026quot;:\u0026quot;YOUR_APPID\u0026quot;,\u0026quot;openid\u0026quot;:\u0026quot;YOUR_OPENID\u0026quot;} );  获取用户信息 获得用户标识openid后,get如下url:\nhttps://graph.qq.com/user/get_simple_userinfo?access_token=1234ABD1234ABD\u0026amp;oauth_consumer_key=12345\u0026amp; openid=B08D412EEC4000FFC37CAABBDC1234CC\u0026amp;format=json     参数 含义     access_token 可通过使用Implicit Grant方式获取Access Token来获取。 access_token有3个月有效期。   oauth_consumer_key 申请QQ登录成功后，分配给应用的appid(即client_id)   openid 用户的ID，与QQ号码一一对应。 可通过调用https://graph.qq.com/oauth2.0/me?access_token=YOUR_ACCESS_TOKEN 来获取。     注意,不是直接返回用户信息,而是让网站自己去请求\n 注意 Implicit was previously recommended for clients without a secret, but has been superseded by using the Authorization Code grant with PKCE.\n授权码流程 参考上述的User-Agent Flow,在第一次访问授权服务的时候,不直接返回access_token,而是返回一个授权码\n接着,我们拿这个授权码去得到access_token\nPOST https://api.authorization-server.com/token?\rgrant_type=authorization_code\u0026amp;\rcode=AUTH_CODE_HERE\u0026amp;\rredirect_uri=REDIRECT_URI\u0026amp;\rclient_id=CLIENT_ID\u0026amp;\rclient_secret=CLIENT_SECRET\r 因为是server发起的,所以可以带上secret\n响应:\n{\r\u0026quot;access_token\u0026quot;:\u0026quot;RsT5OjbzRn430zqMLgV3Ia\u0026quot;,\r\u0026quot;expires_in\u0026quot;:3600\r}\r  为什么不直接返回access_token? 因为不安全,我们希望access_token只在后端持有,所以多了一步用code换access_token的步骤\n Legs implicit和authority code都是three-legs,即都需要用户的参与\n2-legs的使用场景和第三方登陆无关,故不讨论\n Three legged does not imply a certain type of app as in \u0026ldquo;browser based\u0026rdquo;. Three legged means that an application acts on the direct behalf of a user. In the three legged scenarios there is\n an application (consumer), a user (resource owner) and an API (service provider).  In two legged scenarios there is no concept of a user. Typically this has to do with application-to-application solutions. There the application (consumer) acts on behalf of itself. So in two legged OAuth, there is:\n an application (consumer), an API (service provider)  The difference is simply that there is no need of a user authorisation step in the 2-legged approach.\n ","id":55,"section":"posts","summary":"OAuth2.0 open authority 2.0,开放授权 主要用于A网站向某个常用第三方社交网站请求用户信息,第三方社交网站需要给予A网站用户信息,这必须有用户的授权才行,但是","tags":["protocol"],"title":"[protocol] OAuth2","uri":"https://liwm29.github.io/2021/03/protocol-oauth2/","year":"2021"},{"content":"RPC识记-微服务概述 respect： rpc框架: https://doc.rpcx.io/\n关键字 服务发现，注册中心，服务治理，限流熔断隔离降级，codec等\nOutline   一般的，一个rpc框架就是一个微服务框架\n  一个好的协议,request和response应该是同样的格式\n  插件化与回调\n  服务发现\n 点对点 注册中心    服务选择\n 重试策略 节点选择策略    限流熔断，隔离降级\n  编解码codec\n 不同的序列化手段    服务监控\n trace：调用链追踪 logging：日志 metric：指标，统计分析    服务发现   服务发现\n  类似DNS，是一个kv数据库，完成servicName到ip:port的映射\n  点对点\n 直接指定对端ip:port，dial对端，不需要服务发现    点对多\n 同点对点，但指定了多个对端ip：port,它们将提供同样的服务，客户端在此模式下可以有不同的重试策略。    注册中心： zookeeper ， etcd ， consul\n  服务注册中心用来实现服务发现和服务的元数据存储（比如serviceName到多个ip:port的映射）。\n  传统的服务发现可能直接由静态配置文件设置，并且可以运行时动态监听文件修改并重新读入并应用。\n  更现代的方式是拥有一个注册中心，我们不再维护本地的配置文件，好处是注册中心是中心化管理，多个客户端共享。\n  注册中心都实现了某种分布式共识算法（指注册中心本身是分布式的（比如一个部署好的zookeeper集群），保证其某个节点失效仍可正常运行),其本质就是一个分布式键值数据库，如etcd\n  此模式下，使用rpc时，不再需要指定服务主机地址，而替换为注册中心集群地址\n  一般的，客户端将会向注册中心订阅，这样服务的动态变化将会异步通知到客户端。而不是客户端每次请求都去访问注册中心\n       dubbo架构： 服务选择 服务选择：\n 失败模式（重试模式）：当遇到超时或网络错误，该怎么办？  直接失败 重试其他节点 重试当前节点 广播一定数量的目标节点，有一个成功就算成功   节点选择  随机 roundrobin（顺序调用） weightedRoundRobin（在一个周期内，权值高的调用次数多，且较均匀的分布在周期内）  本质也是生成一个调用队列，依次出队   网络质量优先（基于ICMP ping）  也要防止网络状态不好的服务主机一直饥饿   一致性哈希  指满足均衡性，单调性，分散性，低负载的哈希算法，该算法将hash值空间组织成虚拟的环 首先将服务主机的ip:port计算出哈希值，store进哈希表 然后客户端对serviceName:serviceMethod:args计算出哈希值，将该值在环上按一定方向移动，第一个遇到的主机就是选中的主机   地理位置优先（计算经纬度） 自定义    限流熔断，隔离降级   限流：rateLimit\n  目的：有损服务，而不是不服务\n  限流对象\n TCP连接请求  一般无法限制tcp的建立，除非中间加一层代理网关   QPS：连接建立后，是否被处理    限流处理\n 返回错误码，比如http常见的500 internal error 服务端阻塞等待一段时间，看能否在超时时间内被处理    常见算法：\n  固定窗口计数器\n 比如每分钟为一个窗口（一般以整分钟开始1分钟到2分钟一个窗口），限制每个窗口内最多1000个连接 缺点：对于随机选取的时间长度为1分钟的区间（比如1.5分钟到2.5分钟），不一定满足连接数小于1000    滑动窗口计数器\n 固定窗口相当于长度为1的滑动窗口 比如以每秒钟为一个窗口，设置滑动窗口的长度为60，要求每分钟最多1000个连接。 每过1秒钟，滑动窗口向前移动一个小窗口，每个小窗口将维护一个计数，记录这个小窗口的时间期间到来的连接数 新的连接能否在新的小的时间窗口内被接收，取决于的逻辑的长度为60的滑动窗口内的所有小窗口记录的连接数之和是否大于1000    令牌桶 token bucket\n  维护一个有大小的令牌桶，若桶未满，则以一定的速率生成令牌放入桶中\n  每个请求必须在申请到令牌后，才会被处理，否则限流\n  原生令牌桶是基于字节数判断一个packet是否有效，即限制的是读写的byte数\n  详见https://en.wikipedia.org/wiki/Token_bucket\n  一个限流器实现： https://github.com/juju/ratelimit, 其reader/writer实现:\n  func (r *reader) Read(buf []byte) (int, error) {\rn, err := r.r.Read(buf)\rif n \u0026lt;= 0 {\rreturn n, err\r}\rr.bucket.Wait(int64(n))\rreturn n, err\r}\rfunc (w *writer) Write(buf []byte) (int, error) {\rw.bucket.Wait(int64(len(buf)))\rreturn w.w.Write(buf)\r}\r       实际上也可以用于直接限制连接：\n  // rpcx的限流插件：实现了PostConnAcceptPlugin接口\r//\tPostConnAcceptPlugin interface {\r//\tHandleConnAccept(net.Conn) (net.Conn, bool)\r//\t}\rfunc (plugin *RateLimitingPlugin) HandleConnAccept(conn net.Conn) (net.Conn, bool) {\rreturn conn, plugin.bucket.TakeAvailable(1) \u0026gt; 0\r}\r       漏桶\n 维持一个固定大小的连接队列，以恒定的速率出队        熔断： circuit breaker（断路器）\n 熔断属于服务作为客户端时的行为 当对一个节点的调用出现连续的错误时，断路器将打开，后续对该节点的调用将直接返回错误。一定时间后断路器半开，允许一定数量的请求，若正常访问则全开，否则继续断开 这主要是为了防止大量的请求处于请求发出而未超时的等待阶段，若这个客户端本身作为服务，则也会影响自身的服务提供，导致雪崩  因为资源是有限的，一个goroutine要2k的栈，再加上1k的recv buffer等等      降级\n 服务降级：本质就是提供有损服务 限流和熔断都属于服务降级    隔离\n 将本机的各个服务隔离开，这也是docker这类容器的优点：隔离 实现上，就是对资源的获取是有限度的，比如设置最大的goroutine数，这可以通过线程池做到    编解码codec 常见的编解码器，即对对象的序列化和反序列化功能\n binary json  对性能要求不高的场景，可读性高   protobuf  google出品   messagePack  插件化和回调 rpcx提供了多种回调接口,只要插件实现了这些接口，再注册进插件中心即可在合适的地方被调用\n比如限流插件，我们期望其在连接建立后被调用，因此要实现HandleConnAccept(conn net.Conn) (net.Conn, bool)方法\ntype (\r// ... 省略一部分\r// PostConnAcceptPlugin represents connection accept plugin.\r// if returns false, it means subsequent IPostConnAcceptPlugins should not continue to handle this conn\r// and this conn has been closed.\rPostConnAcceptPlugin interface {\rHandleConnAccept(net.Conn) (net.Conn, bool)\r}\r// PostConnClosePlugin represents client connection close plugin.\rPostConnClosePlugin interface {\rHandleConnClose(net.Conn) bool\r}\r// PreReadRequestPlugin represents .\rPreReadRequestPlugin interface {\rPreReadRequest(ctx context.Context) error\r}\r// PostReadRequestPlugin represents .\rPostReadRequestPlugin interface {\rPostReadRequest(ctx context.Context, r *protocol.Message, e error) error\r}\r// ...省略一部分\r)\r 插件中心将会在合适的地方调用注册好的插件，比如read前后的回调：\nfunc (s *Server) readRequest(ctx context.Context, r io.Reader) (req *protocol.Message, err error) {\r// here callback\rerr = s.Plugins.DoPreReadRequest(ctx)\rif err != nil {\rreturn nil, err\r}\r// pool req?\rreq = protocol.GetPooledMsg()\rerr = req.Decode(r)\rif err == io.EOF {\rreturn req, err\r}\r// here callback\rperr := s.Plugins.DoPostReadRequest(ctx, req, err)\rif err == nil {\rerr = perr\r}\rreturn req, err\r}\r 一个朴素的插件中心的实现,将会把不同的插件无差别的放进一个[]interface{}，调用时再遍历一个个type assertion，看是否是想要的接口，这也是rpcx默认的插件中心的实现方法\n//DoPostConnAccept handles accepted conn\rfunc (p *pluginContainer) DoPostConnAccept(conn net.Conn) (net.Conn, bool) {\rvar flag bool\rfor i := range p.plugins {\rif plugin, ok := p.plugins[i].(PostConnAcceptPlugin); ok {\rconn, flag = plugin.HandleConnAccept(conn)\rif !flag { //interrupt\rconn.Close()\rreturn conn, false\r}\r}\r}\rreturn conn, true\r}\r 下一代微服务 service mesh\n 分为数据面和控制面，用户只需编写数据面即可  ","id":56,"section":"posts","summary":"RPC识记-微服务概述 respect： rpc框架: https://doc.rpcx.io/ 关键字 服务发现，注册中心，服务治理，限流熔断隔离降级，codec等 Outline 一般的，一个rpc框","tags":["rpc"],"title":"[rpc] rpcx","uri":"https://liwm29.github.io/2021/03/rpc-rpcx/","year":"2021"},{"content":"Inotify  The inotify API provides a mechanism for monitoring filesystem\revents. Inotify can be used to monitor individual files, or to\rmonitor directories. When a directory is monitored, inotify will\rreturn events for the directory itself, and for files inside the\rdirectory.\r  四个API\n func InotifyInit() (fd int, err error)  func InotifyInit1(flags int) (fd int, err error) 这个可以设置flags(O_NONBLOCK,O_BLOCK),这涉及到read(fd,buffer,buff_size)时是阻塞还是非阻塞   func InotifyAddWatch(fd int, pathname string, mask uint32) (watchdesc int, err error)  对pathname进行监听,并绑定到fd上,mask表示监听哪些事件 返回watch desciptor,专用于remove取消监听   func InotifyRmWatch(fd int, watchdesc uint32) (success int, err error)  将监听事件从fd上取消   其他  读取事件  read(fd , buf , buf_sz)   关闭监听  close(fd)      buf 将需要被解释成:\nstruct inotify_event {\rint wd; /* Watch descriptor */\ruint32_t mask; /* Mask describing event */\ruint32_t cookie; /* Unique cookie associating related\revents (for rename(2)) */\ruint32_t len; /* Size of name field */\rchar name[]; /* Optional null-terminated name */\r};\r 在go语言中就是:\nevent := (*syscall.InotifyEvent)(unsafe.Pointer(\u0026amp;buffer[offset]))\r 示例: from: tomnomnom/go-learning\nfunc main() {\rfd, err := syscall.InotifyInit()\rif err != nil {\rlog.Fatal(err)\r}\rdefer syscall.Close(fd)\rwd1, err := syscall.InotifyAddWatch(fd, \u0026quot;test1.log\u0026quot;, syscall.IN_ALL_EVENTS)\rwd2, err = syscall.InotifyAddWatch(fd, \u0026quot;../test2.log\u0026quot;, syscall.IN_ALL_EVENTS)\r//_, err = syscall.InotifyAddWatch(fd, \u0026quot;.\u0026quot;, syscall.IN_ALL_EVENTS)\rif err != nil {\rlog.Fatal(err)\r}\rdefer syscall.InotifyRmWatch(fd, uint32(wd1))\rdefer syscall.InotifyRmWatch(fd, uint32(wd2))\rfmt.Printf(\u0026quot;WD is %d\\n\u0026quot;, wd)\rfor {\r// Room for at least 128 events\rbuffer := make([]byte, syscall.SizeofInotifyEvent*128)\rbytesRead, err := syscall.Read(fd, buffer)\rif err != nil {\rlog.Fatal(err)\r}\rif bytesRead \u0026lt; syscall.SizeofInotifyEvent {\r// No point trying if we don't have at least one event\rcontinue\r}\rfmt.Printf(\u0026quot;Size of InotifyEvent is %s\\n\u0026quot;, syscall.SizeofInotifyEvent)\rfmt.Printf(\u0026quot;Bytes read: %d\\n\u0026quot;, bytesRead)\roffset := 0\rfor offset \u0026lt; bytesRead-syscall.SizeofInotifyEvent {\revent := (*syscall.InotifyEvent)(unsafe.Pointer(\u0026amp;buffer[offset]))\rfmt.Printf(\u0026quot;%+v\\n\u0026quot;, event)\rif (event.Mask \u0026amp; syscall.IN_ACCESS) \u0026gt; 0 {\rfmt.Printf(\u0026quot;Saw IN_ACCESS for %+v\\n\u0026quot;, event)\r}\r// We need to account for the length of the name\roffset += syscall.SizeofInotifyEvent + int(event.Len)\r}\r}\r}\r ","id":57,"section":"posts","summary":"Inotify The inotify API provides a mechanism for monitoring filesystem events. Inotify can be used to monitor individual files, or to monitor directories. When a directory is monitored, inotify will return events for the directory itself, and for files inside the directory. 四个API func InotifyInit() (fd int, err error) func InotifyInit1(flags int) (fd int, err error) 这个可以设置flag","tags":["sys"],"title":"[sys] inotify","uri":"https://liwm29.github.io/2021/03/sys-inotify/","year":"2021"},{"content":"TSAR taobao system activity reporter\n该工具本质是在读取linux系统/proc目录下的一些计数器文件,本片文章来介绍这些文件,及其内部包含的信息\n关于此目录下的文件信息,\n可直接看linux官方文档:https://man7.org/linux/man-pages/man5/procfs.5.html\n也可关注tsar给的文档: https://github.com/alibaba/tsar/blob/master/info.md\n由于每个文件是非常verbose的,如果你只想关注更重要的那些字段,你可以看看top命令打印了哪些字段\nCPU coreInfo 使用此指令打印出一个逻辑核的相关信息,其他核是类似的信息,因为是SMP\ncat cpuinfo | head -n 27\nprocessor : 0\rvendor_id : GenuineIntel\rcpu family : 6\rmodel : 142\rmodel name : Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\rstepping : 10\rmicrocode : 0xffffffff\rcpu MHz : 1799.999\rcache size : 6144 KB\rphysical id : 0\rsiblings : 8\rcore id : 0\rcpu cores : 4\rapicid : 0\rinitial apicid : 0\rfpu : yes\rfpu_exception : yes\rcpuid level : 21\rwp : yes\rflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves flush_l1d arch_capabilities\rbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\rbogomips : 3599.99\rclflush size : 64\rcache_alignment : 64\raddress sizes : 39 bits physical, 48 bits virtual\rpower management:\r 解释:\n 摘自https://www.cnblogs.com/wxxjianchi/p/10522049.html\n processor　：系统中逻辑处理核心数的编号，从0开始排序。\rvendor_id　：CPU制造商\rcpu family　：CPU产品系列代号\rmodel　：CPU属于其系列中的哪一代的代号\rmodel name：CPU属于的名字及其编号、标称主频\rstepping　：CPU属于制作更新版本\rcpu MHz　：CPU的实际使用主频\rcache size ：CPU二级缓存大小\rphysical id ：单个物理CPU的标号\rsiblings ：单个物理CPU的逻辑CPU数。siblings=cpu cores [*2]。\rcore id ：当前物理核在其所处CPU中的编号，这个编号不一定连续。\rcpu cores ：该逻辑核所处CPU的物理核数。比如此处cpu cores 是4个，那么对应core id 可能是 1、3、4、5。\rapicid ：用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续\rfpu ：是否具有浮点运算单元（Floating Point Unit）\rfpu_exception ：是否支持浮点计算异常\rcpuid level ：执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容\rwp ：表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）\rflags ：当前CPU支持的功能\rbogomips：在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second\rclflush size ：每次刷新缓存的大小单位\rcache_alignment ：缓存地址对齐单位\raddress sizes ：可访问地址空间位数\rpower management ：对能源管理的支持\r 注解 上面已经讲的很清楚了,可以看出,我们的cpu的缓存是64字节为一个缓存行的,有专门的浮点数alu,每秒大概能执行3.6G条指令,虚拟地址空间是48位,物理地址空间是39位.cpu的实际主频是1.8GHZ,在flags里,我们看到了熟悉的avx,也就是是否支持向量化拓展指令集.\n使用\ncat cpuinfo | grep processor\n可以看到输出是8个处理器,这是因为intel的单CPU四核八线程,这里的线程可以理解为就是处理器的意思\n超线程技术 我们知道一个核支持并行执行指令有几个级别,比如数据级并行,指令级并行和线程级并行\n 数据级并行  多个ALU   指令级并行  多个取址译码器,多个ALU,同时执行一个线程的多条指令 也叫多发射  动态多发射叫超标量,即运行时确定同时执行哪些指令 与之相比的是静态多发射,由编译器确定同时执行哪些指令   瓶颈很明显,由于各自依赖(比如数据依赖),单线程没有那么多指令可以并行   线程级并行  多个取址译码器,多个ALU,多个Context(执行上下文/也就是寄存器组) 同时执行不同线程的多条指令    超线程应该就是同时多线程的一种实现\ncpuTime cat /proc/stat 此命令查看cpu的时间分配,典型的就是用户态运行时间,内核态运行时间,io阻塞时间,空闲空转时间,中断时间等\n参考: http://gityuan.com/2017/08/12/proc_stat/\n//CPU指标：user，nice, system, idle, iowait, irq, softirq\rcpu 151 0 1822 3035462 65 0 66 0 0 0\rcpu0 17 0 737 378763 6 0 44 0 0 0\rcpu1 6 0 38 379698 8 0 11 0 0 0\rcpu2 30 0 320 379258 28 0 11 0 0 0\rcpu3 8 0 24 379718 1 0 0 0 0 0\rcpu4 29 0 239 379427 6 0 0 0 0 0\rcpu5 5 0 15 379698 0 0 0 0 0 0\rcpu6 22 0 422 379221 8 0 0 0 0 0\rcpu7 34 0 27 379674 4 0 0 0 0 0\rintr 31441 0 0 0 0 0 0 0 0 0 18 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\rctxt 151746 // 进程上下文切换次数\rbtime 1616574037 // 计算机启动时间(Unix时间)\rprocesses 403 // Number of forks since boot. 如果想看当前的进程数,可以看/proc/loadavg或top\rprocs_running 1 // 正在运行的进程数\rprocs_blocked 0 // 阻塞数\rsoftirq 147819 0 41104 0 123 4812 0 20320 42642 0 38818\r    cpu指标 含义     user 用户态时间(一般/高优先级,nice\u0026lt;=0)   nice 用户态时间(低优先级，nice\u0026gt;0)   system 内核态时间   idle 空闲时间   iowait I/O等待时间   irq 硬中断   softirq 软中断   steal 被盗时间,Steal time is the percentage of time a virtual CPU waits for a real CPU while the hypervisor is servicing another virtual processor.   guest 来宾时间   guest_nice nice来宾时间     单位是jiffies , 1 jiffies = 0.01s = 10ms\n统计cpu利用率: 总时间就是它们的和\n top 在top命令的第三行,即打印出了全局的cpu利用率\n%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\r 进程 如果想看某个进程的统计信息,一是strace -p [pid],二就是直接看统计文件\n某个进程的统计文件在/proc/[pid]/stat\nMemory /rpoc/meminfo\nMemTotal: 6399360 kB // 总共可用空间,由physical - reserved bits - kernel binary code\rMemFree: 6285756 kB // LowFree+HighFree.\rMemAvailable: 6181148 kB // 在不换页的情况下,一个新进程可以使用多少内存\rBuffers: 7140 kB // 尚未被写回硬盘的块\rCached: 21828 kB // page cache,not include wapcached\rSwapCached: 0 kB // 和swapfile有关\rActive: 19984 kB // Inactive: 11220 kB\rActive(anon): 2352 kB\rInactive(anon): 8 kB\rActive(file): 17632 kB\rInactive(file): 11212 kB\rUnevictable: 0 kB\rMlocked: 0 kB\rSwapTotal: 2097152 kB\rSwapFree: 2097152 kB\rDirty: 76 kB\rWriteback: 0 kB\rAnonPages: 2228 kB\rMapped: 4000 kB\rShmem: 68 kB\rSlab: 26720 kB\rSReclaimable: 12924 kB\rSUnreclaim: 13796 kB\rKernelStack: 1892 kB\rPageTables: 448 kB\rNFS_Unstable: 0 kB\rBounce: 0 kB\rWritebackTmp: 0 kB\rCommitLimit: 5296832 kB\rCommitted_AS: 8048 kB\rVmallocTotal: 34359738367 kB\rVmallocUsed: 0 kB\rVmallocChunk: 0 kB\rPercpu: 1888 kB\rAnonHugePages: 0 kB\rShmemHugePages: 0 kB\rShmemPmdMapped: 0 kB\rHugePages_Total: 0\rHugePages_Free: 0\rHugePages_Rsvd: 0\rHugePages_Surp: 0\rHugepagesize: 2048 kB\rHugetlb: 0 kB\rDirectMap4k: 17408 kB\rDirectMap2M: 2398208 kB\rDirectMap1G: 5242880 kB\r util = (total - free - buff - cache) / total * 100%\r 在top的第四/五行:\nKiB Mem : 6399360 total, 6276944 free, 75224 used, 47192 buff KiB Swap: 2097152 total, 2097152 free, 0 used. 6175056 avai\r LoadAvg /proc/loadavg\n0.00 0.00 0.00 1/110 52\r  The first three fields in this file are load average\rfigures giving the number of jobs in the run queue (state\rR) or waiting for disk I/O (state D) averaged over 1, 5,\rand 15 minutes. They are the same as the load average\rnumbers given by uptime(1) and other programs. The fourth\rfield consists of two numbers separated by a slash (/).\rThe first of these is the number of currently runnable\rkernel scheduling entities (processes, threads). The\rvalue after the slash is the number of kernel scheduling\rentities that currently exist on the system. The fifth\rfield is the PID of the process that was most recently\rcreated on the system.\r Trafic /proc/net/dev\nInter-| Receive | Transmit\rface |bytes packets errs drop fifo frame compressed multicast|bytes packets errs drop fifo colls carrier compressed\reth0: 2234 22 0 0 0 0 0 21 1266 17 0 0 0 0 0 0\rlo: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\rdummy0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\rbond0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\rsit0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r TCP/UDP/ICMP /proc/net/snmp\ndiskIO /proc/diskstats\nother 更多详细的可以直接看linux官方文档和tsar\n注意一般官方文档的释义可能也比较简略,这时自己再搜索一下基本就ok了\n","id":58,"section":"posts","summary":"TSAR taobao system activity reporter 该工具本质是在读取linux系统/proc目录下的一些计数器文件,本片文章来介绍这些文件,及其内部包含的信息 关于此目录下的文件信息","tags":["sys"],"title":"[sys] tsar\u0026proc","uri":"https://liwm29.github.io/2021/03/sys-tsarproc/","year":"2021"},{"content":"1. vue的生命周期/运行流程/渲染流程/初始化流程 doc link\n  vue的入口文件可以有四个可能的命名:main.js,index.js,app.vue,App.vue\n 真正的入口文件取决于哪个文件包含了vue实例(new Vue({})),渲染流程从vue实例开始    流程大致如下:\n new Vue({}) init event 回调 beforeCreate() init element 回调 created() 检查Vue实例:  是否有{el:\u0026quot;\u0026hellip;\u0026quot;}?  没有:等待vm.$mount(el)被调用,然后下一步  例: new Vue({render: h =\u0026gt; h(App),}).$mount('#app') 一般出现在main.js,index.js文件中   有:下一步   是否有\u0026lt;template\u0026gt;  有:把\u0026lt;template\u0026gt;编译到render function 没有:把el的outerHTML作为template编译     回调 beforeMount() 创建vm.$el,并且用vm.$el替换#el(应该指渲染,用前面的renderFunc/template) 回调 mounted()  实例进入监听循环,当数据被改变时,重新渲染  回调: beforeUpdate() 回调: updated()     当vm.$destroy()被调用  回调: beforeDestroy() teardown(拆除) watchers,子组件,事件监听器 回调: destroyed()      分析:\n vue实例一定要挂载到一个html元素上 手动使用vm.$mount(\u0026quot;#app\u0026quot;),是为了延迟挂载渲染 render:h=\u0026gt;h(oneComponent) 是一种渲染组件的方式  render: function (createElement) {\rreturn createElement(App);\r}\r   使用vue-cli,vue create hello-word生成的代码分析  main.js  import Vue from 'vue'\rimport App from './App.vue'\rVue.config.productionTip = false\rnew Vue({\rrender: h =\u0026gt; h(App),\r}).$mount('#app')\r 等价于,...就是把字典解包\nimport Vue from 'vue'\rimport App from './App.vue'\rVue.config.productionTip = false\rnew Vue({\rel: '#app',\r...App\r})\r ","id":59,"section":"posts","summary":"1. vue的生命周期/运行流程/渲染流程/初始化流程 doc link vue的入口文件可以有四个可能的命名:main.js,index.js,app.vue","tags":["vue"],"title":"[vue] everything","uri":"https://liwm29.github.io/2021/03/vue-everything/","year":"2021"},{"content":"About import and export  这是es6的语法,即js的语法 export用于对外输出本模块的数据 import用于引入其他模块的数据  语法细则 // 导出变量\r// 法一\r// js1\rexport var name = \u0026quot;a\u0026quot;\r// js2\rimport {name} from \u0026quot;./js1.js\u0026quot;\r// 法二\r// js1\rvar name1 = \u0026quot;a\u0026quot;\rvar name2 = \u0026quot;b\u0026quot;\rexport {name1 , name2}\r// 或者\rexport name1\rexport name2\r// 或者\rexport var name1 = \u0026quot;a\u0026quot;\rexport var name2 = \u0026quot;b\u0026quot;\r// js2\rimport {name1 , name2} from \u0026quot;./js1.js\u0026quot;\r// 或者\rimport {name1} from \u0026quot;./js1.js\u0026quot;\rimport {name2} from \u0026quot;./js1.js\u0026quot;\r// ===========================\r// 导出函数,和变量是一致的\rfunction add(x,y){\rreturn (x+y)\r}\rexport {add}\r// 或者\rexport function add(x,y){\rreturn x+y\r}\r// js2\rimport {add} from \u0026quot;./js1.js\u0026quot;\r export and export default  export,export default均可用于导出变量,函数,文件,模块等 一个文件或模块中,export/import可以有多个,但是export default只能有一个 export的导出,import时要加入{},但是export default则不需要 export default相当于指定默认输出,而export时,import要完整写出对应导出的变量/函数名  export default {\raddress：'1',\r}\rexport var title = '2'\rexport var zzz = '3'\r// js2\rimport js1,{title as t , zzz} from \u0026quot;./js1.js\u0026quot;\r import的后缀名省略  直接使用import js from \u0026quot;./js1\u0026quot; 规则:  在 webpack.base.conf.js 中设置 可以省略js,vue后缀 若同时存在js,vue后缀同名文件,js\u0026gt;vue from后可以是文件夹  加载规则:  先看该文件夹有没有packag.json  若有:取package.main指定的js作为from的来源   index.js index.vue     注意,一般来说 package.json都只会出现项目根目录,注意不是@,是@的再外面一层,用来配置npm install这些指令    ","id":60,"section":"posts","summary":"About import and export 这是es6的语法,即js的语法 export用于对外输出本模块的数据 import用于引入其他模块的数据 语法细则 // 导出变量 // 法一 // js1 export var","tags":["vue"],"title":"[vue] import-export","uri":"https://liwm29.github.io/2021/03/vue-import-export/","year":"2021"},{"content":"聚类 聚类是一种无监督的方法,我们仅仅通过向量的特征即可将不同的向量按相邻的距离聚在一起\n对于输入的数值元组的不同的视角,我们可以定义不同的距离\n 将元组视为向量  计算cos距离来求解相似度,即余弦值,可有余弦定理计算得出   将元组视为集合  计算jaccard距离,即A∩B/A∪B   将元组视为欧氏空间中的坐标点  计算欧式距离    层次聚类 方法是不断的将小聚类合并(合并两个最近的聚类),形成大的聚类,从单个点作为一个聚类开始\n也可以是top down的方法,不断将大聚类split,但一般采用bottom up方法\n 聚类的代表  centroid : average of its points(这要求欧式空间(欧式距离),此时直线最短,所以直接求平均,便是聚类的中心点)  centroid 可能不是一个实际存在的点   clustroid: point closest to other points  clustroid一定是一个实际存在的点     聚类内closest的定义(clustroid选举)  某个点关于其他所有点的最大距离最小,则这个点是clustroid 某个点关于其他所有点的平均距离最小 某个点关于其他所有点的距离平方和最小   聚类间nearness定义(聚类合并选择)  将clustroid视作centroid,计算两个cluster的centroid/clustroid之间的距离  注意如果没有定义欧式距离就没有centroid,但一定会有距离的定义,只是不是直线最短   分别从两个聚类选择两个点,得到的最小的距离即使聚类之间的距离 凝聚度(计算合并后的聚类的凝聚度)  直径: 聚类内的点之间的最大距离 平均距离: 聚类内所有点之间的平均距离 密度: 使用直径或平均距离除以点数,密度越小越好(相同直径下,点越多,密度越小,聚类越密集)     看网上其他博客,基本都采用这样的距离定义来计算聚类间的nearness:  聚类间两点距离的最小值 聚类间两点距离的最大值 聚类间两点距离的平均值    k-means 算法  这里的k指的是k个聚类\n 首先会给每个聚类随机初始化为1个点,也就是我们要随机选取k个点,每个点作为一个聚类.\n但显然,如果随机选,可能选到两个很近的点,因此针对初始化的不同,提出了k-means++算法,二者仅仅在初始化时不同,后续跌打是一样的\n 初始化  随机 k-means++  随机遍历点,但是否将它们加入初始点集合取决于它与已加入初始点集合内的点的最短距离的平方 因此,以这种方法选出来的k个初始点将会尽可能的远   于是,每个cluster都有了一个centroid   聚类  遍历所有点,将其加入离他最近的centroid所属的cluster(你可以认为也遍历了初始点,反正肯定离自己最近,当迭代一次后,一般centroid都不再是实际存在的点) 遍历完后,更新cluster的centroid位置 重新遍历所有点,加入离他最近的centroid所属的cluster  此时,点对cluster的所属关系可能变更   重复上述过程   收敛  当点对cluster的所属关系不再变更,并且centroid稳定时,认为收敛   k的选择  我们计算聚类内的点到centroid的平均距离作为k的好坏,平均距离越小,k越好 实践证明,k越大,平均距离越小,当大到一定程度后,平均距离几乎不变,此时即为最佳的k    BFR 算法  算法名字是三个发明人的首字母\n BFR算法是k-means算法的变种,用于解决大规模数据集问题(这些数据集一般驻留在磁盘上)\n首先我们假设聚类内的点是关于centroid呈正太分布的,不同的维度的标准差不同,这意味着一个聚类将会很像一个关于轴对齐的椭圆(一个轴就是一个维度)\n ? 我们的目标是找到cluster的centroid,然后就可以按照k-means的算法,对所有点计算得到离他最近的centroid,并归入那个cluster(这称为point assignment)\n 算法流程:\n 初始化k个cluster的centroid 加载一些point到内存 对这些点进行point assignment,前提是最小距离小于一定的阈值,如果这些点离最近的centroid的距离大于所设置的阈值,则将这些点视为outlier离群点 将离群点独立为一个cluster,于是现存k+1个cluster 对k+1个cluster中的两个cluster执行merge,生成k个cluster 重复2-5  我们将维护三类点集\n Discard set(DS): 能够被分配给某个cluster的点(我们可以加载它,计算统计信息,然后丢弃这个实例,有点充分统计量的感觉) Compression set(CS): 一些足够近的点的集合,但这些点离最近的centroid足够远,所以独立成为一个cluster Retained set(RS): 孤立的等待被分配给CS压缩集的点  每个discard set将会维护2d+1个值,d是向量的维度\n 1: 点数 d: sum向量,sum_i代表set内的所有点的第i个分量的和 d: sumsq向量,sumsq_i代表sum_i的平方  有了这三个数值,我们可以很方便的计算ds的centroid和方差(centroid就是每个维度的平均值,sum/N , 方差就是(sumsq/N) - (sum/N)^2),我们不需要知道到底哪些点属于ds,我们唯一要维护的就是这三个统计量\n 注意,cluster是轴对齐的,这样的好处是sumsq是一个d维向量,而不是一个dxd的二维协方差矩阵\n 将点加载到内存,如果发现这些点离某个centroid足够近,就将这些点分配给那个cluster,并添加到ds\n这样,一次加载进内存的点将还会剩下一些点没有进入任何集合,这些点由于离现存的centroid们比较远而无法进入discard set,现在我们对这些在内存中的点运用任何in-memory的聚类方法分类即可,我们要分出两类,一类是compression set,一类是retained set\n比如我们直接对剩下的点随机初始化几个centroid(或使用层次聚类),然后遍历所有点,如果离这些centroid足够近,就加入这些cluster对应的compression set,否则便是离群点,加入retained set\n下一步,我们首先处理ds,之前加入ds的点,在这一步用于更新ds的统计量(N,sum,sumsq)(实际上这一步完全可以放在加入ds时就直接更新统计量)\n然后,考虑合并compressed set,如果这是最后一轮,那么合并compressed set和ratained set到最近的cluster中\n距离 使用mahalanobis distance(马氏距离),点x到centroid点c的距离定义为: $$ d(x,c) = \\sqrt{\\sum_{i=1}^d(\\frac{x_i-c_i}{\\sigma_i})^2} $$ 即对每个维度进行标准化,然后求平方和的根号\n根据3sigma原则, 当x_i = c_i + sigma_i或c_i - sigma时,dist = sqrt(d)\n此时,有68%的概率,使得dist\u0026lt;sqrt(d),如果x服从正态分布\n一般的,我们认为一个点x属于某个cluster,如果dist\u0026lt;2sqrt(d)\n合并 何时合并cs中的集合呢? 如果合并后的方差小于某个阈值,则合并两个compressed set\nCURE \u0026hellip;\n","id":61,"section":"posts","summary":"聚类 聚类是一种无监督的方法,我们仅仅通过向量的特征即可将不同的向量按相邻的距离聚在一起 对于输入的数值元组的不同的视角,我们可以定义不同的距离","tags":null,"title":"","uri":"https://liwm29.github.io/1/01/datamining-cluster/","year":"0001"},{"content":"[c] 符号与链接 我们知道,一个可执行文件的生成过程经历了一些步骤:\n预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接\n最终的步骤,是将不同的.o目标文件链接在一起,形成一个可执行文件,不同的.o文件将会引用其他.o文件内的变量或函数,那么它们是怎么找到对应的变量或函数的地址的呢?\n程序装载 一个程序是怎么装载进内存的呢? 很显然,当我们在bash下直接输入程序名时,该程序就被启动了,比如\u0026quot;./a\u0026quot;,就启动了当前路径下的程序a\n但是我们知道,实际上shell也是一个程序,这其实是在一个程序下去启动另一个程序\n实际上,会首先调用fork(),然后在子进程中中进行系统调用\u0026quot;execve()\u0026quot;,执行新的程序,而父进程则\u0026quot;waitpid\u0026quot;等待子进程结束(父进程就是bash,借此我们也可以自己实现一个简单的shell)\n因此,程序被执行/被装载进内存依赖一个系统调用: \u0026ldquo;execve()\u0026rdquo;\n静态链接 这种链接方法会将静态链接库和自己的代码合在一起生成一个较大的可执行文件\n动态链接 程序可以调用不存在于静态文件中的函数或变量\n加载时  称为隐式动态链接\n 常规的链接手段,当使用诸如\u0026quot;gcc a.c -o a.out -lpthread\u0026quot;时,这个libpthread.so就会在程序加载时一起链接加载到内存\n好处是,静态可执行程序是不需要包含整个.so动态链接库的\n运行时  称为显式动态链接\n 还可以在程序中显式的加载动态链接库,这个在windows系统编程中是常见的,比如go语言中加载win32的api\ndll := syscall.NewLazyDLL(\u0026quot;kernel32.dll\u0026quot;)\rmessageBox , _ := syscall.GetProcAddress(dll, \u0026quot;MessageBoxW\u0026quot;)\r 通过GetProcAddress显式调用函数\n","id":62,"section":"posts","summary":"[c] 符号与链接 我们知道,一个可执行文件的生成过程经历了一些步骤: 预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接 最终的步骤,是将不同的.o目标","tags":["c"],"title":"[c] 符号与链接","uri":"https://liwm29.github.io/1/01/c-%E7%AC%A6%E5%8F%B7%E4%B8%8E%E9%93%BE%E6%8E%A5/","year":"0001"},{"content":"荐读 unix domain sockets vs. internet sockets\n简单说来,就是internet socket(使用AF_INET地址族),即使是dial本机localhost来通信,其也会经历一个完整的网络流程(虽然是通过lo网卡),也会收到syn,ack包,只是碰巧在解析的过程中,机器发现了这个包是要路由到本机的,于是借助lo网卡回来,本质仍然是一种尽力交付\n但是unix domain socket不同,它是专用于做本机ipc的,是一种可信交付,它直接将数据写到recv socket 的buffer,而不需要header,checksum这些东西\n","id":63,"section":"posts","summary":"荐读 unix domain sockets vs. internet sockets 简单说来,就是internet socket(使用AF_INET地址族),即使是dial本机localhost来通信,其也会经","tags":["sys","socket"],"title":"[sys] unix domain socket","uri":"https://liwm29.github.io/1/01/sys-unix-domain-socket/","year":"0001"}],"tags":[{"title":"alg","uri":"https://liwm29.github.io/tags/alg/"},{"title":"arch","uri":"https://liwm29.github.io/tags/arch/"},{"title":"atomic","uri":"https://liwm29.github.io/tags/atomic/"},{"title":"ByteDance","uri":"https://liwm29.github.io/tags/bytedance/"},{"title":"c","uri":"https://liwm29.github.io/tags/c/"},{"title":"cache","uri":"https://liwm29.github.io/tags/cache/"},{"title":"cli","uri":"https://liwm29.github.io/tags/cli/"},{"title":"concurrency","uri":"https://liwm29.github.io/tags/concurrency/"},{"title":"dataMining","uri":"https://liwm29.github.io/tags/datamining/"},{"title":"dataStructure","uri":"https://liwm29.github.io/tags/datastructure/"},{"title":"DB","uri":"https://liwm29.github.io/tags/db/"},{"title":"deploy","uri":"https://liwm29.github.io/tags/deploy/"},{"title":"Go","uri":"https://liwm29.github.io/tags/go/"},{"title":"HTTP","uri":"https://liwm29.github.io/tags/http/"},{"title":"interview","uri":"https://liwm29.github.io/tags/interview/"},{"title":"kafka","uri":"https://liwm29.github.io/tags/kafka/"},{"title":"LSH","uri":"https://liwm29.github.io/tags/lsh/"},{"title":"mem","uri":"https://liwm29.github.io/tags/mem/"},{"title":"mq","uri":"https://liwm29.github.io/tags/mq/"},{"title":"other","uri":"https://liwm29.github.io/tags/other/"},{"title":"protocol","uri":"https://liwm29.github.io/tags/protocol/"},{"title":"rpc","uri":"https://liwm29.github.io/tags/rpc/"},{"title":"server","uri":"https://liwm29.github.io/tags/server/"},{"title":"socket","uri":"https://liwm29.github.io/tags/socket/"},{"title":"sys","uri":"https://liwm29.github.io/tags/sys/"},{"title":"Todo","uri":"https://liwm29.github.io/tags/todo/"},{"title":"underTheHood","uri":"https://liwm29.github.io/tags/underthehood/"},{"title":"vue","uri":"https://liwm29.github.io/tags/vue/"},{"title":"zookeeper","uri":"https://liwm29.github.io/tags/zookeeper/"}]}